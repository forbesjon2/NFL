{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70409bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from NFLUtils import NFLUtils\n",
    "nfl_utils = NFLUtils()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ANN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Set pandas display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# XGBoost \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn as sns # confusion matrix\n",
    "\n",
    "# Set device to GPU if available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556dd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff2364",
   "metadata": {},
   "source": [
    "### Load CSV & UMAP model\n",
    "cp Combined.csv ~/drive/Notes/ML/Pytorch/footballData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfebbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5505 entries, 0 to 5504\n",
      "Columns: 196 entries, Unnamed: 0 to kick_punt_umap_dim_2\n",
      "dtypes: float64(179), int64(14), object(3)\n",
      "memory usage: 8.2+ MB\n",
      "df after perf set removed: (5305, 196)\n",
      "performance set size: (200, 196)\n",
      "df after missing odds removed: (5305, 196)\n",
      "df perf after missing odds removed: (188, 196)\n",
      "<class 'umap.umap_.UMAP'>\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"./footballData/CombinedSlidingWindow4.csv\", index_col=False, low_memory=False)\n",
    "\n",
    "df.info()\n",
    "\n",
    "# The performance set's size is defined in the SlidingWindowNFL-1 file. When kick_punt_umap_dim_1 (or 2) is blank\n",
    "test_performance_df = df[df['kick_punt_umap_dim_1'].isna()]\n",
    "df = df[df['kick_punt_umap_dim_1'].isna() == False]\n",
    "print(f'df after perf set removed: {df.shape}')\n",
    "print(f'performance set size: {test_performance_df.shape}')\n",
    "\n",
    "# Remove missing odds data (Ignore data with no odds?)\n",
    "test_performance_df = test_performance_df[test_performance_df['D_start_odds'] != 0.0]\n",
    "\n",
    "print(f'df after missing odds removed: {df.shape}')\n",
    "print(f'df perf after missing odds removed: {test_performance_df.shape}')\n",
    "\n",
    "# Load the UMAP\n",
    "filename = \"kick_punt_umap.sav\"\n",
    "umap_model = None\n",
    "try:\n",
    "    with open(filename, 'rb') as file:\n",
    "        umap_model = pickle.load(file)\n",
    "        print(type(umap_model))\n",
    "except EOFError:\n",
    "    print(\"The file is empty or corrupt. Please check its content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26c9e0",
   "metadata": {},
   "source": [
    "### Remove items w/ missing odds data, apply UMAP to performance set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593aec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 196)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove missing odds data\n",
    "test_performance_df = test_performance_df[test_performance_df['D_start_odds'] != 0.0]\n",
    "print(test_performance_df.shape)\n",
    "\n",
    "# ---- Apply UMAP to performance set ----\n",
    "# Fit standardScaler on the training set\n",
    "umap_columns = [\"D_kick_punt_returns_lng\", \"D_kick_punt_returns_rt\", \"D_kick_punt_returns_yds\"]\n",
    "umap_train_df = df[umap_columns]\n",
    "umap_scaler = StandardScaler().fit(umap_train_df)\n",
    "\n",
    "# Scale the test set\n",
    "scaled_return_game_df = umap_scaler.transform(test_performance_df[umap_columns])\n",
    "\n",
    "if umap_model is None:\n",
    "    print(\"UMAP not correctly loaded FIX NOW\")\n",
    "\n",
    "umap_embedding = umap_model.transform(scaled_return_game_df)\n",
    "print(umap_embedding.shape)\n",
    "\n",
    "# Create the two new columns, drop the 4\n",
    "test_performance_df['kick_punt_umap_dim_1'] = umap_embedding[:,0]\n",
    "test_performance_df['kick_punt_umap_dim_2'] = umap_embedding[:,1]\n",
    "\n",
    "test_performance_df.drop(umap_columns, axis=1, inplace=True)\n",
    "df.drop(umap_columns, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9bfcf9-0964-4ed7-8fcb-3512b324b220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>H_Q1</th>\n",
       "      <th>H_Q2</th>\n",
       "      <th>H_Q3</th>\n",
       "      <th>H_Q4</th>\n",
       "      <th>H_OT</th>\n",
       "      <th>H_Final</th>\n",
       "      <th>Visitor_Team</th>\n",
       "      <th>V_Q1</th>\n",
       "      <th>V_Q2</th>\n",
       "      <th>V_Q3</th>\n",
       "      <th>V_Q4</th>\n",
       "      <th>V_OT</th>\n",
       "      <th>V_Final</th>\n",
       "      <th>H_First_Downs</th>\n",
       "      <th>V_First_Downs</th>\n",
       "      <th>H_Rush</th>\n",
       "      <th>V_Rush</th>\n",
       "      <th>H_Yds</th>\n",
       "      <th>V_Yds</th>\n",
       "      <th>H_TDs</th>\n",
       "      <th>V_TDs</th>\n",
       "      <th>H_Cmp</th>\n",
       "      <th>V_Cmp</th>\n",
       "      <th>H_Att</th>\n",
       "      <th>V_Att</th>\n",
       "      <th>H_Yd</th>\n",
       "      <th>V_Yd</th>\n",
       "      <th>H_TD</th>\n",
       "      <th>V_TD</th>\n",
       "      <th>H_INT</th>\n",
       "      <th>V_INT</th>\n",
       "      <th>H_Sacked</th>\n",
       "      <th>V_Sacked</th>\n",
       "      <th>H_Sacked_Yards</th>\n",
       "      <th>V_Sacked_Yards</th>\n",
       "      <th>H_Net_Pass_Yards</th>\n",
       "      <th>V_Net_Pass_Yards</th>\n",
       "      <th>H_Total_Yards</th>\n",
       "      <th>V_Total_Yards</th>\n",
       "      <th>H_Fumbles</th>\n",
       "      <th>V_Fumbles</th>\n",
       "      <th>H_Lost</th>\n",
       "      <th>V_Lost</th>\n",
       "      <th>H_Turnovers</th>\n",
       "      <th>V_Turnovers</th>\n",
       "      <th>H_Penalties</th>\n",
       "      <th>V_Penalties</th>\n",
       "      <th>H_Penalties_Yards</th>\n",
       "      <th>V_Penalties_Yards</th>\n",
       "      <th>H_Third_Down_Conv</th>\n",
       "      <th>V_Third_Down_Conv</th>\n",
       "      <th>H_Fourth_Down_Conv</th>\n",
       "      <th>V_Fourth_Down_Conv</th>\n",
       "      <th>H_Time_of_Possession</th>\n",
       "      <th>V_Time_of_Possession</th>\n",
       "      <th>H_passing_att</th>\n",
       "      <th>H_passing_cmp</th>\n",
       "      <th>H_passing_int</th>\n",
       "      <th>H_passing_lng</th>\n",
       "      <th>H_passing_sk</th>\n",
       "      <th>H_passing_td</th>\n",
       "      <th>H_receiving_lng</th>\n",
       "      <th>H_rushing_att</th>\n",
       "      <th>H_rushing_lng</th>\n",
       "      <th>H_rushing_td</th>\n",
       "      <th>H_rushing_yds</th>\n",
       "      <th>V_passing_att</th>\n",
       "      <th>V_passing_cmp</th>\n",
       "      <th>V_passing_int</th>\n",
       "      <th>V_passing_lng</th>\n",
       "      <th>V_passing_sk</th>\n",
       "      <th>V_passing_td</th>\n",
       "      <th>V_receiving_lng</th>\n",
       "      <th>V_rushing_att</th>\n",
       "      <th>V_rushing_lng</th>\n",
       "      <th>V_rushing_td</th>\n",
       "      <th>V_rushing_yds</th>\n",
       "      <th>H_def_interceptions_int</th>\n",
       "      <th>H_def_interceptions_td</th>\n",
       "      <th>H_def_interceptions_yds</th>\n",
       "      <th>H_fumbles_ff</th>\n",
       "      <th>H_fumbles_fr</th>\n",
       "      <th>H_fumbles_td</th>\n",
       "      <th>H_fumbles_yds</th>\n",
       "      <th>H_sk</th>\n",
       "      <th>H_tackles_ast</th>\n",
       "      <th>H_tackles_comb</th>\n",
       "      <th>H_tackles_solo</th>\n",
       "      <th>V_def_interceptions_int</th>\n",
       "      <th>V_def_interceptions_td</th>\n",
       "      <th>V_def_interceptions_yds</th>\n",
       "      <th>V_fumbles_ff</th>\n",
       "      <th>V_fumbles_fr</th>\n",
       "      <th>V_fumbles_td</th>\n",
       "      <th>V_fumbles_yds</th>\n",
       "      <th>V_sk</th>\n",
       "      <th>V_tackles_ast</th>\n",
       "      <th>V_tackles_comb</th>\n",
       "      <th>V_tackles_solo</th>\n",
       "      <th>H_punting_pnt</th>\n",
       "      <th>H_scoring_fga</th>\n",
       "      <th>H_scoring_xpa</th>\n",
       "      <th>V_punting_pnt</th>\n",
       "      <th>V_scoring_fga</th>\n",
       "      <th>V_scoring_xpa</th>\n",
       "      <th>H_halftime_odds</th>\n",
       "      <th>V_halftime_odds</th>\n",
       "      <th>H_start_odds</th>\n",
       "      <th>V_start_odds</th>\n",
       "      <th>H_Won</th>\n",
       "      <th>H_passing_rushing_td</th>\n",
       "      <th>V_passing_rushing_td</th>\n",
       "      <th>H_Final_Allowed</th>\n",
       "      <th>V_Final_Allowed</th>\n",
       "      <th>H_kick_punt_returns_lng</th>\n",
       "      <th>H_kick_punt_returns_rt</th>\n",
       "      <th>H_kick_punt_returns_td</th>\n",
       "      <th>H_kick_punt_returns_yds</th>\n",
       "      <th>H_scoring_fgp</th>\n",
       "      <th>H_scoring_xpp</th>\n",
       "      <th>H_punting_avg</th>\n",
       "      <th>V_kick_punt_returns_lng</th>\n",
       "      <th>V_kick_punt_returns_rt</th>\n",
       "      <th>V_kick_punt_returns_td</th>\n",
       "      <th>V_kick_punt_returns_yds</th>\n",
       "      <th>V_scoring_fgp</th>\n",
       "      <th>V_scoring_xpp</th>\n",
       "      <th>V_punting_avg</th>\n",
       "      <th>H_pythagorean</th>\n",
       "      <th>V_pythagorean</th>\n",
       "      <th>H_datediff</th>\n",
       "      <th>V_datediff</th>\n",
       "      <th>D_First_Downs</th>\n",
       "      <th>D_Rush</th>\n",
       "      <th>D_Yds</th>\n",
       "      <th>D_TDs</th>\n",
       "      <th>D_Cmp</th>\n",
       "      <th>D_Att</th>\n",
       "      <th>D_Yd</th>\n",
       "      <th>D_TD</th>\n",
       "      <th>D_INT</th>\n",
       "      <th>D_Sacked</th>\n",
       "      <th>D_Sacked_Yards</th>\n",
       "      <th>D_Net_Pass_Yards</th>\n",
       "      <th>D_Total_Yards</th>\n",
       "      <th>D_Fumbles</th>\n",
       "      <th>D_Lost</th>\n",
       "      <th>D_Turnovers</th>\n",
       "      <th>D_Penalties</th>\n",
       "      <th>D_Third_Down_Conv</th>\n",
       "      <th>D_Fourth_Down_Conv</th>\n",
       "      <th>D_Time_of_Possession</th>\n",
       "      <th>D_passing_att</th>\n",
       "      <th>D_passing_cmp</th>\n",
       "      <th>D_passing_int</th>\n",
       "      <th>D_passing_lng</th>\n",
       "      <th>D_passing_sk</th>\n",
       "      <th>D_passing_td</th>\n",
       "      <th>D_receiving_lng</th>\n",
       "      <th>D_rushing_att</th>\n",
       "      <th>D_rushing_lng</th>\n",
       "      <th>D_rushing_td</th>\n",
       "      <th>D_rushing_yds</th>\n",
       "      <th>D_passing_rushing_td</th>\n",
       "      <th>D_def_interceptions_int</th>\n",
       "      <th>D_def_interceptions_td</th>\n",
       "      <th>D_def_interceptions_yds</th>\n",
       "      <th>D_fumbles_ff</th>\n",
       "      <th>D_fumbles_fr</th>\n",
       "      <th>D_fumbles_td</th>\n",
       "      <th>D_fumbles_yds</th>\n",
       "      <th>D_sk</th>\n",
       "      <th>D_tackles_ast</th>\n",
       "      <th>D_tackles_comb</th>\n",
       "      <th>D_tackles_solo</th>\n",
       "      <th>D_punting_pnt</th>\n",
       "      <th>D_punting_avg</th>\n",
       "      <th>D_scoring_fga</th>\n",
       "      <th>D_scoring_fgp</th>\n",
       "      <th>D_scoring_xpa</th>\n",
       "      <th>D_scoring_xpp</th>\n",
       "      <th>D_Final</th>\n",
       "      <th>D_Final_Allowed</th>\n",
       "      <th>D_start_odds</th>\n",
       "      <th>D_halftime_odds</th>\n",
       "      <th>D_datediff</th>\n",
       "      <th>D_pythagorean</th>\n",
       "      <th>kick_punt_umap_dim_1</th>\n",
       "      <th>kick_punt_umap_dim_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>7645</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024-02-11</td>\n",
       "      <td>SFO</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>26.327756</td>\n",
       "      <td>KAN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23.565749</td>\n",
       "      <td>21.681889</td>\n",
       "      <td>20.03471</td>\n",
       "      <td>85.286041</td>\n",
       "      <td>53.241765</td>\n",
       "      <td>16.837382</td>\n",
       "      <td>12.335741</td>\n",
       "      <td>37.022830</td>\n",
       "      <td>94.260273</td>\n",
       "      <td>27.544142</td>\n",
       "      <td>24.595582</td>\n",
       "      <td>86.247511</td>\n",
       "      <td>122.984985</td>\n",
       "      <td>13.874851</td>\n",
       "      <td>9.667066</td>\n",
       "      <td>185.654186</td>\n",
       "      <td>127.621534</td>\n",
       "      <td>0.909679</td>\n",
       "      <td>0.553025</td>\n",
       "      <td>6.131457</td>\n",
       "      <td>7.571339</td>\n",
       "      <td>10.101820</td>\n",
       "      <td>2.341893</td>\n",
       "      <td>248.115479</td>\n",
       "      <td>222.061301</td>\n",
       "      <td>383.994236</td>\n",
       "      <td>355.447188</td>\n",
       "      <td>0.294323</td>\n",
       "      <td>1.014176</td>\n",
       "      <td>0.790133</td>\n",
       "      <td>1.558539</td>\n",
       "      <td>0.961939</td>\n",
       "      <td>1.105717</td>\n",
       "      <td>14.763529</td>\n",
       "      <td>20.107144</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>52.691158</td>\n",
       "      <td>30.340287</td>\n",
       "      <td>29.509262</td>\n",
       "      <td>50.474282</td>\n",
       "      <td>30.114245</td>\n",
       "      <td>27.015743</td>\n",
       "      <td>32.249467</td>\n",
       "      <td>20.685092</td>\n",
       "      <td>0.681074</td>\n",
       "      <td>47.279149</td>\n",
       "      <td>1.911462</td>\n",
       "      <td>1.682720</td>\n",
       "      <td>126.607746</td>\n",
       "      <td>27.457345</td>\n",
       "      <td>53.970660</td>\n",
       "      <td>1.610792</td>\n",
       "      <td>135.878758</td>\n",
       "      <td>31.169328</td>\n",
       "      <td>19.743665</td>\n",
       "      <td>0.297006</td>\n",
       "      <td>39.073186</td>\n",
       "      <td>0.692465</td>\n",
       "      <td>1.333246</td>\n",
       "      <td>118.436566</td>\n",
       "      <td>26.637019</td>\n",
       "      <td>59.475233</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>133.385887</td>\n",
       "      <td>1.405798</td>\n",
       "      <td>0.079550</td>\n",
       "      <td>15.406524</td>\n",
       "      <td>0.595246</td>\n",
       "      <td>0.497786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510743</td>\n",
       "      <td>1.844116</td>\n",
       "      <td>19.448767</td>\n",
       "      <td>60.306976</td>\n",
       "      <td>40.858210</td>\n",
       "      <td>0.296697</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.60054</td>\n",
       "      <td>1.163285</td>\n",
       "      <td>1.28807</td>\n",
       "      <td>0.146419</td>\n",
       "      <td>14.120897</td>\n",
       "      <td>1.788186</td>\n",
       "      <td>24.397286</td>\n",
       "      <td>69.009875</td>\n",
       "      <td>44.612589</td>\n",
       "      <td>3.068265</td>\n",
       "      <td>1.364111</td>\n",
       "      <td>3.373062</td>\n",
       "      <td>2.562885</td>\n",
       "      <td>2.77236</td>\n",
       "      <td>2.204331</td>\n",
       "      <td>1.301111</td>\n",
       "      <td>3.472222</td>\n",
       "      <td>1.757009</td>\n",
       "      <td>2.028809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.293512</td>\n",
       "      <td>2.06911</td>\n",
       "      <td>20.177794</td>\n",
       "      <td>17.018386</td>\n",
       "      <td>28.075001</td>\n",
       "      <td>2.839997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.038545</td>\n",
       "      <td>0.560247</td>\n",
       "      <td>0.937146</td>\n",
       "      <td>46.622098</td>\n",
       "      <td>22.023097</td>\n",
       "      <td>2.8641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.796869</td>\n",
       "      <td>0.935373</td>\n",
       "      <td>0.998549</td>\n",
       "      <td>47.624768</td>\n",
       "      <td>0.756792</td>\n",
       "      <td>0.652535</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.647</td>\n",
       "      <td>32.044</td>\n",
       "      <td>4.502</td>\n",
       "      <td>-57.237</td>\n",
       "      <td>2.949</td>\n",
       "      <td>-36.737</td>\n",
       "      <td>4.208</td>\n",
       "      <td>58.033</td>\n",
       "      <td>0.357</td>\n",
       "      <td>-1.440</td>\n",
       "      <td>7.760</td>\n",
       "      <td>26.054</td>\n",
       "      <td>28.547</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.768</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-5.344</td>\n",
       "      <td>22.351</td>\n",
       "      <td>-20.965</td>\n",
       "      <td>3.099</td>\n",
       "      <td>1.080</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.384</td>\n",
       "      <td>8.206</td>\n",
       "      <td>1.219</td>\n",
       "      <td>0.349</td>\n",
       "      <td>8.171</td>\n",
       "      <td>0.820</td>\n",
       "      <td>-5.505</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2.493</td>\n",
       "      <td>1.224</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.080</td>\n",
       "      <td>14.806</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-13.610</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-4.949</td>\n",
       "      <td>-8.703</td>\n",
       "      <td>-3.754</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-1.003</td>\n",
       "      <td>-1.408</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>1.169</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>2.762</td>\n",
       "      <td>3.159</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-2.171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>7.202415</td>\n",
       "      <td>4.370455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>7808</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>SFO</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>26.393382</td>\n",
       "      <td>SEA</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26.288000</td>\n",
       "      <td>21.977941</td>\n",
       "      <td>26.93600</td>\n",
       "      <td>53.808824</td>\n",
       "      <td>47.320000</td>\n",
       "      <td>18.643382</td>\n",
       "      <td>13.992000</td>\n",
       "      <td>51.834559</td>\n",
       "      <td>73.952000</td>\n",
       "      <td>28.283088</td>\n",
       "      <td>36.704000</td>\n",
       "      <td>133.948529</td>\n",
       "      <td>205.088000</td>\n",
       "      <td>8.944853</td>\n",
       "      <td>10.528000</td>\n",
       "      <td>166.753676</td>\n",
       "      <td>117.784000</td>\n",
       "      <td>1.066176</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>13.253676</td>\n",
       "      <td>13.968000</td>\n",
       "      <td>4.779412</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>280.044118</td>\n",
       "      <td>297.056000</td>\n",
       "      <td>420.577206</td>\n",
       "      <td>412.416000</td>\n",
       "      <td>2.066176</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.525735</td>\n",
       "      <td>1.712000</td>\n",
       "      <td>12.775735</td>\n",
       "      <td>37.424000</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>47.675854</td>\n",
       "      <td>40.465455</td>\n",
       "      <td>33.088235</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>32.742647</td>\n",
       "      <td>31.264000</td>\n",
       "      <td>29.514706</td>\n",
       "      <td>19.477941</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>41.738971</td>\n",
       "      <td>2.025735</td>\n",
       "      <td>1.452206</td>\n",
       "      <td>143.941176</td>\n",
       "      <td>31.988971</td>\n",
       "      <td>37.297794</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>140.533088</td>\n",
       "      <td>42.296000</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>1.096000</td>\n",
       "      <td>43.184000</td>\n",
       "      <td>2.784000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>139.904000</td>\n",
       "      <td>22.984000</td>\n",
       "      <td>40.960000</td>\n",
       "      <td>2.256000</td>\n",
       "      <td>115.360000</td>\n",
       "      <td>0.724265</td>\n",
       "      <td>0.459559</td>\n",
       "      <td>24.816176</td>\n",
       "      <td>2.268382</td>\n",
       "      <td>2.433824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.919118</td>\n",
       "      <td>4.345588</td>\n",
       "      <td>21.841912</td>\n",
       "      <td>58.941176</td>\n",
       "      <td>37.099265</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>1.056000</td>\n",
       "      <td>0.45600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.504000</td>\n",
       "      <td>22.752000</td>\n",
       "      <td>63.640000</td>\n",
       "      <td>40.888000</td>\n",
       "      <td>2.360294</td>\n",
       "      <td>2.691176</td>\n",
       "      <td>2.735294</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.74400</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>1.056667</td>\n",
       "      <td>9.383333</td>\n",
       "      <td>1.461897</td>\n",
       "      <td>2.642566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.275735</td>\n",
       "      <td>3.25600</td>\n",
       "      <td>19.110294</td>\n",
       "      <td>24.720000</td>\n",
       "      <td>17.319853</td>\n",
       "      <td>2.643382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.367647</td>\n",
       "      <td>0.862132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.728554</td>\n",
       "      <td>35.560000</td>\n",
       "      <td>3.8560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.680000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.591733</td>\n",
       "      <td>0.631902</td>\n",
       "      <td>0.606376</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.958</td>\n",
       "      <td>6.489</td>\n",
       "      <td>4.651</td>\n",
       "      <td>-22.117</td>\n",
       "      <td>-8.421</td>\n",
       "      <td>-71.139</td>\n",
       "      <td>-1.583</td>\n",
       "      <td>48.970</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-4.221</td>\n",
       "      <td>-17.012</td>\n",
       "      <td>8.161</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-24.648</td>\n",
       "      <td>7.210</td>\n",
       "      <td>5.888</td>\n",
       "      <td>1.479</td>\n",
       "      <td>-12.781</td>\n",
       "      <td>-10.602</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>-1.445</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>0.452</td>\n",
       "      <td>4.037</td>\n",
       "      <td>9.005</td>\n",
       "      <td>-3.662</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>25.173</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.460</td>\n",
       "      <td>23.952</td>\n",
       "      <td>1.212</td>\n",
       "      <td>1.978</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.842</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-4.699</td>\n",
       "      <td>-3.789</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-5.610</td>\n",
       "      <td>-1.181</td>\n",
       "      <td>-8.327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-2.466227</td>\n",
       "      <td>7.205903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>7940</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>JAX</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.786765</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>20.496000</td>\n",
       "      <td>17.716912</td>\n",
       "      <td>17.57600</td>\n",
       "      <td>38.977941</td>\n",
       "      <td>87.728000</td>\n",
       "      <td>3.573529</td>\n",
       "      <td>16.096000</td>\n",
       "      <td>88.261029</td>\n",
       "      <td>47.600000</td>\n",
       "      <td>22.257353</td>\n",
       "      <td>29.744000</td>\n",
       "      <td>148.893382</td>\n",
       "      <td>112.392000</td>\n",
       "      <td>2.591912</td>\n",
       "      <td>10.592000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>92.872000</td>\n",
       "      <td>2.121324</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>4.452206</td>\n",
       "      <td>15.336000</td>\n",
       "      <td>5.187500</td>\n",
       "      <td>16.536000</td>\n",
       "      <td>157.988971</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>289.683824</td>\n",
       "      <td>261.888000</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.459559</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.650735</td>\n",
       "      <td>1.224000</td>\n",
       "      <td>22.025735</td>\n",
       "      <td>30.656000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>27.060709</td>\n",
       "      <td>32.024477</td>\n",
       "      <td>13.786765</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>26.386029</td>\n",
       "      <td>29.464000</td>\n",
       "      <td>34.897059</td>\n",
       "      <td>18.948529</td>\n",
       "      <td>0.275735</td>\n",
       "      <td>37.702206</td>\n",
       "      <td>2.797794</td>\n",
       "      <td>1.294118</td>\n",
       "      <td>88.474265</td>\n",
       "      <td>21.772059</td>\n",
       "      <td>69.084559</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>131.694853</td>\n",
       "      <td>33.272000</td>\n",
       "      <td>21.056000</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>28.776000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>44.712000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>95.888000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165441</td>\n",
       "      <td>1.183824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.547794</td>\n",
       "      <td>23.930147</td>\n",
       "      <td>67.474265</td>\n",
       "      <td>43.544118</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>0.216</td>\n",
       "      <td>11.71200</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.59200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>21.440000</td>\n",
       "      <td>62.368000</td>\n",
       "      <td>40.928000</td>\n",
       "      <td>3.941176</td>\n",
       "      <td>1.790441</td>\n",
       "      <td>1.558824</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.491667</td>\n",
       "      <td>1.198333</td>\n",
       "      <td>1.790476</td>\n",
       "      <td>1.986097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.558824</td>\n",
       "      <td>1.82400</td>\n",
       "      <td>28.952206</td>\n",
       "      <td>18.648000</td>\n",
       "      <td>23.301471</td>\n",
       "      <td>3.202206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.371324</td>\n",
       "      <td>0.944853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.029412</td>\n",
       "      <td>35.256000</td>\n",
       "      <td>3.4640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.040000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.856000</td>\n",
       "      <td>0.195463</td>\n",
       "      <td>0.515588</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-48.750</td>\n",
       "      <td>-12.522</td>\n",
       "      <td>40.661</td>\n",
       "      <td>-7.487</td>\n",
       "      <td>36.501</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>-25.872</td>\n",
       "      <td>1.977</td>\n",
       "      <td>-10.884</td>\n",
       "      <td>-11.349</td>\n",
       "      <td>-8.011</td>\n",
       "      <td>27.796</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.573</td>\n",
       "      <td>-8.630</td>\n",
       "      <td>-4.964</td>\n",
       "      <td>-34.213</td>\n",
       "      <td>-3.078</td>\n",
       "      <td>1.625</td>\n",
       "      <td>-2.107</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>8.926</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.474</td>\n",
       "      <td>-4.068</td>\n",
       "      <td>24.373</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>35.807</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-11.712</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>2.490</td>\n",
       "      <td>5.106</td>\n",
       "      <td>2.616</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>3.173</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.709</td>\n",
       "      <td>10.304</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>3.293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-0.674538</td>\n",
       "      <td>7.954360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>7945</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>ARI</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.580882</td>\n",
       "      <td>GNB</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.368000</td>\n",
       "      <td>18.257353</td>\n",
       "      <td>20.28000</td>\n",
       "      <td>162.077206</td>\n",
       "      <td>81.576000</td>\n",
       "      <td>26.386029</td>\n",
       "      <td>15.688000</td>\n",
       "      <td>13.529412</td>\n",
       "      <td>39.024000</td>\n",
       "      <td>26.680147</td>\n",
       "      <td>22.888000</td>\n",
       "      <td>17.091912</td>\n",
       "      <td>105.984000</td>\n",
       "      <td>15.955882</td>\n",
       "      <td>14.744000</td>\n",
       "      <td>168.625000</td>\n",
       "      <td>188.672000</td>\n",
       "      <td>0.474265</td>\n",
       "      <td>2.112000</td>\n",
       "      <td>7.952206</td>\n",
       "      <td>10.416000</td>\n",
       "      <td>15.860294</td>\n",
       "      <td>6.352000</td>\n",
       "      <td>165.172794</td>\n",
       "      <td>268.984000</td>\n",
       "      <td>320.110294</td>\n",
       "      <td>421.296000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>1.016000</td>\n",
       "      <td>0.724265</td>\n",
       "      <td>1.216000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>46.452206</td>\n",
       "      <td>29.440000</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>35.648053</td>\n",
       "      <td>36.266259</td>\n",
       "      <td>30.637255</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>27.125000</td>\n",
       "      <td>30.072000</td>\n",
       "      <td>26.036765</td>\n",
       "      <td>18.040441</td>\n",
       "      <td>0.275735</td>\n",
       "      <td>30.139706</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>1.330882</td>\n",
       "      <td>88.172794</td>\n",
       "      <td>28.768382</td>\n",
       "      <td>55.176471</td>\n",
       "      <td>0.724265</td>\n",
       "      <td>154.937500</td>\n",
       "      <td>35.736000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>1.416000</td>\n",
       "      <td>46.416000</td>\n",
       "      <td>1.552000</td>\n",
       "      <td>2.416000</td>\n",
       "      <td>144.824000</td>\n",
       "      <td>28.648000</td>\n",
       "      <td>60.008000</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>152.312000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.757353</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>1.349265</td>\n",
       "      <td>0.165441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.577206</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>74.805147</td>\n",
       "      <td>43.055147</td>\n",
       "      <td>1.744000</td>\n",
       "      <td>0.240</td>\n",
       "      <td>18.48000</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>1.47200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.296000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>63.032000</td>\n",
       "      <td>41.832000</td>\n",
       "      <td>3.580882</td>\n",
       "      <td>1.080882</td>\n",
       "      <td>2.220588</td>\n",
       "      <td>3.264000</td>\n",
       "      <td>2.96000</td>\n",
       "      <td>2.496000</td>\n",
       "      <td>12.958333</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>3.043214</td>\n",
       "      <td>1.362319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.055147</td>\n",
       "      <td>2.87200</td>\n",
       "      <td>29.845588</td>\n",
       "      <td>24.544000</td>\n",
       "      <td>37.617647</td>\n",
       "      <td>3.485294</td>\n",
       "      <td>0.099265</td>\n",
       "      <td>79.349265</td>\n",
       "      <td>0.540441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.194853</td>\n",
       "      <td>8.464000</td>\n",
       "      <td>1.2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.184000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.376000</td>\n",
       "      <td>0.441557</td>\n",
       "      <td>0.591251</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.023</td>\n",
       "      <td>80.501</td>\n",
       "      <td>10.698</td>\n",
       "      <td>-25.495</td>\n",
       "      <td>3.792</td>\n",
       "      <td>-88.892</td>\n",
       "      <td>1.212</td>\n",
       "      <td>-20.047</td>\n",
       "      <td>-1.638</td>\n",
       "      <td>-2.464</td>\n",
       "      <td>9.508</td>\n",
       "      <td>-103.811</td>\n",
       "      <td>-101.186</td>\n",
       "      <td>-0.751</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>17.012</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>9.037</td>\n",
       "      <td>-2.947</td>\n",
       "      <td>-9.699</td>\n",
       "      <td>-3.280</td>\n",
       "      <td>-1.140</td>\n",
       "      <td>-16.276</td>\n",
       "      <td>1.124</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-56.651</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-4.832</td>\n",
       "      <td>0.268</td>\n",
       "      <td>2.625</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>-15.723</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>-1.719</td>\n",
       "      <td>10.550</td>\n",
       "      <td>11.773</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-1.879</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.787</td>\n",
       "      <td>5.302</td>\n",
       "      <td>1.681</td>\n",
       "      <td>11.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>11.330870</td>\n",
       "      <td>2.273398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>7948</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>CIN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>29.852941</td>\n",
       "      <td>NYG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.928000</td>\n",
       "      <td>23.569853</td>\n",
       "      <td>17.05600</td>\n",
       "      <td>64.540441</td>\n",
       "      <td>66.824000</td>\n",
       "      <td>8.022059</td>\n",
       "      <td>14.520000</td>\n",
       "      <td>96.257353</td>\n",
       "      <td>47.520000</td>\n",
       "      <td>22.639706</td>\n",
       "      <td>24.048000</td>\n",
       "      <td>149.852941</td>\n",
       "      <td>83.504000</td>\n",
       "      <td>10.540441</td>\n",
       "      <td>16.352000</td>\n",
       "      <td>128.595588</td>\n",
       "      <td>165.632000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>5.336000</td>\n",
       "      <td>4.632353</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>248.632353</td>\n",
       "      <td>226.576000</td>\n",
       "      <td>366.812500</td>\n",
       "      <td>298.416000</td>\n",
       "      <td>0.496324</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.363971</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.456000</td>\n",
       "      <td>15.312500</td>\n",
       "      <td>52.088000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>49.989716</td>\n",
       "      <td>34.957143</td>\n",
       "      <td>44.117647</td>\n",
       "      <td>68.400000</td>\n",
       "      <td>27.647059</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>33.558824</td>\n",
       "      <td>23.996324</td>\n",
       "      <td>0.459559</td>\n",
       "      <td>50.812500</td>\n",
       "      <td>1.345588</td>\n",
       "      <td>2.077206</td>\n",
       "      <td>128.503676</td>\n",
       "      <td>24.988971</td>\n",
       "      <td>36.360294</td>\n",
       "      <td>1.294118</td>\n",
       "      <td>118.180147</td>\n",
       "      <td>37.504000</td>\n",
       "      <td>24.416000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>31.752000</td>\n",
       "      <td>2.104000</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>105.120000</td>\n",
       "      <td>24.984000</td>\n",
       "      <td>29.888000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>71.840000</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.691176</td>\n",
       "      <td>0.540441</td>\n",
       "      <td>0.430147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.330882</td>\n",
       "      <td>0.981618</td>\n",
       "      <td>28.757353</td>\n",
       "      <td>68.415441</td>\n",
       "      <td>39.658088</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>1.55200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.184000</td>\n",
       "      <td>3.256000</td>\n",
       "      <td>19.912000</td>\n",
       "      <td>59.704000</td>\n",
       "      <td>39.792000</td>\n",
       "      <td>2.106618</td>\n",
       "      <td>2.507353</td>\n",
       "      <td>3.095588</td>\n",
       "      <td>3.664000</td>\n",
       "      <td>2.67200</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>1.236667</td>\n",
       "      <td>4.008333</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.758468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.371324</td>\n",
       "      <td>1.15200</td>\n",
       "      <td>27.397059</td>\n",
       "      <td>20.672000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>5.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.275735</td>\n",
       "      <td>0.908088</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>40.550858</td>\n",
       "      <td>40.224000</td>\n",
       "      <td>4.2560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.856000</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>46.213143</td>\n",
       "      <td>0.488497</td>\n",
       "      <td>0.310574</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.514</td>\n",
       "      <td>-2.284</td>\n",
       "      <td>-6.498</td>\n",
       "      <td>48.737</td>\n",
       "      <td>-1.408</td>\n",
       "      <td>66.349</td>\n",
       "      <td>-5.812</td>\n",
       "      <td>-37.036</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-3.086</td>\n",
       "      <td>-3.928</td>\n",
       "      <td>22.056</td>\n",
       "      <td>68.396</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>-36.776</td>\n",
       "      <td>15.033</td>\n",
       "      <td>-24.282</td>\n",
       "      <td>-4.353</td>\n",
       "      <td>-3.945</td>\n",
       "      <td>-0.420</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>19.060</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>1.309</td>\n",
       "      <td>23.384</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6.472</td>\n",
       "      <td>0.910</td>\n",
       "      <td>46.340</td>\n",
       "      <td>2.219</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.475</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-2.274</td>\n",
       "      <td>8.845</td>\n",
       "      <td>8.711</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>-5.662</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.292</td>\n",
       "      <td>2.232</td>\n",
       "      <td>0.677</td>\n",
       "      <td>14.925</td>\n",
       "      <td>6.725</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>-2.772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8.612288</td>\n",
       "      <td>5.388192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Season        Date Home_Team  H_Q1  H_Q2  H_Q3  H_Q4  H_OT  \\\n",
       "5305        7645    2023  2024-02-11       SFO     0    10     0     9     3   \n",
       "5306        7808    2024  2024-10-10       SFO     3    13     7    13     0   \n",
       "5307        7940    2024  2024-10-13       JAX     3     0     7     6     0   \n",
       "5308        7945    2024  2024-10-13       ARI     0    10     3     0     0   \n",
       "5309        7948    2024  2024-10-13       CIN     7     0     3     7     0   \n",
       "\n",
       "        H_Final Visitor_Team  V_Q1  V_Q2  V_Q3  V_Q4  V_OT    V_Final  \\\n",
       "5305  26.327756          KAN     0     3    10     6     6  23.565749   \n",
       "5306  26.393382          SEA     0     3    14     7     0  26.288000   \n",
       "5307  15.786765          CHI     0    14     7    14     0  20.496000   \n",
       "5308  19.580882          GNB     7    17     7     3     0  27.368000   \n",
       "5309  29.852941          NYG     0     0     7     0     0  14.928000   \n",
       "\n",
       "      H_First_Downs  V_First_Downs      H_Rush     V_Rush      H_Yds  \\\n",
       "5305      21.681889       20.03471   85.286041  53.241765  16.837382   \n",
       "5306      21.977941       26.93600   53.808824  47.320000  18.643382   \n",
       "5307      17.716912       17.57600   38.977941  87.728000   3.573529   \n",
       "5308      18.257353       20.28000  162.077206  81.576000  26.386029   \n",
       "5309      23.569853       17.05600   64.540441  66.824000   8.022059   \n",
       "\n",
       "          V_Yds      H_TDs      V_TDs      H_Cmp      V_Cmp       H_Att  \\\n",
       "5305  12.335741  37.022830  94.260273  27.544142  24.595582   86.247511   \n",
       "5306  13.992000  51.834559  73.952000  28.283088  36.704000  133.948529   \n",
       "5307  16.096000  88.261029  47.600000  22.257353  29.744000  148.893382   \n",
       "5308  15.688000  13.529412  39.024000  26.680147  22.888000   17.091912   \n",
       "5309  14.520000  96.257353  47.520000  22.639706  24.048000  149.852941   \n",
       "\n",
       "           V_Att       H_Yd       V_Yd        H_TD        V_TD     H_INT  \\\n",
       "5305  122.984985  13.874851   9.667066  185.654186  127.621534  0.909679   \n",
       "5306  205.088000   8.944853  10.528000  166.753676  117.784000  1.066176   \n",
       "5307  112.392000   2.591912  10.592000   67.000000   92.872000  2.121324   \n",
       "5308  105.984000  15.955882  14.744000  168.625000  188.672000  0.474265   \n",
       "5309   83.504000  10.540441  16.352000  128.595588  165.632000  1.250000   \n",
       "\n",
       "         V_INT   H_Sacked   V_Sacked  H_Sacked_Yards  V_Sacked_Yards  \\\n",
       "5305  0.553025   6.131457   7.571339       10.101820        2.341893   \n",
       "5306  2.040000  13.253676  13.968000        4.779412        9.000000   \n",
       "5307  0.144000   4.452206  15.336000        5.187500       16.536000   \n",
       "5308  2.112000   7.952206  10.416000       15.860294        6.352000   \n",
       "5309  1.312000   2.250000   5.336000        4.632353        8.560000   \n",
       "\n",
       "      H_Net_Pass_Yards  V_Net_Pass_Yards  H_Total_Yards  V_Total_Yards  \\\n",
       "5305        248.115479        222.061301     383.994236     355.447188   \n",
       "5306        280.044118        297.056000     420.577206     412.416000   \n",
       "5307        157.988971        166.000000     289.683824     261.888000   \n",
       "5308        165.172794        268.984000     320.110294     421.296000   \n",
       "5309        248.632353        226.576000     366.812500     298.416000   \n",
       "\n",
       "      H_Fumbles  V_Fumbles    H_Lost    V_Lost  H_Turnovers  V_Turnovers  \\\n",
       "5305   0.294323   1.014176  0.790133  1.558539     0.961939     1.105717   \n",
       "5306   2.066176   0.616000  0.955882  0.360000     1.525735     1.712000   \n",
       "5307   0.933824   0.856000  0.459559  0.360000     0.650735     1.224000   \n",
       "5308   0.264706   1.016000  0.724265  1.216000     1.000000     1.960000   \n",
       "5309   0.496324   1.080000  0.363971  0.480000     0.823529     1.456000   \n",
       "\n",
       "      H_Penalties  V_Penalties  H_Penalties_Yards  V_Penalties_Yards  \\\n",
       "5305    14.763529    20.107144                  6                 55   \n",
       "5306    12.775735    37.424000                  9                 69   \n",
       "5307    22.025735    30.656000                  2                 10   \n",
       "5308    46.452206    29.440000                  5                 40   \n",
       "5309    15.312500    52.088000                  2                  9   \n",
       "\n",
       "      H_Third_Down_Conv  V_Third_Down_Conv  H_Fourth_Down_Conv  \\\n",
       "5305          52.691158          30.340287           29.509262   \n",
       "5306          47.675854          40.465455           33.088235   \n",
       "5307          27.060709          32.024477           13.786765   \n",
       "5308          35.648053          36.266259           30.637255   \n",
       "5309          49.989716          34.957143           44.117647   \n",
       "\n",
       "      V_Fourth_Down_Conv  H_Time_of_Possession  V_Time_of_Possession  \\\n",
       "5305           50.474282             30.114245             27.015743   \n",
       "5306           27.200000             32.742647             31.264000   \n",
       "5307           48.000000             26.386029             29.464000   \n",
       "5308           21.600000             27.125000             30.072000   \n",
       "5309           68.400000             27.647059             32.000000   \n",
       "\n",
       "      H_passing_att  H_passing_cmp  H_passing_int  H_passing_lng  \\\n",
       "5305      32.249467      20.685092       0.681074      47.279149   \n",
       "5306      29.514706      19.477941       0.625000      41.738971   \n",
       "5307      34.897059      18.948529       0.275735      37.702206   \n",
       "5308      26.036765      18.040441       0.275735      30.139706   \n",
       "5309      33.558824      23.996324       0.459559      50.812500   \n",
       "\n",
       "      H_passing_sk  H_passing_td  H_receiving_lng  H_rushing_att  \\\n",
       "5305      1.911462      1.682720       126.607746      27.457345   \n",
       "5306      2.025735      1.452206       143.941176      31.988971   \n",
       "5307      2.797794      1.294118        88.474265      21.772059   \n",
       "5308      2.676471      1.330882        88.172794      28.768382   \n",
       "5309      1.345588      2.077206       128.503676      24.988971   \n",
       "\n",
       "      H_rushing_lng  H_rushing_td  H_rushing_yds  V_passing_att  \\\n",
       "5305      53.970660      1.610792     135.878758      31.169328   \n",
       "5306      37.297794      0.823529     140.533088      42.296000   \n",
       "5307      69.084559      0.264706     131.694853      33.272000   \n",
       "5308      55.176471      0.724265     154.937500      35.736000   \n",
       "5309      36.360294      1.294118     118.180147      37.504000   \n",
       "\n",
       "      V_passing_cmp  V_passing_int  V_passing_lng  V_passing_sk  V_passing_td  \\\n",
       "5305      19.743665       0.297006      39.073186      0.692465      1.333246   \n",
       "5306      30.080000       1.096000      43.184000      2.784000      1.000000   \n",
       "5307      21.056000       0.768000      28.776000      3.600000      0.880000   \n",
       "5308      21.320000       1.416000      46.416000      1.552000      2.416000   \n",
       "5309      24.416000       0.832000      31.752000      2.104000      0.768000   \n",
       "\n",
       "      V_receiving_lng  V_rushing_att  V_rushing_lng  V_rushing_td  \\\n",
       "5305       118.436566      26.637019      59.475233      0.735864   \n",
       "5306       139.904000      22.984000      40.960000      2.256000   \n",
       "5307        88.000000      25.840000      44.712000      0.944000   \n",
       "5308       144.824000      28.648000      60.008000      0.456000   \n",
       "5309       105.120000      24.984000      29.888000      0.384000   \n",
       "\n",
       "      V_rushing_yds  H_def_interceptions_int  H_def_interceptions_td  \\\n",
       "5305     133.385887                 1.405798                0.079550   \n",
       "5306     115.360000                 0.724265                0.459559   \n",
       "5307      95.888000                 0.000000                0.000000   \n",
       "5308     152.312000                 0.735294                0.000000   \n",
       "5309      71.840000                 0.790441                0.000000   \n",
       "\n",
       "      H_def_interceptions_yds  H_fumbles_ff  H_fumbles_fr  H_fumbles_td  \\\n",
       "5305                15.406524      0.595246      0.497786      0.000000   \n",
       "5306                24.816176      2.268382      2.433824      0.000000   \n",
       "5307                 0.000000      0.165441      1.183824      0.000000   \n",
       "5308                 2.757353      0.264706      1.349265      0.165441   \n",
       "5309                16.691176      0.540441      0.430147      0.000000   \n",
       "\n",
       "      H_fumbles_yds      H_sk  H_tackles_ast  H_tackles_comb  H_tackles_solo  \\\n",
       "5305       0.510743  1.844116      19.448767       60.306976       40.858210   \n",
       "5306      -0.919118  4.345588      21.841912       58.941176       37.099265   \n",
       "5307       0.000000  1.547794      23.930147       67.474265       43.544118   \n",
       "5308       0.000000  1.577206      31.750000       74.805147       43.055147   \n",
       "5309      -0.330882  0.981618      28.757353       68.415441       39.658088   \n",
       "\n",
       "      V_def_interceptions_int  V_def_interceptions_td  \\\n",
       "5305                 0.296697                   0.000   \n",
       "5306                 0.432000                   0.000   \n",
       "5307                 1.312000                   0.216   \n",
       "5308                 1.744000                   0.240   \n",
       "5309                 0.216000                   0.000   \n",
       "\n",
       "      V_def_interceptions_yds  V_fumbles_ff  V_fumbles_fr  V_fumbles_td  \\\n",
       "5305                  0.60054      1.163285       1.28807      0.146419   \n",
       "5306                  0.86400      1.056000       0.45600      0.000000   \n",
       "5307                 11.71200      0.760000       1.59200      0.000000   \n",
       "5308                 18.48000      0.784000       1.47200      0.000000   \n",
       "5309                  0.21600      0.856000       1.55200      0.000000   \n",
       "\n",
       "      V_fumbles_yds      V_sk  V_tackles_ast  V_tackles_comb  V_tackles_solo  \\\n",
       "5305      14.120897  1.788186      24.397286       69.009875       44.612589   \n",
       "5306       0.000000  3.504000      22.752000       63.640000       40.888000   \n",
       "5307       0.000000  2.520000      21.440000       62.368000       40.928000   \n",
       "5308       1.600000  3.296000      21.200000       63.032000       41.832000   \n",
       "5309      -0.184000  3.256000      19.912000       59.704000       39.792000   \n",
       "\n",
       "      H_punting_pnt  H_scoring_fga  H_scoring_xpa  V_punting_pnt  \\\n",
       "5305       3.068265       1.364111       3.373062       2.562885   \n",
       "5306       2.360294       2.691176       2.735294       3.960000   \n",
       "5307       3.941176       1.790441       1.558824       4.880000   \n",
       "5308       3.580882       1.080882       2.220588       3.264000   \n",
       "5309       2.106618       2.507353       3.095588       3.664000   \n",
       "\n",
       "      V_scoring_fga  V_scoring_xpa  H_halftime_odds  V_halftime_odds  \\\n",
       "5305        2.77236       2.204331         1.301111         3.472222   \n",
       "5306        1.74400       2.640000         1.056667         9.383333   \n",
       "5307        1.81600       1.800000         4.491667         1.198333   \n",
       "5308        2.96000       2.496000        12.958333         1.033333   \n",
       "5309        2.67200       0.864000         1.236667         4.008333   \n",
       "\n",
       "      H_start_odds  V_start_odds  H_Won  H_passing_rushing_td  \\\n",
       "5305      1.757009      2.028809    0.0              3.293512   \n",
       "5306      1.461897      2.642566    1.0              2.275735   \n",
       "5307      1.790476      1.986097    0.0              1.558824   \n",
       "5308      3.043214      1.362319    0.0              2.055147   \n",
       "5309      1.428571      2.758468    1.0              3.371324   \n",
       "\n",
       "      V_passing_rushing_td  H_Final_Allowed  V_Final_Allowed  \\\n",
       "5305               2.06911        20.177794        17.018386   \n",
       "5306               3.25600        19.110294        24.720000   \n",
       "5307               1.82400        28.952206        18.648000   \n",
       "5308               2.87200        29.845588        24.544000   \n",
       "5309               1.15200        27.397059        20.672000   \n",
       "\n",
       "      H_kick_punt_returns_lng  H_kick_punt_returns_rt  H_kick_punt_returns_td  \\\n",
       "5305                28.075001                2.839997                0.000000   \n",
       "5306                17.319853                2.643382                0.000000   \n",
       "5307                23.301471                3.202206                0.000000   \n",
       "5308                37.617647                3.485294                0.099265   \n",
       "5309                46.250000                5.029412                0.000000   \n",
       "\n",
       "      H_kick_punt_returns_yds  H_scoring_fgp  H_scoring_xpp  H_punting_avg  \\\n",
       "5305                42.038545       0.560247       0.937146      46.622098   \n",
       "5306                25.367647       0.862132       1.000000      46.728554   \n",
       "5307                44.371324       0.944853       1.000000      52.029412   \n",
       "5308                79.349265       0.540441       1.000000      50.194853   \n",
       "5309                97.275735       0.908088       0.917279      40.550858   \n",
       "\n",
       "      V_kick_punt_returns_lng  V_kick_punt_returns_rt  V_kick_punt_returns_td  \\\n",
       "5305                22.023097                  2.8641                     0.0   \n",
       "5306                35.560000                  3.8560                     0.0   \n",
       "5307                35.256000                  3.4640                     0.0   \n",
       "5308                 8.464000                  1.2400                     0.0   \n",
       "5309                40.224000                  4.2560                     0.0   \n",
       "\n",
       "      V_kick_punt_returns_yds  V_scoring_fgp  V_scoring_xpp  V_punting_avg  \\\n",
       "5305                39.796869       0.935373       0.998549      47.624768   \n",
       "5306                65.680000       0.480000       1.000000      47.591733   \n",
       "5307                60.040000       0.880000       1.000000      48.856000   \n",
       "5308                 9.184000       0.510000       1.000000      50.376000   \n",
       "5309                87.856000       0.616000       0.240000      46.213143   \n",
       "\n",
       "      H_pythagorean  V_pythagorean  H_datediff  V_datediff  D_First_Downs  \\\n",
       "5305       0.756792       0.652535        14.0        14.0          1.647   \n",
       "5306       0.631902       0.606376         4.0         4.0         -4.958   \n",
       "5307       0.195463       0.515588         7.0         7.0          0.141   \n",
       "5308       0.441557       0.591251         7.0         7.0         -2.023   \n",
       "5309       0.488497       0.310574         7.0         7.0          6.514   \n",
       "\n",
       "      D_Rush   D_Yds   D_TDs  D_Cmp   D_Att   D_Yd    D_TD  D_INT  D_Sacked  \\\n",
       "5305  32.044   4.502 -57.237  2.949 -36.737  4.208  58.033  0.357    -1.440   \n",
       "5306   6.489   4.651 -22.117 -8.421 -71.139 -1.583  48.970 -0.974    -0.714   \n",
       "5307 -48.750 -12.522  40.661 -7.487  36.501 -8.000 -25.872  1.977   -10.884   \n",
       "5308  80.501  10.698 -25.495  3.792 -88.892  1.212 -20.047 -1.638    -2.464   \n",
       "5309  -2.284  -6.498  48.737 -1.408  66.349 -5.812 -37.036 -0.062    -3.086   \n",
       "\n",
       "      D_Sacked_Yards  D_Net_Pass_Yards  D_Total_Yards  D_Fumbles  D_Lost  \\\n",
       "5305           7.760            26.054         28.547     -0.720  -0.768   \n",
       "5306          -4.221           -17.012          8.161      1.450   0.596   \n",
       "5307         -11.349            -8.011         27.796      0.078   0.100   \n",
       "5308           9.508          -103.811       -101.186     -0.751  -0.492   \n",
       "5309          -3.928            22.056         68.396     -0.584  -0.116   \n",
       "\n",
       "      D_Turnovers  D_Penalties  D_Third_Down_Conv  D_Fourth_Down_Conv  \\\n",
       "5305       -0.144       -5.344             22.351             -20.965   \n",
       "5306       -0.186      -24.648              7.210               5.888   \n",
       "5307       -0.573       -8.630             -4.964             -34.213   \n",
       "5308       -0.960       17.012             -0.618               9.037   \n",
       "5309       -0.632      -36.776             15.033             -24.282   \n",
       "\n",
       "      D_Time_of_Possession  D_passing_att  D_passing_cmp  D_passing_int  \\\n",
       "5305                 3.099          1.080          0.941          0.384   \n",
       "5306                 1.479        -12.781        -10.602         -0.471   \n",
       "5307                -3.078          1.625         -2.107         -0.492   \n",
       "5308                -2.947         -9.699         -3.280         -1.140   \n",
       "5309                -4.353         -3.945         -0.420         -0.372   \n",
       "\n",
       "      D_passing_lng  D_passing_sk  D_passing_td  D_receiving_lng  \\\n",
       "5305          8.206         1.219         0.349            8.171   \n",
       "5306         -1.445        -0.758         0.452            4.037   \n",
       "5307          8.926        -0.802         0.414            0.474   \n",
       "5308        -16.276         1.124        -1.085          -56.651   \n",
       "5309         19.060        -0.758         1.309           23.384   \n",
       "\n",
       "      D_rushing_att  D_rushing_lng  D_rushing_td  D_rushing_yds  \\\n",
       "5305          0.820         -5.505         0.875          2.493   \n",
       "5306          9.005         -3.662        -1.432         25.173   \n",
       "5307         -4.068         24.373        -0.679         35.807   \n",
       "5308          0.120         -4.832         0.268          2.625   \n",
       "5309          0.005          6.472         0.910         46.340   \n",
       "\n",
       "      D_passing_rushing_td  D_def_interceptions_int  D_def_interceptions_td  \\\n",
       "5305                 1.224                    1.109                   0.080   \n",
       "5306                -0.980                    0.292                   0.460   \n",
       "5307                -0.265                   -1.312                  -0.216   \n",
       "5308                -0.817                   -1.009                  -0.240   \n",
       "5309                 2.219                    0.574                   0.000   \n",
       "\n",
       "      D_def_interceptions_yds  D_fumbles_ff  D_fumbles_fr  D_fumbles_td  \\\n",
       "5305                   14.806        -0.568        -0.790        -0.146   \n",
       "5306                   23.952         1.212         1.978         0.000   \n",
       "5307                  -11.712        -0.595        -0.408         0.000   \n",
       "5308                  -15.723        -0.519        -0.123         0.165   \n",
       "5309                   16.475        -0.316        -1.122         0.000   \n",
       "\n",
       "      D_fumbles_yds   D_sk  D_tackles_ast  D_tackles_comb  D_tackles_solo  \\\n",
       "5305        -13.610  0.056         -4.949          -8.703          -3.754   \n",
       "5306         -0.919  0.842         -0.910          -4.699          -3.789   \n",
       "5307          0.000 -0.972          2.490           5.106           2.616   \n",
       "5308         -1.600 -1.719         10.550          11.773           1.223   \n",
       "5309         -0.147 -2.274          8.845           8.711          -0.134   \n",
       "\n",
       "      D_punting_pnt  D_punting_avg  D_scoring_fga  D_scoring_fgp  \\\n",
       "5305          0.505         -1.003         -1.408         -0.375   \n",
       "5306         -1.600         -0.863          0.947          0.382   \n",
       "5307         -0.939          3.173         -0.026          0.065   \n",
       "5308          0.317         -0.181         -1.879          0.030   \n",
       "5309         -1.557         -5.662         -0.165          0.292   \n",
       "\n",
       "      D_scoring_xpa  D_scoring_xpp  D_Final  D_Final_Allowed  D_start_odds  \\\n",
       "5305          1.169         -0.061    2.762            3.159        -0.272   \n",
       "5306          0.095          0.000    0.105           -5.610        -1.181   \n",
       "5307         -0.241          0.000   -4.709           10.304        -0.196   \n",
       "5308         -0.275          0.000   -7.787            5.302         1.681   \n",
       "5309          2.232          0.677   14.925            6.725        -1.330   \n",
       "\n",
       "      D_halftime_odds  D_datediff  D_pythagorean  kick_punt_umap_dim_1  \\\n",
       "5305           -2.171         0.0          0.104              7.202415   \n",
       "5306           -8.327         0.0          0.026             -2.466227   \n",
       "5307            3.293         0.0         -0.320             -0.674538   \n",
       "5308           11.925         0.0         -0.150             11.330870   \n",
       "5309           -2.772         0.0          0.178              8.612288   \n",
       "\n",
       "      kick_punt_umap_dim_2  \n",
       "5305              4.370455  \n",
       "5306              7.205903  \n",
       "5307              7.954360  \n",
       "5308              2.273398  \n",
       "5309              5.388192  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df[:5]\n",
    "# print(test_performance_df['H_start_odds'][:5])\n",
    "# print(test_performance_df['V_start_odds'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc250",
   "metadata": {},
   "source": [
    "# Columns to use\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db79ec",
   "metadata": {},
   "source": [
    "## 1. Separate continuous, categorical, and label column names\n",
    "\n",
    "Pretty much everything is continuous. \n",
    "\n",
    "Note: the y_col is what you're trying to predict\n",
    "\n",
    "## Feature engineering\n",
    "New Columns\n",
    "- **h_win**: Home team won\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3960b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5305, 193)\n",
      "(5305, 48)\n",
      "(188, 5)\n",
      "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
      "5500    0.0      1.724771      2.073398              0.0              0.0\n",
      "5501    0.0      4.991514      1.159063              0.0              0.0\n",
      "5502    1.0      4.513858      1.188369              0.0              0.0\n",
      "5503    0.0      3.804017      1.250000              0.0              0.0\n",
      "5504    0.0      1.790476      1.986097              0.0              0.0\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "\n",
    "cont_cols = [col for col in nfl_utils.cont_cols if col not in nfl_utils.drop_cols]\n",
    "\n",
    "\n",
    "y_col = ['H_Won'] # Old\n",
    "y_col = ['H_Won', 'H_start_odds', 'V_start_odds']\n",
    "y_col_perf = ['H_Won', 'H_start_odds', 'V_start_odds', 'H_halftime_odds', 'V_halftime_odds']\n",
    "\n",
    "\n",
    "# create cont_df and y_df from the df\n",
    "print(df.shape)\n",
    "cont_df = df[cont_cols]\n",
    "y_df = df[y_col]\n",
    "\n",
    "# test performance set\n",
    "perf_conts_df = test_performance_df[cont_cols]\n",
    "perf_y_df = test_performance_df[y_col_perf]\n",
    "perf_date_df = test_performance_df[['Date','Home_Team', 'Visitor_Team']]\n",
    "\n",
    "# print(cont_df.dtypes)\n",
    "print(cont_df.shape)\n",
    "print(perf_y_df.shape)\n",
    "print(perf_y_df.tail())\n",
    "# print(perf_conts_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a936f59-3205-422f-b760-7296518b2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_Won</th>\n",
       "      <th>H_start_odds</th>\n",
       "      <th>V_start_odds</th>\n",
       "      <th>H_halftime_odds</th>\n",
       "      <th>V_halftime_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.757009</td>\n",
       "      <td>2.028809</td>\n",
       "      <td>1.301111</td>\n",
       "      <td>3.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.461897</td>\n",
       "      <td>2.642566</td>\n",
       "      <td>1.056667</td>\n",
       "      <td>9.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790476</td>\n",
       "      <td>1.986097</td>\n",
       "      <td>4.491667</td>\n",
       "      <td>1.198333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.043214</td>\n",
       "      <td>1.362319</td>\n",
       "      <td>12.958333</td>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2.758468</td>\n",
       "      <td>1.236667</td>\n",
       "      <td>4.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
       "5305    0.0      1.757009      2.028809         1.301111         3.472222\n",
       "5306    1.0      1.461897      2.642566         1.056667         9.383333\n",
       "5307    0.0      1.790476      1.986097         4.491667         1.198333\n",
       "5308    0.0      3.043214      1.362319        12.958333         1.033333\n",
       "5309    1.0      1.428571      2.758468         1.236667         4.008333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_y_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05613417",
   "metadata": {},
   "source": [
    "#### 1a. Normalize cont_df\n",
    "StandardScaler is instead used by the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e76a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# cont_scaled = min_max_scaler.fit_transform(cont_df.values)\n",
    "# cont_df = pd.DataFrame(cont_scaled)\n",
    "# cont_df.head()\n",
    "\n",
    "# # test performance set\n",
    "# perf_conts_df_scaled = min_max_scaler.fit_transform(perf_conts_df.values)\n",
    "# perf_conts_df = pd.DataFrame(perf_conts_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1912ae",
   "metadata": {},
   "source": [
    "### 3. Create an array of continuous values\n",
    "Numpy array 'conts' containing stack of each continuous column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([cont_df[col].values for col in list(cont_df.columns)], 1)\n",
    "conts[:5]\n",
    "\n",
    "y_col = np.stack([y_df[col].values for col in y_col], 1)\n",
    "\n",
    "# test performance set\n",
    "perf_conts = np.stack([perf_conts_df[col].values for col in list(perf_conts_df.columns)], 1)\n",
    "perf_y_col = np.stack([perf_y_df[col].values for col in list(perf_y_df.columns)], 1)\n",
    "perf_date_col = np.stack([perf_date_df[col].values for col in list(perf_date_df.columns)], 1)\n",
    "\n",
    "\n",
    "conts_train = conts\n",
    "y_train = y_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2547a",
   "metadata": {},
   "source": [
    "### 4. Convert conts to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 48)\n",
      "(5108, 1)\n"
     ]
    }
   ],
   "source": [
    "print(conts.shape)\n",
    "print(y_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handled by model.fit()\n",
    "# conts = torch.tensor(conts, dtype=torch.float32)\n",
    "# y_col = torch.tensor(y_col, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875b494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TabularModelUpdated(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, criterion=nn.MSELoss(),\n",
    "                optimizer_class=torch.optim.Adam, lr=0.001, confidence_threshold=0.1):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Training params\n",
    "        self.criterion = criterion\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # BatchNorm layer for continuous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.Mish(),  # Mish instead of ReLU\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.Mish(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([\n",
    "            nn.Linear(self.layer_shape[-1], out_sz),\n",
    "            # nn.Sigmoid()  # Ensures output between 0 and 1\n",
    "        ])\n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        # Initialize the optimizer\n",
    "        self.optimizer = optimizer_class(self.parameters(), lr=self.lr)\n",
    "\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        # optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        # Training loop\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred = self.forward(X)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas > 0.5).astype(int)\n",
    "        # return probas\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X, torch.Tensor):\n",
    "                X = torch.FloatTensor(X)\n",
    "            return self(X).numpy()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Custom eval metric aiming to:\n",
    "            1. Apply kelly criterion to size bet with prediction confidence & ignore certain predictions\n",
    "            2. Penalize predictions that lie too close to the market's prediction (via pearson's correlation)\n",
    "            \n",
    "        \"\"\"\n",
    "        # Get prediction (0-1 where < 0.5 = visitor predicted win, otherwise home predicted win)\n",
    "        # convert this into prediciton probability\n",
    "        probas = self.predict_proba(X)\n",
    "        prediction_h_won = np.where(probas < 0.5, 0, 1)\n",
    "        x_won_probability = np.where(probas < 0.5, probas * 2, probas)\n",
    "\n",
    "        # Convert decimal odds to probabilities, get odds for y based on winning team\n",
    "        home_probs = 1 / np.array(y['H_start_odds'])\n",
    "        visitor_probs = 1 / np.array(y['V_start_odds'])\n",
    "        y_won_market_decimal_odds = np.where(y['H_Won'] == 1, y['H_start_odds'], y['V_start_odds'])\n",
    "        \n",
    "        # TODO: This needs a better name (from prediction, not y col)\n",
    "        predicted_y_won_probability = np.where(prediction_h_won == 1, home_probs, visitor_probs)\n",
    "\n",
    "\n",
    "        # 2. Kelly criterion (xwp is percent, y_won_market_odds is decimal)\n",
    "        bankroll_fraction = x_won_probability - ((1 - x_won_probability) / y_won_market_decimal_odds)\n",
    "        # 2a. Apply mask to filter out when kelly returns <= 0\n",
    "        mask = (bankroll_fraction > 0)\n",
    "        valid_mask = np.where(mask, bankroll_fraction, np.nan)\n",
    "        ~np.isnan(x_won_probability)\n",
    "        \n",
    "        # 2. Pearson correlation coefficient based on the model's predicted winner. 0 to 1\n",
    "        pearson_coefficient = np.absolute(r_regression(x_won_probability, predicted_y_won_probability))\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    def old_score(self, X, y):\n",
    "        \"\"\"\n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        # First apply confidence thresholding\n",
    "        mask = (probas < 0.5 - self.confidence_threshold) | (probas > 0.5 + self.confidence_threshold)\n",
    "        predictions = np.where(mask, (probas > 0.5).astype(np.int32), np.nan)\n",
    "\n",
    "        # Use numpy mask for nan values\n",
    "        valid_mask = ~np.isnan(predictions)\n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = y[valid_mask]\n",
    "        \n",
    "        # Penalize if < 80% predicted\n",
    "        if (1.0* len(valid_predictions) / len(X)) < 0.85:\n",
    "            # print(f\"mask {len(valid_predictions)}  pred {len(X)}\")\n",
    "            return 0.0\n",
    "\n",
    "        # Apply f1 score\n",
    "        score = f1_score(valid_predictions.flatten(), valid_targets)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b31ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- Suggest hyperparameters ---\n",
    "\n",
    "    criterion = trial.suggest_categorical('criterion', nfl_utils.map_losses(None).keys())\n",
    "    first_layer_size = trial.suggest_categorical('first_layer_size', [64, 56, 48, 32, 16, 12])\n",
    "    min_layers = math.floor(math.sqrt(first_layer_size))\n",
    "    num_layers = trial.suggest_int('num_layers', 2, min_layers)\n",
    "    confidence_threshold = trial.suggest_float('confidence_threshold', 0, 0.05)\n",
    "    layer_shape = [first_layer_size]\n",
    "    for i in range(1, num_layers):\n",
    "        layer_shape.append(first_layer_size//(2*i))\n",
    "    \n",
    "    # Set random state to have consistent results (42 is arbitrary)\n",
    "    set_all_seeds()\n",
    "    \n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Split once\n",
    "    X_train_fold = []\n",
    "    X_val = []\n",
    "    y_train_fold = []\n",
    "    y_val = []\n",
    "    models = []\n",
    "    for train_index, val_index in kf.split(conts_train):\n",
    "        # print(f\"train {train_index.shape} val {val_index.shape}\")\n",
    "        X_train_fold.append(torch.FloatTensor(conts_train[train_index]).to(device))\n",
    "        X_val.append(torch.FloatTensor(conts_train[val_index]).to(device))\n",
    "\n",
    "        y_train_fold.append(torch.FloatTensor(y_train[train_index]).to(device))\n",
    "        y_val.append(torch.FloatTensor(y_train[val_index]).to(device))\n",
    "\n",
    "        model = TabularModelUpdated(\n",
    "            n_cont=conts.shape[1],\n",
    "            out_sz=1,\n",
    "            layer_shape=layer_shape,\n",
    "            p=trial.suggest_float('dropout', 0.28, 0.38),     # Dropout\n",
    "            criterion=nfl_utils.map_losses(criterion),\n",
    "            optimizer_class=torch.optim.Adam,\n",
    "            lr=trial.suggest_float('lr', 1e-3, 1e-2, log=True),   # Learning rate \n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "            # ('regressor', LinearRegression()), # Apply a regression model\n",
    "            ('model', model)\n",
    "        ])\n",
    "        models.append(pipeline)\n",
    "\n",
    "    # Run once on each split, track average loss, stop if > max patience\n",
    "    max_patience = 10\n",
    "    current_patience = max_patience\n",
    "    tracked_loss = 0.0\n",
    "    n_epochs = 0\n",
    "    while current_patience > 0 or n_epochs < 100:\n",
    "        n_epochs = n_epochs + 1\n",
    "        running_loss = []\n",
    "        for i in range(0,n_splits):\n",
    "            # ----- Train -----\n",
    "            models[i].fit(X_train_fold[i], y_train_fold[i])\n",
    "\n",
    "            # ----- Eval -----\n",
    "            running_loss.append(models[i].score(X_val[i], y_val[i]))\n",
    "            # y_pred = models[i].predict(X_val[i])\n",
    "            # running_loss.append(f1_score(y_val[i], y_pred))\n",
    "        running_loss = np.mean(running_loss)\n",
    "\n",
    "        # ----- Current epoch loss > previous -----\n",
    "        # print(f\"{tracked_loss} {running_loss} {tracked_loss < running_loss}\")\n",
    "        if tracked_loss < running_loss:\n",
    "            current_patience = max_patience\n",
    "            tracked_loss = running_loss\n",
    "        else:\n",
    "            current_patience = current_patience - 1\n",
    "    trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "    trial.report(tracked_loss, n_epochs)\n",
    "    return tracked_loss\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value}\")\n",
    "    print(f\"Best trial so far: {study.best_trial.number}, value: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd663af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:11:20,641] A new study created in memory with name: no-name-571f9f4a-ad10-43d4-941e-6072fa33018e\n",
      "[I 2025-03-02 20:11:33,575] Trial 0 finished with value: 0.44086642419114536 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 2, 'confidence_threshold': 0.012538014874680786, 'dropout': 0.28124651361101594, 'lr': 0.004233958635390632, 'n_epochs': 144}. Best is trial 0 with value: 0.44086642419114536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.44086642419114536\n",
      "Best trial so far: 0, value: 0.44086642419114536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:11:49,850] Trial 1 finished with value: 0.14669276878833026 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 64, 'num_layers': 4, 'confidence_threshold': 0.0402354807109669, 'dropout': 0.3748113362797768, 'lr': 0.0018748937719715632, 'n_epochs': 108}. Best is trial 0 with value: 0.44086642419114536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.14669276878833026\n",
      "Best trial so far: 0, value: 0.44086642419114536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:12:22,688] Trial 2 finished with value: 0.17864277704927434 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.04123791171255932, 'dropout': 0.3221050103964721, 'lr': 0.003924833837605191, 'n_epochs': 131}. Best is trial 0 with value: 0.44086642419114536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.17864277704927434\n",
      "Best trial so far: 0, value: 0.44086642419114536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:12:40,339] Trial 3 finished with value: 0.22906006472038715 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.03810276610838044, 'dropout': 0.3585456768690177, 'lr': 0.006600846965325849, 'n_epochs': 133}. Best is trial 0 with value: 0.44086642419114536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.22906006472038715\n",
      "Best trial so far: 0, value: 0.44086642419114536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:13:10,403] Trial 4 finished with value: 0.4492335162014676 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.0025920919147729374, 'dropout': 0.3088799598507141, 'lr': 0.0030265919539351795, 'n_epochs': 256}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.4492335162014676\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:13:45,950] Trial 5 finished with value: 0.43584034412043104 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 3, 'confidence_threshold': 0.02659145387043349, 'dropout': 0.3622484468189097, 'lr': 0.002361676164249358, 'n_epochs': 238}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 finished with value: 0.43584034412043104\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:14:30,688] Trial 6 finished with value: 0.20206051681068407 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 64, 'num_layers': 8, 'confidence_threshold': 0.015489217519997428, 'dropout': 0.3682104422113942, 'lr': 0.008159296745660707, 'n_epochs': 137}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 finished with value: 0.20206051681068407\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:14:57,115] Trial 7 finished with value: 0.18094098833563277 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 6, 'confidence_threshold': 0.008388736052134955, 'dropout': 0.31406710975316576, 'lr': 0.0029815289553363133, 'n_epochs': 100}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 0.18094098833563277\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:15:07,057] Trial 8 finished with value: 0.05656938904052069 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.048330660624766125, 'dropout': 0.28509119273693345, 'lr': 0.005255791665106613, 'n_epochs': 100}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 0.05656938904052069\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:15:23,179] Trial 9 finished with value: 0.20192440578833049 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 56, 'num_layers': 2, 'confidence_threshold': 0.03871469735025729, 'dropout': 0.2833729436135273, 'lr': 0.0015769117514595574, 'n_epochs': 100}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 finished with value: 0.20192440578833049\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:15:32,680] Trial 10 finished with value: 0.1835349957607309 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.0018203422027876504, 'dropout': 0.34135964645827477, 'lr': 0.0010405980040501153, 'n_epochs': 100}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.1835349957607309\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:16:05,899] Trial 11 finished with value: 0.37825725290203543 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 3, 'confidence_threshold': 0.015305882796837233, 'dropout': 0.30395647037659, 'lr': 0.004385307740352614, 'n_epochs': 158}. Best is trial 4 with value: 0.4492335162014676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 finished with value: 0.37825725290203543\n",
      "Best trial so far: 4, value: 0.4492335162014676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:17:07,230] Trial 12 finished with value: 0.4750280328608329 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.0027956916095242482, 'dropout': 0.2980974260611646, 'lr': 0.0030030592298337226, 'n_epochs': 226}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 finished with value: 0.4750280328608329\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:17:35,671] Trial 13 finished with value: 0.44719126821196487 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.0006941994022723226, 'dropout': 0.30224798017803955, 'lr': 0.0027997707496816605, 'n_epochs': 259}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 finished with value: 0.44719126821196487\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:17:47,027] Trial 14 finished with value: 0.06153846153846153 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.023283489730655242, 'dropout': 0.3371695588150241, 'lr': 0.0018908342949241549, 'n_epochs': 100}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 finished with value: 0.06153846153846153\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:19:35,574] Trial 15 finished with value: 0.41847184847991653 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 5, 'confidence_threshold': 0.006254450739790132, 'dropout': 0.3044931034677944, 'lr': 0.0012929469543391597, 'n_epochs': 416}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 finished with value: 0.41847184847991653\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:20:49,740] Trial 16 finished with value: 0.46831392167319946 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 4, 'confidence_threshold': 0.02245571648620785, 'dropout': 0.295392440495444, 'lr': 0.0024508491734879733, 'n_epochs': 392}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 finished with value: 0.46831392167319946\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:22:02,081] Trial 17 finished with value: 0.44657681770939284 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 4, 'confidence_threshold': 0.02382111692777074, 'dropout': 0.28982415132662304, 'lr': 0.002202826983139876, 'n_epochs': 358}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 finished with value: 0.44657681770939284\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:22:54,906] Trial 18 finished with value: 0.39873577034668944 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 4, 'confidence_threshold': 0.030766194432183747, 'dropout': 0.2955716025071749, 'lr': 0.0034416850125260526, 'n_epochs': 208}. Best is trial 12 with value: 0.4750280328608329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 finished with value: 0.39873577034668944\n",
      "Best trial so far: 12, value: 0.4750280328608329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:23:30,510] Trial 19 finished with value: 0.5208894620152986 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.020749634948591347, 'dropout': 0.32284907012637715, 'lr': 0.005705207180564017, 'n_epochs': 105}. Best is trial 19 with value: 0.5208894620152986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 finished with value: 0.5208894620152986\n",
      "Best trial so far: 19, value: 0.5208894620152986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:24:10,891] Trial 20 finished with value: 0.21798738354629593 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 6, 'confidence_threshold': 0.03192928252028282, 'dropout': 0.32631962585835184, 'lr': 0.008930745151759088, 'n_epochs': 124}. Best is trial 19 with value: 0.5208894620152986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 finished with value: 0.21798738354629593\n",
      "Best trial so far: 19, value: 0.5208894620152986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:24:43,806] Trial 21 finished with value: 0.5217581070509718 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019294668599208645, 'dropout': 0.3441359998352749, 'lr': 0.005619928156933571, 'n_epochs': 108}. Best is trial 21 with value: 0.5217581070509718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 finished with value: 0.5217581070509718\n",
      "Best trial so far: 21, value: 0.5217581070509718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:25:18,906] Trial 22 finished with value: 0.5345812261878565 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018221406791835596, 'dropout': 0.3480881221958881, 'lr': 0.006338668664573213, 'n_epochs': 141}. Best is trial 22 with value: 0.5345812261878565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 finished with value: 0.5345812261878565\n",
      "Best trial so far: 22, value: 0.5345812261878565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:25:55,604] Trial 23 finished with value: 0.5330854136188135 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019104284072654392, 'dropout': 0.3488033018986125, 'lr': 0.0060539057646973125, 'n_epochs': 139}. Best is trial 22 with value: 0.5345812261878565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 finished with value: 0.5330854136188135\n",
      "Best trial so far: 22, value: 0.5345812261878565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:26:26,994] Trial 24 finished with value: 0.5271307084194301 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017988719621352792, 'dropout': 0.3494557203118667, 'lr': 0.007673463590571568, 'n_epochs': 107}. Best is trial 22 with value: 0.5345812261878565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 finished with value: 0.5271307084194301\n",
      "Best trial so far: 22, value: 0.5345812261878565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:26:58,978] Trial 25 finished with value: 0.5442432665007659 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013009590165302412, 'dropout': 0.35255654755246774, 'lr': 0.00999362999132362, 'n_epochs': 129}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 finished with value: 0.5442432665007659\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:27:37,888] Trial 26 finished with value: 0.5425215117872161 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.010526218097028719, 'dropout': 0.3526596698858023, 'lr': 0.009905731160071957, 'n_epochs': 127}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 finished with value: 0.5425215117872161\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:29:03,817] Trial 27 finished with value: 0.520325060173854 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 6, 'confidence_threshold': 0.009554117082146742, 'dropout': 0.356436107632526, 'lr': 0.009567140357306537, 'n_epochs': 213}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 finished with value: 0.520325060173854\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:29:33,492] Trial 28 finished with value: 0.4622932009466739 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011912873250040418, 'dropout': 0.37988837278879384, 'lr': 0.007204396538014173, 'n_epochs': 141}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 finished with value: 0.4622932009466739\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:29:53,910] Trial 29 finished with value: 0.5375364814615132 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012560860967721877, 'dropout': 0.336876647161318, 'lr': 0.009867797056711841, 'n_epochs': 105}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 finished with value: 0.5375364814615132\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:30:19,160] Trial 30 finished with value: 0.42733319868979136 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.0062288696295223775, 'dropout': 0.3337427081864729, 'lr': 0.009496630188755899, 'n_epochs': 110}. Best is trial 25 with value: 0.5442432665007659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 finished with value: 0.42733319868979136\n",
      "Best trial so far: 25, value: 0.5442432665007659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:30:47,300] Trial 31 finished with value: 0.5447023892659958 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013522637230083281, 'dropout': 0.35237719758650754, 'lr': 0.008229876111751157, 'n_epochs': 141}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 finished with value: 0.5447023892659958\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:31:13,823] Trial 32 finished with value: 0.5409087876514391 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012011469565219706, 'dropout': 0.36565428251060395, 'lr': 0.008303488570285015, 'n_epochs': 130}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32 finished with value: 0.5409087876514391\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:31:40,513] Trial 33 finished with value: 0.5432637587907233 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013656352336433008, 'dropout': 0.3683560817839425, 'lr': 0.008157357293084633, 'n_epochs': 132}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 finished with value: 0.5432637587907233\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:31:58,448] Trial 34 finished with value: 0.22521128745240365 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.014996904926786238, 'dropout': 0.372466141033779, 'lr': 0.00470516775405625, 'n_epochs': 158}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 finished with value: 0.22521128745240365\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:33:11,591] Trial 35 finished with value: 0.5218647773704517 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 6, 'confidence_threshold': 0.005600400709038329, 'dropout': 0.3553478339492994, 'lr': 0.0069167506792179485, 'n_epochs': 257}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 finished with value: 0.5218647773704517\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:34:28,887] Trial 36 finished with value: 0.43145768353337344 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.026862525993613228, 'dropout': 0.3604630457005797, 'lr': 0.008035665940876546, 'n_epochs': 232}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 finished with value: 0.43145768353337344\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:35:17,451] Trial 37 finished with value: 0.2034561124561384 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.00959094958016032, 'dropout': 0.37072698037182344, 'lr': 0.007242116692278496, 'n_epochs': 123}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 finished with value: 0.2034561124561384\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:35:49,124] Trial 38 finished with value: 0.5083847999877247 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.014107092068086018, 'dropout': 0.35228643843276114, 'lr': 0.008952332320956232, 'n_epochs': 157}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 finished with value: 0.5083847999877247\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:36:02,701] Trial 39 finished with value: 0.24176702038517767 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.008616012246913435, 'dropout': 0.36131327995780127, 'lr': 0.009966543756750395, 'n_epochs': 100}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 finished with value: 0.24176702038517767\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:36:27,841] Trial 40 finished with value: 0.509560567255426 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.004004678778955228, 'dropout': 0.3762609778235589, 'lr': 0.0049064009750550246, 'n_epochs': 100}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 finished with value: 0.509560567255426\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:36:56,176] Trial 41 finished with value: 0.5309853342320491 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011400908350246926, 'dropout': 0.3662472999640972, 'lr': 0.0082144301507876, 'n_epochs': 115}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 finished with value: 0.5309853342320491\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:37:29,508] Trial 42 finished with value: 0.5323728301943167 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01595815463071462, 'dropout': 0.3654713386185421, 'lr': 0.008413567507348573, 'n_epochs': 115}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42 finished with value: 0.5323728301943167\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:38:06,072] Trial 43 finished with value: 0.532111963723375 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012112663379830108, 'dropout': 0.3646495644220986, 'lr': 0.006549227668733951, 'n_epochs': 138}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 finished with value: 0.532111963723375\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:38:41,017] Trial 44 finished with value: 0.5098945347055511 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.010063810247794742, 'dropout': 0.3425356633054435, 'lr': 0.003689196439782237, 'n_epochs': 138}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 finished with value: 0.5098945347055511\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:39:01,367] Trial 45 finished with value: 0.4766392648192209 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.01603938397590339, 'dropout': 0.35795778685637736, 'lr': 0.0073138410861683135, 'n_epochs': 160}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 finished with value: 0.4766392648192209\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:39:43,600] Trial 46 finished with value: 0.4989745555585924 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.0067015446748333474, 'dropout': 0.35403906686628206, 'lr': 0.008692185721011114, 'n_epochs': 134}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 finished with value: 0.4989745555585924\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:40:13,562] Trial 47 finished with value: 0.46939013670389257 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.04890681742344082, 'dropout': 0.3685462067944855, 'lr': 0.008022781570125051, 'n_epochs': 141}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 finished with value: 0.46939013670389257\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:40:57,822] Trial 48 finished with value: 0.4860816283271845 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 6, 'confidence_threshold': 0.013575825461833444, 'dropout': 0.3133521792880026, 'lr': 0.006168453528998025, 'n_epochs': 159}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 finished with value: 0.4860816283271845\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:41:26,883] Trial 49 finished with value: 0.5000491616803303 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.004132433755054158, 'dropout': 0.37637225513247197, 'lr': 0.008918547587282912, 'n_epochs': 141}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 finished with value: 0.5000491616803303\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:41:35,797] Trial 50 finished with value: 0.06782586115633146 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.04261786027988901, 'dropout': 0.362312945081851, 'lr': 0.007572554206396768, 'n_epochs': 100}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 finished with value: 0.06782586115633146\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:41:58,342] Trial 51 finished with value: 0.5356736879523227 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012954227324345013, 'dropout': 0.33832181913490617, 'lr': 0.009681187000882115, 'n_epochs': 106}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 finished with value: 0.5356736879523227\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:42:19,225] Trial 52 finished with value: 0.5361981864718384 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016684027001110897, 'dropout': 0.3450190476895943, 'lr': 0.009937827520073063, 'n_epochs': 104}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52 finished with value: 0.5361981864718384\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:42:40,270] Trial 53 finished with value: 0.5291474601941898 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.007679205198350965, 'dropout': 0.3353329209008982, 'lr': 0.008766642644445448, 'n_epochs': 100}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 finished with value: 0.5291474601941898\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:43:22,726] Trial 54 finished with value: 0.5068848467885951 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.011406257801087026, 'dropout': 0.35281350859750843, 'lr': 0.007867651641631746, 'n_epochs': 217}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 finished with value: 0.5068848467885951\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:44:04,342] Trial 55 finished with value: 0.4870620785414559 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.013680698866905467, 'dropout': 0.33054650711078126, 'lr': 0.006797409481322367, 'n_epochs': 156}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 finished with value: 0.4870620785414559\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:44:45,526] Trial 56 finished with value: 0.4946244547553575 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.010910301898698328, 'dropout': 0.34022088231517716, 'lr': 0.005406196896212826, 'n_epochs': 265}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 finished with value: 0.4946244547553575\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:45:10,855] Trial 57 finished with value: 0.530034814171927 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.00012037540572523882, 'dropout': 0.34593792386124106, 'lr': 0.008866096015591013, 'n_epochs': 106}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 finished with value: 0.530034814171927\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:45:47,387] Trial 58 finished with value: 0.5054277881421012 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.017666164607652354, 'dropout': 0.350724803292639, 'lr': 0.009266560606897139, 'n_epochs': 144}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 finished with value: 0.5054277881421012\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:46:23,914] Trial 59 finished with value: 0.20470216402747768 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.027334532617615055, 'dropout': 0.3604688825315837, 'lr': 0.004087097959677493, 'n_epochs': 104}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 finished with value: 0.20470216402747768\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:46:50,776] Trial 60 finished with value: 0.39091207606816913 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.020211988421072, 'dropout': 0.37248054737743763, 'lr': 0.005903517058803573, 'n_epochs': 105}. Best is trial 31 with value: 0.5447023892659958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 finished with value: 0.39091207606816913\n",
      "Best trial so far: 31, value: 0.5447023892659958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:47:20,310] Trial 61 finished with value: 0.5490357263324551 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016013830242761637, 'dropout': 0.34560491055014947, 'lr': 0.009946989049667785, 'n_epochs': 131}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61 finished with value: 0.5490357263324551\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:47:46,619] Trial 62 finished with value: 0.5229490109331256 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014359839604650475, 'dropout': 0.33167477367611986, 'lr': 0.008078782412699652, 'n_epochs': 106}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62 finished with value: 0.5229490109331256\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:48:16,826] Trial 63 finished with value: 0.5490344297228079 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.007994629314780424, 'dropout': 0.3276017056372576, 'lr': 0.009927538283669478, 'n_epochs': 129}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63 finished with value: 0.5490344297228079\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:48:41,561] Trial 64 finished with value: 0.5207310211208191 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0075669396841491305, 'dropout': 0.3276410943977891, 'lr': 0.008475030823939555, 'n_epochs': 100}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 finished with value: 0.5207310211208191\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:49:08,508] Trial 65 finished with value: 0.2157649842013812 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.02125464932696013, 'dropout': 0.35801079080804105, 'lr': 0.00675515990840304, 'n_epochs': 135}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 finished with value: 0.2157649842013812\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:50:26,732] Trial 66 finished with value: 0.5078886268525451 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0049244482800479775, 'dropout': 0.345603470665297, 'lr': 0.0014269907897054815, 'n_epochs': 334}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 finished with value: 0.5078886268525451\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:50:52,460] Trial 67 finished with value: 0.5244184391142042 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0024279026802095614, 'dropout': 0.3181776247452799, 'lr': 0.0075067045750158694, 'n_epochs': 104}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 finished with value: 0.5244184391142042\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:51:13,598] Trial 68 finished with value: 0.46036771786858877 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 3, 'confidence_threshold': 0.008551114260269303, 'dropout': 0.32426586745112707, 'lr': 0.009990018732659624, 'n_epochs': 185}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 finished with value: 0.46036771786858877\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:51:40,541] Trial 69 finished with value: 0.21866581251334613 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 6, 'confidence_threshold': 0.024851548027074646, 'dropout': 0.34866654902724187, 'lr': 0.009006759749039582, 'n_epochs': 125}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 finished with value: 0.21866581251334613\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:52:19,377] Trial 70 finished with value: 0.518915151417939 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 4, 'confidence_threshold': 0.010238593928356104, 'dropout': 0.3799409005712647, 'lr': 0.009264096893257303, 'n_epochs': 199}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70 finished with value: 0.518915151417939\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:52:41,298] Trial 71 finished with value: 0.5270331720523951 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012392607469740793, 'dropout': 0.33958520420123456, 'lr': 0.008383454047461611, 'n_epochs': 105}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71 finished with value: 0.5270331720523951\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:53:03,070] Trial 72 finished with value: 0.5401556836022343 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014800799406284587, 'dropout': 0.3427620633127424, 'lr': 0.009999092328578353, 'n_epochs': 107}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72 finished with value: 0.5401556836022343\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:53:25,766] Trial 73 finished with value: 0.5324756925864823 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017040123039173568, 'dropout': 0.3554130287504983, 'lr': 0.009526926440138276, 'n_epochs': 106}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73 finished with value: 0.5324756925864823\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:54:08,017] Trial 74 finished with value: 0.4907172123652548 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 6, 'confidence_threshold': 0.015406394670575292, 'dropout': 0.3185778351716822, 'lr': 0.007116401856725978, 'n_epochs': 139}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74 finished with value: 0.4907172123652548\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:54:40,229] Trial 75 finished with value: 0.19008484925837058 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01842068496022208, 'dropout': 0.34148903310937123, 'lr': 0.0010314670655851665, 'n_epochs': 130}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75 finished with value: 0.19008484925837058\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:54:54,902] Trial 76 finished with value: 0.11761474196831904 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.00927630622484162, 'dropout': 0.3634023121148518, 'lr': 0.007771095715492792, 'n_epochs': 100}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76 finished with value: 0.11761474196831904\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:55:44,173] Trial 77 finished with value: 0.4071032595476577 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.006792136641655056, 'dropout': 0.33331125894717084, 'lr': 0.0019270145657663725, 'n_epochs': 200}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77 finished with value: 0.4071032595476577\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:56:18,833] Trial 78 finished with value: 0.5450515102321016 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014845289724448983, 'dropout': 0.36813615530174465, 'lr': 0.00928302712580938, 'n_epochs': 130}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78 finished with value: 0.5450515102321016\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:56:56,355] Trial 79 finished with value: 0.4980707163221191 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.02251800934116529, 'dropout': 0.3669921749899578, 'lr': 0.00838901877647702, 'n_epochs': 135}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79 finished with value: 0.4980707163221191\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:57:15,986] Trial 80 finished with value: 0.5404137981402382 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011201305689520442, 'dropout': 0.36904876229072836, 'lr': 0.009307470042979485, 'n_epochs': 105}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80 finished with value: 0.5404137981402382\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:57:36,870] Trial 81 finished with value: 0.5392701291480784 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01291931036441595, 'dropout': 0.36915626805826446, 'lr': 0.009118192814013742, 'n_epochs': 114}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81 finished with value: 0.5392701291480784\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:58:00,592] Trial 82 finished with value: 0.5402922907888452 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.010791784114206636, 'dropout': 0.37388589004885425, 'lr': 0.00938116899912744, 'n_epochs': 118}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 finished with value: 0.5402922907888452\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:58:27,301] Trial 83 finished with value: 0.5269540122998769 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.009043222761643214, 'dropout': 0.3587376933509253, 'lr': 0.007739380474085184, 'n_epochs': 116}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 finished with value: 0.5269540122998769\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:58:53,836] Trial 84 finished with value: 0.5360155157846125 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013774766411725859, 'dropout': 0.37032754734589884, 'lr': 0.008497817331752039, 'n_epochs': 116}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 finished with value: 0.5360155157846125\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 20:59:43,536] Trial 85 finished with value: 0.5186527246909498 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019272405108856795, 'dropout': 0.37581796491332653, 'lr': 0.002572132562966447, 'n_epochs': 220}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85 finished with value: 0.5186527246909498\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:00:34,212] Trial 86 finished with value: 0.514552540857332 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.01595616023524207, 'dropout': 0.3647417977247631, 'lr': 0.006391427637709884, 'n_epochs': 279}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86 finished with value: 0.514552540857332\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:01:03,203] Trial 87 finished with value: 0.5396356203172296 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011603105069520697, 'dropout': 0.3523095910205018, 'lr': 0.00725680572532261, 'n_epochs': 140}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87 finished with value: 0.5396356203172296\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:01:41,536] Trial 88 finished with value: 0.5192666328200553 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 6, 'confidence_threshold': 0.007737246038967196, 'dropout': 0.36706355853679007, 'lr': 0.009177725521988277, 'n_epochs': 150}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88 finished with value: 0.5192666328200553\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:02:03,972] Trial 89 finished with value: 0.5307592863625826 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.009882798946484627, 'dropout': 0.35667508520667274, 'lr': 0.008083994528230566, 'n_epochs': 102}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89 finished with value: 0.5307592863625826\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:02:13,426] Trial 90 finished with value: 0.3301168164332001 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.014843154192521581, 'dropout': 0.3622957941298606, 'lr': 0.008616669838154761, 'n_epochs': 100}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 finished with value: 0.3301168164332001\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:02:41,256] Trial 91 finished with value: 0.5397347986141602 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.010713711990735345, 'dropout': 0.3729163296816412, 'lr': 0.009465793573426282, 'n_epochs': 118}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91 finished with value: 0.5397347986141602\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:03:14,237] Trial 92 finished with value: 0.5413380274907735 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012833644557916498, 'dropout': 0.37412390180062577, 'lr': 0.009425899898075645, 'n_epochs': 117}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92 finished with value: 0.5413380274907735\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:03:55,405] Trial 93 finished with value: 0.5181768217952928 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012881500175607932, 'dropout': 0.3768862972492659, 'lr': 0.003252671927450972, 'n_epochs': 177}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93 finished with value: 0.5181768217952928\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:04:24,979] Trial 94 finished with value: 0.5397062643681217 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01689574191459969, 'dropout': 0.370581989843687, 'lr': 0.008853785291353972, 'n_epochs': 116}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94 finished with value: 0.5397062643681217\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:04:57,952] Trial 95 finished with value: 0.5428058072027708 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011922110031669982, 'dropout': 0.3601877682543027, 'lr': 0.009982602430123213, 'n_epochs': 128}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95 finished with value: 0.5428058072027708\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:05:26,797] Trial 96 finished with value: 0.5290065590357237 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013810827953614154, 'dropout': 0.3599140322269383, 'lr': 0.009925491613093402, 'n_epochs': 100}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96 finished with value: 0.5290065590357237\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:05:49,747] Trial 97 finished with value: 0.4075815814958932 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.03552406064240974, 'dropout': 0.354293141860953, 'lr': 0.008162216374880345, 'n_epochs': 103}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97 finished with value: 0.4075815814958932\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:06:06,298] Trial 98 finished with value: 0.4766020514712005 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.01264915982830494, 'dropout': 0.3638221143578727, 'lr': 0.00873977960877521, 'n_epochs': 161}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98 finished with value: 0.4766020514712005\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:06:29,424] Trial 99 finished with value: 0.5336206761608708 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.005360053520964175, 'dropout': 0.35097796210718546, 'lr': 0.009610458310819338, 'n_epochs': 115}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99 finished with value: 0.5336206761608708\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:06:55,522] Trial 100 finished with value: 0.19587216011457606 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.047312321244588944, 'dropout': 0.3469295279569526, 'lr': 0.007513707158581352, 'n_epochs': 117}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 finished with value: 0.19587216011457606\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:07:20,366] Trial 101 finished with value: 0.5349838641260555 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.010995817010295953, 'dropout': 0.377799654499811, 'lr': 0.009313642372800416, 'n_epochs': 117}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 101 finished with value: 0.5349838641260555\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:07:46,835] Trial 102 finished with value: 0.544150849455967 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011783180434566262, 'dropout': 0.3683425886161463, 'lr': 0.009478664882197587, 'n_epochs': 128}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 102 finished with value: 0.544150849455967\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:08:09,493] Trial 103 finished with value: 0.527180460182393 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.008063710063013985, 'dropout': 0.3575817894840958, 'lr': 0.00861539826119519, 'n_epochs': 105}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 103 finished with value: 0.527180460182393\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:08:40,040] Trial 104 finished with value: 0.537099889247737 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011923956591351103, 'dropout': 0.37175880145206397, 'lr': 0.007994847507462792, 'n_epochs': 137}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 finished with value: 0.537099889247737\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:09:01,338] Trial 105 finished with value: 0.5179815061007591 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 4, 'confidence_threshold': 0.01547211286956766, 'dropout': 0.36669250539653936, 'lr': 0.009558144131265312, 'n_epochs': 103}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 105 finished with value: 0.5179815061007591\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:09:27,670] Trial 106 finished with value: 0.534449896390333 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014413118708104886, 'dropout': 0.3504113564447486, 'lr': 0.008975314368461686, 'n_epochs': 115}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 106 finished with value: 0.534449896390333\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:09:50,836] Trial 107 finished with value: 0.5277174757967878 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.009520216516347204, 'dropout': 0.35972393889327575, 'lr': 0.0083001309099384, 'n_epochs': 106}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 107 finished with value: 0.5277174757967878\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:10:10,320] Trial 108 finished with value: 0.2969111110588153 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.006991894861679535, 'dropout': 0.36232538242058165, 'lr': 0.0070060904448769785, 'n_epochs': 119}. Best is trial 61 with value: 0.5490357263324551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 108 finished with value: 0.2969111110588153\n",
      "Best trial so far: 61, value: 0.5490357263324551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:10:37,087] Trial 109 finished with value: 0.5524234784313315 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01777733972951912, 'dropout': 0.32659154441329213, 'lr': 0.009654433371114043, 'n_epochs': 128}. Best is trial 109 with value: 0.5524234784313315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 109 finished with value: 0.5524234784313315\n",
      "Best trial so far: 109, value: 0.5524234784313315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:11:14,377] Trial 110 finished with value: 0.5504581258679165 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017508972869133277, 'dropout': 0.3289331589233273, 'lr': 0.009949587077760003, 'n_epochs': 129}. Best is trial 109 with value: 0.5524234784313315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 110 finished with value: 0.5504581258679165\n",
      "Best trial so far: 109, value: 0.5524234784313315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:11:43,159] Trial 111 finished with value: 0.5298605178131744 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018955914622613534, 'dropout': 0.32542379388835335, 'lr': 0.00988822059577945, 'n_epochs': 102}. Best is trial 109 with value: 0.5524234784313315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 111 finished with value: 0.5298605178131744\n",
      "Best trial so far: 109, value: 0.5524234784313315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:12:10,054] Trial 112 finished with value: 0.5534210873103904 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0204122625043393, 'dropout': 0.32818116040585577, 'lr': 0.009639440559135761, 'n_epochs': 128}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 finished with value: 0.5534210873103904\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:12:29,693] Trial 113 finished with value: 0.5242831646659756 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02033376700487055, 'dropout': 0.3287514416451882, 'lr': 0.009046628225102863, 'n_epochs': 100}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 113 finished with value: 0.5242831646659756\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:12:55,225] Trial 114 finished with value: 0.5339614302619341 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017576636757809877, 'dropout': 0.3195991103039199, 'lr': 0.009715929179944438, 'n_epochs': 103}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 114 finished with value: 0.5339614302619341\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:13:23,896] Trial 115 finished with value: 0.54967732335142 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.021590404122641207, 'dropout': 0.3277776846727235, 'lr': 0.00992755383949103, 'n_epochs': 128}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 115 finished with value: 0.54967732335142\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:13:44,702] Trial 116 finished with value: 0.531669854240455 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.022278540624563765, 'dropout': 0.3208119712365679, 'lr': 0.008759267413951537, 'n_epochs': 105}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 116 finished with value: 0.531669854240455\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:14:01,669] Trial 117 finished with value: 0.37246291026268724 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 12, 'num_layers': 3, 'confidence_threshold': 0.024533780609594123, 'dropout': 0.3159645320814932, 'lr': 0.009042000555079885, 'n_epochs': 148}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 117 finished with value: 0.37246291026268724\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:14:23,155] Trial 118 finished with value: 0.5304691343151894 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01640626120547781, 'dropout': 0.3237229557257744, 'lr': 0.007833464863543868, 'n_epochs': 106}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 118 finished with value: 0.5304691343151894\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:14:55,664] Trial 119 finished with value: 0.49419250017077515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 6, 'confidence_threshold': 0.018086793307116246, 'dropout': 0.32681186041602944, 'lr': 0.009620870802981388, 'n_epochs': 127}. Best is trial 112 with value: 0.5534210873103904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 119 finished with value: 0.49419250017077515\n",
      "Best trial so far: 112, value: 0.5534210873103904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:15:22,469] Trial 120 finished with value: 0.5539292279711663 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.020035905628227317, 'dropout': 0.3304903855361223, 'lr': 0.009934711669307882, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 120 finished with value: 0.5539292279711663\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:15:42,926] Trial 121 finished with value: 0.535061569839544 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.021258567953735236, 'dropout': 0.330271593809978, 'lr': 0.009948057803555857, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 121 finished with value: 0.535061569839544\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:16:02,922] Trial 122 finished with value: 0.5355547715016591 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019857483259040395, 'dropout': 0.33360568463263474, 'lr': 0.00919558863139131, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 122 finished with value: 0.5355547715016591\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:16:24,545] Trial 123 finished with value: 0.5240456069974726 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.023103490317404933, 'dropout': 0.327740176384405, 'lr': 0.008435050563537683, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 123 finished with value: 0.5240456069974726\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:16:50,511] Trial 124 finished with value: 0.549927696166082 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02596055298367536, 'dropout': 0.33596523692532876, 'lr': 0.009512897785417569, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 124 finished with value: 0.549927696166082\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:17:13,052] Trial 125 finished with value: 0.5305444592004603 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02159468513222532, 'dropout': 0.3368034837470729, 'lr': 0.008754749418278066, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 125 finished with value: 0.5305444592004603\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:17:45,229] Trial 126 finished with value: 0.550493934984402 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.026146488904360908, 'dropout': 0.3317334104943838, 'lr': 0.009389298524763338, 'n_epochs': 132}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 126 finished with value: 0.550493934984402\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:18:11,715] Trial 127 finished with value: 0.5489769397146805 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.028242846003595397, 'dropout': 0.332016963808265, 'lr': 0.009499315800272181, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 127 finished with value: 0.5489769397146805\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:18:23,639] Trial 128 finished with value: 0.2384681903399156 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.026469791443719422, 'dropout': 0.33192864601763267, 'lr': 0.009123090237080382, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 finished with value: 0.2384681903399156\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:18:46,717] Trial 129 finished with value: 0.5389970531458599 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.030637369678671696, 'dropout': 0.33560995071424593, 'lr': 0.009504405674343788, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 129 finished with value: 0.5389970531458599\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:19:08,513] Trial 130 finished with value: 0.5349895225679094 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.027995061012040724, 'dropout': 0.3226658611839979, 'lr': 0.009999334176236474, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 130 finished with value: 0.5349895225679094\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:19:29,720] Trial 131 finished with value: 0.5250962028778368 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.029028844004304343, 'dropout': 0.32919900110876815, 'lr': 0.009408431970757056, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 131 finished with value: 0.5250962028778368\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:19:55,085] Trial 132 finished with value: 0.18774152969369604 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02599939320409187, 'dropout': 0.3317115966377294, 'lr': 0.0011403698566697254, 'n_epochs': 122}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 132 finished with value: 0.18774152969369604\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:20:17,751] Trial 133 finished with value: 0.5270810281797995 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02872575118206537, 'dropout': 0.3253082644498858, 'lr': 0.008502682866869924, 'n_epochs': 108}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 133 finished with value: 0.5270810281797995\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:20:38,332] Trial 134 finished with value: 0.5323176569363393 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.025397634995107464, 'dropout': 0.33842353107549655, 'lr': 0.009035045911446065, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 134 finished with value: 0.5323176569363393\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:21:06,935] Trial 135 finished with value: 0.5040309387160921 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.024008676410974344, 'dropout': 0.33461004430407426, 'lr': 0.009496070423060636, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 135 finished with value: 0.5040309387160921\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:21:29,485] Trial 136 finished with value: 0.5256232818135695 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.031261731982439235, 'dropout': 0.3302035868763424, 'lr': 0.00873178444824109, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 136 finished with value: 0.5256232818135695\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:21:50,045] Trial 137 finished with value: 0.533970941865042 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02295021958207708, 'dropout': 0.32644879097379076, 'lr': 0.009969829831754215, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 137 finished with value: 0.533970941865042\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:22:11,124] Trial 138 finished with value: 0.5328806188593811 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019061363047782633, 'dropout': 0.321545864123935, 'lr': 0.009181039667939858, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 138 finished with value: 0.5328806188593811\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:22:28,239] Trial 139 finished with value: 0.09441441441441442 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.029793648320651754, 'dropout': 0.3327720499097141, 'lr': 0.008135149659427177, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 139 finished with value: 0.09441441441441442\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:22:56,114] Trial 140 finished with value: 0.4758739823119219 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.03332537768578682, 'dropout': 0.32866145924055185, 'lr': 0.008535220978037302, 'n_epochs': 136}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 140 finished with value: 0.4758739823119219\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:23:17,543] Trial 141 finished with value: 0.5383812536968591 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.027514418861869817, 'dropout': 0.33580889542461423, 'lr': 0.009513766696507822, 'n_epochs': 110}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 141 finished with value: 0.5383812536968591\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:23:37,881] Trial 142 finished with value: 0.5312808849069308 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017238730202494043, 'dropout': 0.3244305696232921, 'lr': 0.0076969997696883525, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 142 finished with value: 0.5312808849069308\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:23:58,699] Trial 143 finished with value: 0.5329455164597005 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016148832787917542, 'dropout': 0.34401206360517067, 'lr': 0.008993308212751084, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 143 finished with value: 0.5329455164597005\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:24:33,028] Trial 144 finished with value: 0.5338014527324366 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02088250393414083, 'dropout': 0.3306237681441899, 'lr': 0.004629366398686603, 'n_epochs': 180}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 144 finished with value: 0.5338014527324366\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:24:54,033] Trial 145 finished with value: 0.5341223665251064 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018375671032078433, 'dropout': 0.3380840598706499, 'lr': 0.0099880931759419, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 145 finished with value: 0.5341223665251064\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:25:15,638] Trial 146 finished with value: 0.524452926600718 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014916962663377853, 'dropout': 0.3270123181125865, 'lr': 0.008304472982612408, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 146 finished with value: 0.524452926600718\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:25:41,818] Trial 147 finished with value: 0.5481676411186309 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.025421164773118125, 'dropout': 0.33368462857054926, 'lr': 0.009487709306912475, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 147 finished with value: 0.5481676411186309\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:26:04,698] Trial 148 finished with value: 0.5378875048984026 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.025725799107322384, 'dropout': 0.34074844641493734, 'lr': 0.009497556004292449, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 148 finished with value: 0.5378875048984026\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:26:16,311] Trial 149 finished with value: 0.4662393984563469 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.01988452991353136, 'dropout': 0.33497592136078885, 'lr': 0.008876731336124054, 'n_epochs': 123}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 149 finished with value: 0.4662393984563469\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:26:38,199] Trial 150 finished with value: 0.5168335150878642 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 4, 'confidence_threshold': 0.024200240553981976, 'dropout': 0.33289251004794945, 'lr': 0.009490200986544118, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150 finished with value: 0.5168335150878642\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:27:20,963] Trial 151 finished with value: 0.3936058784779514 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.026882826171562697, 'dropout': 0.3286374442177877, 'lr': 0.0021216348829764184, 'n_epochs': 224}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 151 finished with value: 0.3936058784779514\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:28:03,819] Trial 152 finished with value: 0.5321037957843917 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0140047592170254, 'dropout': 0.33138916862456813, 'lr': 0.003793478410235012, 'n_epochs': 212}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 152 finished with value: 0.5321037957843917\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:28:24,986] Trial 153 finished with value: 0.5334199645754862 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016854732750372418, 'dropout': 0.32307759197664665, 'lr': 0.009224407537149815, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 153 finished with value: 0.5334199645754862\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:28:44,692] Trial 154 finished with value: 0.5258351383391988 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.021847793269496533, 'dropout': 0.32588942644565905, 'lr': 0.008647273386907213, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 154 finished with value: 0.5258351383391988\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:29:05,453] Trial 155 finished with value: 0.5296128300275331 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.028160324253345113, 'dropout': 0.329590080843784, 'lr': 0.0096053292520683, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 155 finished with value: 0.5296128300275331\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:29:35,954] Trial 156 finished with value: 0.5400962562060565 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.023417937181117395, 'dropout': 0.33403342804164987, 'lr': 0.00799938659788737, 'n_epochs': 132}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 156 finished with value: 0.5400962562060565\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:30:01,239] Trial 157 finished with value: 0.5322131151300767 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02519056132113617, 'dropout': 0.33888856688146984, 'lr': 0.009103880536127153, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 157 finished with value: 0.5322131151300767\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:30:24,772] Trial 158 finished with value: 0.22077882369052454 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015255734819701746, 'dropout': 0.32737216522800255, 'lr': 0.0016921268763688204, 'n_epochs': 107}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 158 finished with value: 0.22077882369052454\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:30:39,144] Trial 159 finished with value: 0.2898806887564172 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.018484971005240103, 'dropout': 0.3327120101051016, 'lr': 0.009948914835449152, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 159 finished with value: 0.2898806887564172\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:31:00,069] Trial 160 finished with value: 0.5292586214984261 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02030896344455997, 'dropout': 0.34760311583316494, 'lr': 0.00869536915743515, 'n_epochs': 102}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 160 finished with value: 0.5292586214984261\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:31:25,745] Trial 161 finished with value: 0.5502425902993162 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01333514460581991, 'dropout': 0.33067642632746147, 'lr': 0.00963469363348003, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 161 finished with value: 0.5502425902993162\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:31:51,565] Trial 162 finished with value: 0.5523135993487662 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013436903112218344, 'dropout': 0.33055354260773534, 'lr': 0.009543513935064203, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 162 finished with value: 0.5523135993487662\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:32:20,437] Trial 163 finished with value: 0.5523135993487662 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013426709222876029, 'dropout': 0.33055420527753626, 'lr': 0.009541921580949103, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 163 finished with value: 0.5523135993487662\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:32:46,111] Trial 164 finished with value: 0.5348363497480317 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01333521081642535, 'dropout': 0.33692188540401846, 'lr': 0.00923468483799088, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 164 finished with value: 0.5348363497480317\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:33:15,302] Trial 165 finished with value: 0.5512908119929476 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015760293671390573, 'dropout': 0.3303171992094036, 'lr': 0.009984232440104998, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 165 finished with value: 0.5512908119929476\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:33:43,625] Trial 166 finished with value: 0.5498178963515472 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015907443068084406, 'dropout': 0.33038308376429715, 'lr': 0.00962743204751389, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 166 finished with value: 0.5498178963515472\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:34:14,954] Trial 167 finished with value: 0.5521935044623828 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016090030137861186, 'dropout': 0.3303645308304069, 'lr': 0.009967711944491107, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 167 finished with value: 0.5521935044623828\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:34:39,555] Trial 168 finished with value: 0.5341438458369726 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017841949281269635, 'dropout': 0.3304627393117928, 'lr': 0.009647347164779859, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 168 finished with value: 0.5341438458369726\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:35:01,153] Trial 169 finished with value: 0.5280788166758483 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016044296974469574, 'dropout': 0.32833110268814286, 'lr': 0.009724050850236945, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 169 finished with value: 0.5280788166758483\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:35:23,744] Trial 170 finished with value: 0.48119293397416996 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 5, 'confidence_threshold': 0.01683149923554447, 'dropout': 0.3253515340082629, 'lr': 0.008969913787064594, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 170 finished with value: 0.48119293397416996\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:35:52,247] Trial 171 finished with value: 0.5490415087989253 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014964266405258901, 'dropout': 0.33168012240596595, 'lr': 0.009997330482817332, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 171 finished with value: 0.5490415087989253\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:36:18,632] Trial 172 finished with value: 0.5498766356470005 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016003807711785573, 'dropout': 0.331672740167125, 'lr': 0.009959189067418071, 'n_epochs': 126}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 172 finished with value: 0.5498766356470005\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:36:46,635] Trial 173 finished with value: 0.5493101422266669 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015364055205632731, 'dropout': 0.33095575577538905, 'lr': 0.009809233685154389, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 173 finished with value: 0.5493101422266669\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:37:14,356] Trial 174 finished with value: 0.5503132232356032 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015761551058142947, 'dropout': 0.32981061969069436, 'lr': 0.009966711858964517, 'n_epochs': 127}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 174 finished with value: 0.5503132232356032\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:37:38,398] Trial 175 finished with value: 0.5348402801296899 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015347405869896682, 'dropout': 0.3299265771864302, 'lr': 0.009961250603719184, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 175 finished with value: 0.5348402801296899\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:38:06,510] Trial 176 finished with value: 0.5509703019887627 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017374384315107693, 'dropout': 0.33086527462876586, 'lr': 0.009996289212536851, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 176 finished with value: 0.5509703019887627\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:38:28,556] Trial 177 finished with value: 0.4604666643365311 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017222944195611777, 'dropout': 0.3314794513970437, 'lr': 0.009988580304874168, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 177 finished with value: 0.4604666643365311\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:38:50,623] Trial 178 finished with value: 0.5333844911371501 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014123891577042035, 'dropout': 0.33514919729130827, 'lr': 0.00917304648177607, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 178 finished with value: 0.5333844911371501\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:39:23,650] Trial 179 finished with value: 0.5474989700654255 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019204970952646304, 'dropout': 0.32873327902314664, 'lr': 0.008820224636444192, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 179 finished with value: 0.5474989700654255\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:39:53,426] Trial 180 finished with value: 0.5516584988392497 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018010950059343604, 'dropout': 0.32627011030121883, 'lr': 0.009563438246240192, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 finished with value: 0.5516584988392497\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:40:18,442] Trial 181 finished with value: 0.5529464028600803 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01795817302706577, 'dropout': 0.32642666567262996, 'lr': 0.009529458535861303, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 181 finished with value: 0.5529464028600803\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:40:44,251] Trial 182 finished with value: 0.5526196059497147 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01779737510238062, 'dropout': 0.326419450470161, 'lr': 0.009405597518380396, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 182 finished with value: 0.5526196059497147\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:41:05,493] Trial 183 finished with value: 0.5333589863728425 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017922889863452394, 'dropout': 0.3238645545378112, 'lr': 0.009204396584993082, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 183 finished with value: 0.5333589863728425\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:41:35,353] Trial 184 finished with value: 0.5020660805812536 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.019272553145910833, 'dropout': 0.3264343949877176, 'lr': 0.00940148867020819, 'n_epochs': 185}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 184 finished with value: 0.5020660805812536\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:41:58,020] Trial 185 finished with value: 0.5256388733749384 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016251625686582588, 'dropout': 0.32757624163383303, 'lr': 0.008546001264116048, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 185 finished with value: 0.5256388733749384\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:42:19,922] Trial 186 finished with value: 0.5325339315268869 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01745742805164249, 'dropout': 0.32080976007883527, 'lr': 0.00893580264309859, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 186 finished with value: 0.5325339315268869\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:42:40,600] Trial 187 finished with value: 0.5271278866998343 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018410860461856002, 'dropout': 0.32594875926152034, 'lr': 0.009502639472844658, 'n_epochs': 101}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 187 finished with value: 0.5271278866998343\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:43:01,750] Trial 188 finished with value: 0.5350828495854929 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019725478731083802, 'dropout': 0.32327169202459344, 'lr': 0.009147554380189622, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 188 finished with value: 0.5350828495854929\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:43:29,006] Trial 189 finished with value: 0.5493581864511049 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016356556757491, 'dropout': 0.3292374202252121, 'lr': 0.00953073298430944, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 189 finished with value: 0.5493581864511049\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:43:53,169] Trial 190 finished with value: 0.5395158405731022 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017574251438585976, 'dropout': 0.3340696121078749, 'lr': 0.009998417312278919, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 190 finished with value: 0.5395158405731022\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:44:18,624] Trial 191 finished with value: 0.5244940689407295 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01643561692708188, 'dropout': 0.3293755449429165, 'lr': 0.009459825763212356, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 191 finished with value: 0.5244940689407295\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:44:39,062] Trial 192 finished with value: 0.5248095770565246 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01859629218997776, 'dropout': 0.32887416377540346, 'lr': 0.00954204099815416, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 192 finished with value: 0.5248095770565246\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:44:57,822] Trial 193 finished with value: 0.5296998163692713 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.020882680498817183, 'dropout': 0.3248826576076873, 'lr': 0.008929810915250047, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 193 finished with value: 0.5296998163692713\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:45:20,425] Trial 194 finished with value: 0.5268283759912171 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016923218891424306, 'dropout': 0.3275643411437186, 'lr': 0.009577899843622792, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 194 finished with value: 0.5268283759912171\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:45:34,240] Trial 195 finished with value: 0.473341440169137 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 2, 'confidence_threshold': 0.015776439039503095, 'dropout': 0.3306361483531389, 'lr': 0.009998573868214228, 'n_epochs': 121}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 195 finished with value: 0.473341440169137\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:46:00,310] Trial 196 finished with value: 0.5232396026778047 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 5, 'confidence_threshold': 0.014653817932424625, 'dropout': 0.3326778473194077, 'lr': 0.008464236512999922, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 196 finished with value: 0.5232396026778047\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:46:25,790] Trial 197 finished with value: 0.5503209518600345 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01863511244728289, 'dropout': 0.33637766564285637, 'lr': 0.009154175332404096, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 197 finished with value: 0.5503209518600345\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:46:55,918] Trial 198 finished with value: 0.5459218931992132 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02023303119825384, 'dropout': 0.3357131159948976, 'lr': 0.008961898537439958, 'n_epochs': 133}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 198 finished with value: 0.5459218931992132\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:47:20,655] Trial 199 finished with value: 0.5358720540225839 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01906387680395761, 'dropout': 0.33300322015850686, 'lr': 0.009211888369065651, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 199 finished with value: 0.5358720540225839\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:47:56,288] Trial 200 finished with value: 0.548560234236777 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017840259585955948, 'dropout': 0.33639223487456166, 'lr': 0.00866543306166436, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 finished with value: 0.548560234236777\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:48:20,694] Trial 201 finished with value: 0.5317879442942262 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01652693789873069, 'dropout': 0.3298394696665706, 'lr': 0.009550188426174963, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 201 finished with value: 0.5317879442942262\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:48:38,979] Trial 202 finished with value: 0.5252165053643412 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017580994003623646, 'dropout': 0.3269736354168634, 'lr': 0.009351943881455447, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 202 finished with value: 0.5252165053643412\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:48:58,061] Trial 203 finished with value: 0.533141700433505 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014112109990630985, 'dropout': 0.3245949732384255, 'lr': 0.009974397103588533, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 203 finished with value: 0.533141700433505\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:49:21,202] Trial 204 finished with value: 0.5506149703300424 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015958621741972042, 'dropout': 0.328681637268778, 'lr': 0.009578795355612497, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 204 finished with value: 0.5506149703300424\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:49:45,006] Trial 205 finished with value: 0.5296093791625058 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019484301254208195, 'dropout': 0.33134137868920216, 'lr': 0.009054341556421505, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 205 finished with value: 0.5296093791625058\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:50:10,901] Trial 206 finished with value: 0.5452924347487866 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02183589607803927, 'dropout': 0.2864370144934932, 'lr': 0.009631444473641646, 'n_epochs': 116}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 206 finished with value: 0.5452924347487866\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:50:33,994] Trial 207 finished with value: 0.5313027228558951 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018449528925227464, 'dropout': 0.3339532201362646, 'lr': 0.008804930118798949, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 207 finished with value: 0.5313027228558951\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:51:04,175] Trial 208 finished with value: 0.5473461491591008 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015281312850805728, 'dropout': 0.32684741232671416, 'lr': 0.00918733839353029, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 208 finished with value: 0.5473461491591008\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:51:19,847] Trial 209 finished with value: 0.299246565661313 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.013517869639286018, 'dropout': 0.3285454359721978, 'lr': 0.009995175879249486, 'n_epochs': 126}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 209 finished with value: 0.299246565661313\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:51:42,162] Trial 210 finished with value: 0.5348551657042393 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017256622877401165, 'dropout': 0.32180577119424014, 'lr': 0.009558801712421445, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 210 finished with value: 0.5348551657042393\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:52:04,788] Trial 211 finished with value: 0.5335442340649977 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015963404897080126, 'dropout': 0.3299996165572099, 'lr': 0.00955696690746156, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 211 finished with value: 0.5335442340649977\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:52:28,698] Trial 212 finished with value: 0.5328791329984911 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016815728582961445, 'dropout': 0.3319734992904079, 'lr': 0.009298504944468383, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 212 finished with value: 0.5328791329984911\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:53:03,048] Trial 213 finished with value: 0.5517438388994675 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01581725519497347, 'dropout': 0.32853167398586997, 'lr': 0.009560951774078213, 'n_epochs': 132}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 213 finished with value: 0.5517438388994675\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:53:25,163] Trial 214 finished with value: 0.5272876216826828 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01477425874437927, 'dropout': 0.3256153072778935, 'lr': 0.008873354913221476, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 214 finished with value: 0.5272876216826828\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:53:47,239] Trial 215 finished with value: 0.4655290383613984 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018430702425835523, 'dropout': 0.3279723147569242, 'lr': 0.009955858346619271, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 215 finished with value: 0.4655290383613984\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:54:24,195] Trial 216 finished with value: 0.3166274921904112 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.020657604274795894, 'dropout': 0.33343028870816854, 'lr': 0.002751257197584184, 'n_epochs': 118}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 216 finished with value: 0.3166274921904112\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:54:51,016] Trial 217 finished with value: 0.547015181463377 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015881638252855036, 'dropout': 0.3311742773783979, 'lr': 0.009220337421956744, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 217 finished with value: 0.547015181463377\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:55:09,613] Trial 218 finished with value: 0.5319993003455818 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01410411814821589, 'dropout': 0.32393511923735685, 'lr': 0.008473485667898274, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 218 finished with value: 0.5319993003455818\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:55:35,446] Trial 219 finished with value: 0.5520822929298466 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012743742909178134, 'dropout': 0.3265417842389044, 'lr': 0.009632722353743283, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 219 finished with value: 0.5520822929298466\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:55:58,176] Trial 220 finished with value: 0.5293989013905218 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013487259779188361, 'dropout': 0.3257915222033296, 'lr': 0.009179426587022654, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 220 finished with value: 0.5293989013905218\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:56:18,321] Trial 221 finished with value: 0.5266530572476361 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012959784355409128, 'dropout': 0.328437512524096, 'lr': 0.0096088710161719, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 221 finished with value: 0.5266530572476361\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:56:39,657] Trial 222 finished with value: 0.5333450143980014 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017396592192535837, 'dropout': 0.33018974132458245, 'lr': 0.00996203243297343, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 222 finished with value: 0.5333450143980014\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:57:07,666] Trial 223 finished with value: 0.5497773099690596 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015615858684538365, 'dropout': 0.3271438040914894, 'lr': 0.009570363233938537, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 223 finished with value: 0.5497773099690596\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:57:34,556] Trial 224 finished with value: 0.5518976309147088 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015467433206795372, 'dropout': 0.32659707715278613, 'lr': 0.009543976263665335, 'n_epochs': 126}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 224 finished with value: 0.5518976309147088\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:57:59,012] Trial 225 finished with value: 0.529497248306375 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012433633773955816, 'dropout': 0.322517048995335, 'lr': 0.008752937362979272, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 225 finished with value: 0.529497248306375\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:58:39,080] Trial 226 finished with value: 0.5099231528773599 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.015464808825457067, 'dropout': 0.33155211913949745, 'lr': 0.009157352044033857, 'n_epochs': 191}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 226 finished with value: 0.5099231528773599\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:59:06,523] Trial 227 finished with value: 0.5372621616798294 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014346422469900654, 'dropout': 0.3347285477089833, 'lr': 0.009640832117103586, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 227 finished with value: 0.5372621616798294\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:59:30,924] Trial 228 finished with value: 0.5468527071280445 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016633832820909467, 'dropout': 0.32564023902346184, 'lr': 0.00999949752738246, 'n_epochs': 126}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 228 finished with value: 0.5468527071280445\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 21:59:50,915] Trial 229 finished with value: 0.5281526475269525 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018092233605474184, 'dropout': 0.32957983432890114, 'lr': 0.009172424711069486, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 229 finished with value: 0.5281526475269525\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:00:12,219] Trial 230 finished with value: 0.5311467928949835 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01432700272638769, 'dropout': 0.33732714784880574, 'lr': 0.008808698533001204, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 230 finished with value: 0.5311467928949835\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:00:45,342] Trial 231 finished with value: 0.5501444351084205 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015942442964064094, 'dropout': 0.3271962698364362, 'lr': 0.009519206044810853, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 231 finished with value: 0.5501444351084205\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:01:14,271] Trial 232 finished with value: 0.5514797419356178 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016356807720625074, 'dropout': 0.32756977855547, 'lr': 0.009467384315034215, 'n_epochs': 130}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 232 finished with value: 0.5514797419356178\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:01:46,524] Trial 233 finished with value: 0.549069877064618 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017342861769318794, 'dropout': 0.32704325904048476, 'lr': 0.009365235431536929, 'n_epochs': 137}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 233 finished with value: 0.549069877064618\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:02:10,981] Trial 234 finished with value: 0.5315687579745263 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016727846469211285, 'dropout': 0.3242204110541943, 'lr': 0.009176081888780933, 'n_epochs': 107}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 234 finished with value: 0.5315687579745263\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:02:31,148] Trial 235 finished with value: 0.5291929410967229 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015123309756066239, 'dropout': 0.328332283736184, 'lr': 0.009996227274870196, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 235 finished with value: 0.5291929410967229\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:02:52,756] Trial 236 finished with value: 0.5290423486081972 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01309780221491104, 'dropout': 0.3253527205953212, 'lr': 0.00958044708286082, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 236 finished with value: 0.5290423486081972\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:03:17,271] Trial 237 finished with value: 0.5325703172215591 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01878176833283982, 'dropout': 0.3325728787302769, 'lr': 0.00892190991750875, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 237 finished with value: 0.5325703172215591\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:03:40,998] Trial 238 finished with value: 0.5304927560358748 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01631163603379423, 'dropout': 0.3296932809172076, 'lr': 0.009475600960371006, 'n_epochs': 103}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 238 finished with value: 0.5304927560358748\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:04:05,834] Trial 239 finished with value: 0.5311719019292469 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 5, 'confidence_threshold': 0.014743807468490298, 'dropout': 0.3271116094909367, 'lr': 0.008340989034317825, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 239 finished with value: 0.5311719019292469\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:04:33,725] Trial 240 finished with value: 0.46468155363575125 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 12, 'num_layers': 3, 'confidence_threshold': 0.01788336601398023, 'dropout': 0.3225125499410501, 'lr': 0.009550145852787526, 'n_epochs': 230}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 240 finished with value: 0.46468155363575125\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:05:04,399] Trial 241 finished with value: 0.5515380517029974 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015871109979459515, 'dropout': 0.330623667863137, 'lr': 0.00956718162876286, 'n_epochs': 129}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 241 finished with value: 0.5515380517029974\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:05:32,379] Trial 242 finished with value: 0.5472239583832834 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015787811722388644, 'dropout': 0.3290242815421338, 'lr': 0.009275902777249564, 'n_epochs': 131}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 242 finished with value: 0.5472239583832834\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:05:57,998] Trial 243 finished with value: 0.5495184428092244 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01692721637987613, 'dropout': 0.3321695895233881, 'lr': 0.009626592317461494, 'n_epochs': 132}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 243 finished with value: 0.5495184428092244\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:06:19,767] Trial 244 finished with value: 0.5144022208789722 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014944196583312147, 'dropout': 0.3306132929880687, 'lr': 0.005100092056976852, 'n_epochs': 108}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 244 finished with value: 0.5144022208789722\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:06:41,951] Trial 245 finished with value: 0.5220150397922743 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019634960261021253, 'dropout': 0.32725821453625875, 'lr': 0.008952909020823286, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 245 finished with value: 0.5220150397922743\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:07:05,311] Trial 246 finished with value: 0.5405258143687893 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016499490340251825, 'dropout': 0.3339159830481715, 'lr': 0.009669057449349693, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 246 finished with value: 0.5405258143687893\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:07:24,868] Trial 247 finished with value: 0.5309057288057043 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.011924851737021569, 'dropout': 0.32558050657436727, 'lr': 0.009994005384963034, 'n_epochs': 101}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 247 finished with value: 0.5309057288057043\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:07:47,491] Trial 248 finished with value: 0.530621037951564 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.017834414000003785, 'dropout': 0.3283773376512795, 'lr': 0.00920144263748267, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 248 finished with value: 0.530621037951564\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:08:17,280] Trial 249 finished with value: 0.5518353606535963 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02681566320012984, 'dropout': 0.3312778454242949, 'lr': 0.009993688440294473, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 249 finished with value: 0.5518353606535963\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:08:42,051] Trial 250 finished with value: 0.5297029593774851 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02736141733940518, 'dropout': 0.3295915736998583, 'lr': 0.008737246680390012, 'n_epochs': 105}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 250 finished with value: 0.5297029593774851\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:09:04,024] Trial 251 finished with value: 0.5296800562904418 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.024797935521176286, 'dropout': 0.3249291013075011, 'lr': 0.009237307569183782, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 251 finished with value: 0.5296800562904418\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:09:25,756] Trial 252 finished with value: 0.084217238449973 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 16, 'num_layers': 4, 'confidence_threshold': 0.026254279602963754, 'dropout': 0.33539343831267093, 'lr': 0.0034704402120914655, 'n_epochs': 156}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 252 finished with value: 0.084217238449973\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:09:48,958] Trial 253 finished with value: 0.5305579340526371 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.0134353102033282, 'dropout': 0.29884423813687677, 'lr': 0.009524786066796588, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 253 finished with value: 0.5305579340526371\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:10:09,809] Trial 254 finished with value: 0.5236406160881667 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01901140781754278, 'dropout': 0.32799680829687283, 'lr': 0.00864053896405458, 'n_epochs': 103}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 finished with value: 0.5236406160881667\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:10:34,191] Trial 255 finished with value: 0.546933164967872 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.014142410412221728, 'dropout': 0.3325746752086888, 'lr': 0.00999480912197122, 'n_epochs': 122}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 255 finished with value: 0.546933164967872\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:10:57,789] Trial 256 finished with value: 0.5312853616967435 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.018163804727895402, 'dropout': 0.32990981710633793, 'lr': 0.009102409469161231, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 256 finished with value: 0.5312853616967435\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:11:20,944] Trial 257 finished with value: 0.4768999022841515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 5, 'confidence_threshold': 0.027085412565280208, 'dropout': 0.3262591225245453, 'lr': 0.009589556189922854, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 257 finished with value: 0.4768999022841515\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:11:42,535] Trial 258 finished with value: 0.5322837735549942 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.04138423929141437, 'dropout': 0.3238962309857232, 'lr': 0.009282539274784434, 'n_epochs': 102}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 258 finished with value: 0.5322837735549942\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:12:07,136] Trial 259 finished with value: 0.5311612161488745 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01731247707498606, 'dropout': 0.31939278306015434, 'lr': 0.008946052556937579, 'n_epochs': 104}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 259 finished with value: 0.5311612161488745\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:12:36,436] Trial 260 finished with value: 0.5488100929267242 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015573983294279364, 'dropout': 0.3312088772030187, 'lr': 0.009582227341091406, 'n_epochs': 128}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 260 finished with value: 0.5488100929267242\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:12:58,974] Trial 261 finished with value: 0.5288129767692297 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.012330084740442233, 'dropout': 0.32825422776985774, 'lr': 0.009998053575254713, 'n_epochs': 100}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 261 finished with value: 0.5288129767692297\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:13:24,747] Trial 262 finished with value: 0.5289552127041135 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.016890687192681497, 'dropout': 0.3339643104283925, 'lr': 0.008522870120785958, 'n_epochs': 106}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 262 finished with value: 0.5289552127041135\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:13:53,897] Trial 263 finished with value: 0.5007374499734607 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.0144620115304481, 'dropout': 0.3307701241532616, 'lr': 0.009323984718488422, 'n_epochs': 173}. Best is trial 120 with value: 0.5539292279711663.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 263 finished with value: 0.5007374499734607\n",
      "Best trial so far: 120, value: 0.5539292279711663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:14:17,183] Trial 264 finished with value: 0.5539537581136061 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.026384181284097457, 'dropout': 0.32643679545330817, 'lr': 0.009992607214066574, 'n_epochs': 128}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 264 finished with value: 0.5539537581136061\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:14:41,793] Trial 265 finished with value: 0.5528543714011915 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015363997991794446, 'dropout': 0.3264785166180913, 'lr': 0.009962161174260133, 'n_epochs': 126}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 265 finished with value: 0.5528543714011915\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:15:06,211] Trial 266 finished with value: 0.5303057520813783 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.013683896483168902, 'dropout': 0.3223384613559066, 'lr': 0.009645034759343026, 'n_epochs': 106}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 266 finished with value: 0.5303057520813783\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:15:27,910] Trial 267 finished with value: 0.5312094444343918 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.019602091845070665, 'dropout': 0.32532251262811474, 'lr': 0.009995202301075853, 'n_epochs': 100}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 267 finished with value: 0.5312094444343918\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:15:47,670] Trial 268 finished with value: 0.5232735314351548 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.01833357940439484, 'dropout': 0.32675230248092874, 'lr': 0.008935828240527756, 'n_epochs': 100}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 268 finished with value: 0.5232735314351548\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:16:19,650] Trial 269 finished with value: 0.5193929897459653 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.02943078832232394, 'dropout': 0.3287681613843418, 'lr': 0.004193720943280145, 'n_epochs': 144}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 269 finished with value: 0.5193929897459653\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-02 22:16:41,538] Trial 270 finished with value: 0.533199101737097 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.015070331118917434, 'dropout': 0.3239119099434909, 'lr': 0.009984890572737456, 'n_epochs': 100}. Best is trial 264 with value: 0.5539537581136061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 270 finished with value: 0.533199101737097\n",
      "Best trial so far: 264, value: 0.5539537581136061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-03-02 22:16:44,715] Trial 271 failed with parameters: {'criterion': 'MSELoss', 'first_layer_size': 48, 'num_layers': 5, 'confidence_threshold': 0.026504897641837676, 'dropout': 0.32938395941126625, 'lr': 0.009237860793868445} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_23544/1515200931.py\", line 60, in objective\n",
      "    models[i].fit(X_train_fold[i], y_train_fold[i])\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_23544/2109550693.py\", line 73, in fit\n",
      "    y_pred = self.forward(X)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_23544/2109550693.py\", line 55, in forward\n",
      "    x = self.layers(x_cont)        # Set up model layers\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/activation.py\", line 434, in forward\n",
      "    return F.mish(input, inplace=self.inplace)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/functional.py\", line 2122, in mish\n",
      "    return torch._C._nn.mish(input)\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-02 22:16:44,733] Trial 271 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Uncomment to run\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# study.optimize(objective, n_trials=3)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[17], line 60\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     57\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,n_splits):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# ----- Train -----\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# ----- Eval -----\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     running_loss\u001b[38;5;241m.\u001b[39mappend(models[i]\u001b[38;5;241m.\u001b[39mscore(X_val[i], y_val[i]))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/sklearn/pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 73\u001b[0m, in \u001b[0;36mTabularModelUpdated.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 73\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(y_pred, y)\n\u001b[1;32m     75\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[16], line 55\u001b[0m, in \u001b[0;36mTabularModelUpdated.forward\u001b[0;34m(self, x_cont)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_cont):\n\u001b[1;32m     54\u001b[0m     x_cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_cont(x_cont)  \u001b[38;5;66;03m# Normalize the incoming continuous data\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# Set up model layers\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/modules/activation.py:434\u001b[0m, in \u001b[0;36mMish.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmish\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/torch/nn/functional.py:2122\u001b[0m, in \u001b[0;36mmish\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   2121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmish_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 2122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmish\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',   # max because using f1\n",
    "    pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1,\n",
    "        max_resource=1000\n",
    "    )\n",
    ")\n",
    "# Uncomment to run\n",
    "if True:\n",
    "    study.optimize(objective, n_trials=2000, callbacks=[print_callback])\n",
    "    # study.optimize(objective, n_trials=3)\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"Value: \", trial.value)\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = study.best_trial.params\n",
    "best_params = {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}\n",
    "layer_shape = [best_params['first_layer_size']]\n",
    "for i in range(1, best_params['num_layers']):\n",
    "    layer_shape.append(best_params['first_layer_size']//(2*i))\n",
    "\n",
    "# Set random state to have consistent results (42 is arbitrary)\n",
    "set_all_seeds()\n",
    "model = TabularModelUpdated(\n",
    "    n_cont=conts.shape[1],\n",
    "    out_sz=1,\n",
    "    layer_shape=layer_shape,\n",
    "    p=best_params['dropout'],     # Dropout\n",
    "    criterion=nfl_utils.map_losses(best_params['criterion']),\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    lr= best_params['lr'],   # Learning rate \n",
    "    confidence_threshold=best_params['confidence_threshold']\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "    # ('regressor', LinearRegression()), # Apply a regression model\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Run once on each split, track average loss, stop if > max patience\n",
    "for _ in range(0, (best_params['n_epochs'] - 10)):\n",
    "    running_loss = 0.0\n",
    "    # ----- Train -----\n",
    "    pipeline.fit(conts_train, y_train)\n",
    "\n",
    "    # ----- Eval -----\n",
    "    # loss = pipeline.score(perf_conts, perf_y_col)\n",
    "    #print(f\"loss: {loss}\")\n",
    "\n",
    "# pipeline.fit(conts_train, y_train)\n",
    "probas = pipeline.predict(perf_conts)\n",
    "confidence_threshold = best_params['confidence_threshold']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109e37c",
   "metadata": {},
   "source": [
    "Value:  0.37491718013436764\n",
    "\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 39\n",
    "    dropout: 0.47875406200808335\n",
    "    lr: 0.009997751942238913\n",
    "    \n",
    "\n",
    "\n",
    "Value:  0.3759073484440955\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 68\n",
    "    dropout: 0.4497689844977892\n",
    "    lr: 0.007977206154472633\n",
    "    \n",
    "    \n",
    "    \n",
    "12/6\n",
    "\n",
    "Trial 206 finished with value: 0.547218605316966 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.05966702820817666, 'n_epochs': 379, 'dropout': 0.36961850006275193, 'lr': 0.008649806179332952}. Best is trial 206 with value: 0.547218605316966.\n",
    "\n",
    "[I 2024-12-06 12:49:28,047] Trial 579 finished with value: 0.5335308702482566 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.059979796814548306, 'n_epochs': 481, 'dropout': 0.2511747953677191, 'lr': 0.007942836869449217}. Best is trial 579 with value: 0.5335308702482566.\n",
    "\n",
    "\n",
    "[I 2024-12-06 14:53:00,850] Trial 385 finished with value: 0.5547767877242975 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.003263372268063613, 'n_epochs': 300, 'dropout': 0.3153661030384182, 'lr': 0.00593138298730814}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:32:38,969] Trial 583 finished with value: 0.550872165273167 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.010458110701511005, 'n_epochs': 336, 'dropout': 0.3188974735143638, 'lr': 0.006976522077116529}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:55:26,133] Trial 669 finished with value: 0.5645423555160363 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.0243907527056759, 'n_epochs': 370, 'dropout': 0.32998724447261185, 'lr': 0.0075018456671685696}. Best is trial 669 with value: 0.5645423555160363.\n",
    "\n",
    "[I 2024-12-06 20:33:46,555] Trial 1737 finished with value: 0.5716002919237433 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.015368961704784596, 'n_epochs': 328, 'dropout': 0.348927921024466, 'lr': 0.009575624984802092}. Best is trial 1737 with value: 0.5716002919237433.\n",
    "\n",
    "\n",
    "[I 2024-12-06 21:17:06,545] Trial 1889 finished with value: 0.5739803740995499 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.014029751567812504, 'n_epochs': 357, 'dropout': 0.34275064196127053, 'lr': 0.008692336113071646}. Best is trial 1889 with value: 0.5739803740995499.\n",
    "\n",
    "[I 2024-12-10 09:39:54,796] Trial 1612 finished with value: 0.5748324966932515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.003855147984840053, 'dropout': 0.3182765851196762, 'lr': 0.008210651343970551, 'n_epochs': 219}. Best is trial 1612 with value: 0.5748324966932515.\n",
    "\n",
    "\n",
    "\n",
    "Trial 1749 finished with value: 0.5772962775717783 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328981",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_utils.backtest_model(pipeline, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.05, confidence_threshold=best_params['confidence_threshold'], show_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outside of confidence threshold\n",
    "mask = (probas < 0.5 - confidence_threshold) | (probas > 0.5 + confidence_threshold)\n",
    "predictions = np.where(mask, probas, np.nan)\n",
    "\n",
    "# Use numpy mask for nan values\n",
    "valid_mask = ~np.isnan(predictions)\n",
    "valid_predictions = predictions[valid_mask]\n",
    "valid_mask = valid_mask.flatten()\n",
    "perf_y_col_mask = perf_y_col[valid_mask]\n",
    "\n",
    "\n",
    "true_values = perf_y_col_mask[:,0].astype(np.int32)\n",
    "pred_values = valid_predictions.flatten()\n",
    "pred_values_int = np.rint(valid_predictions).flatten().astype(np.int32)\n",
    "\n",
    "model_win_prob = (1.0*(true_values == pred_values_int).sum()) / (true_values.shape[0])\n",
    "print(model_win_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d6ca8",
   "metadata": {},
   "source": [
    "# Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc8524f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.008, 0.01, 0.03],\n",
       "                         'max_depth': [3, 6, 9], 'min_child_weight': [1, 3],\n",
       "                         'n_estimators': [100, 200], 'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.008, 0.01, 0.03],           # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3, 6, 9],                      # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [100, 200],                  # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.8, 1.0],                     # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.8, 1.0],              # Same as above\n",
    "    'min_child_weight': [1, 3],                  # Removed 5 as it might be too restrictive\n",
    "}\n",
    "aparam_grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],        # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3],                         # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [300, 350, 400],             # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.5, 0.6, 0.7],                # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],         # Same as above\n",
    "    'min_child_weight': [3, 4],                  # Removed 5 as it might be too restrictive\n",
    "}\n",
    "\n",
    "# model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create a custom scorer using the F1 score\n",
    "# f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "# Tune hyperparameters using GridSearchCV with the custom F1 scorer\n",
    "# grid_search = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=5, verbose=1)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "grid_search.fit(conts_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acdae5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee2ec9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.49255\n",
      "[1]\tvalidation_0-rmse:0.49108\n",
      "[2]\tvalidation_0-rmse:0.48967\n",
      "[3]\tvalidation_0-rmse:0.48835\n",
      "[4]\tvalidation_0-rmse:0.48711\n",
      "[5]\tvalidation_0-rmse:0.48584\n",
      "[6]\tvalidation_0-rmse:0.48473\n",
      "[7]\tvalidation_0-rmse:0.48363\n",
      "[8]\tvalidation_0-rmse:0.48256\n",
      "[9]\tvalidation_0-rmse:0.48160\n",
      "[10]\tvalidation_0-rmse:0.48067\n",
      "[11]\tvalidation_0-rmse:0.47977\n",
      "[12]\tvalidation_0-rmse:0.47888\n",
      "[13]\tvalidation_0-rmse:0.47808\n",
      "[14]\tvalidation_0-rmse:0.47732\n",
      "[15]\tvalidation_0-rmse:0.47657\n",
      "[16]\tvalidation_0-rmse:0.47587\n",
      "[17]\tvalidation_0-rmse:0.47518\n",
      "[18]\tvalidation_0-rmse:0.47454\n",
      "[19]\tvalidation_0-rmse:0.47394\n",
      "[20]\tvalidation_0-rmse:0.47332\n",
      "[21]\tvalidation_0-rmse:0.47277\n",
      "[22]\tvalidation_0-rmse:0.47221\n",
      "[23]\tvalidation_0-rmse:0.47169\n",
      "[24]\tvalidation_0-rmse:0.47117\n",
      "[25]\tvalidation_0-rmse:0.47069\n",
      "[26]\tvalidation_0-rmse:0.47016\n",
      "[27]\tvalidation_0-rmse:0.46968\n",
      "[28]\tvalidation_0-rmse:0.46928\n",
      "[29]\tvalidation_0-rmse:0.46889\n",
      "[30]\tvalidation_0-rmse:0.46850\n",
      "[31]\tvalidation_0-rmse:0.46809\n",
      "[32]\tvalidation_0-rmse:0.46771\n",
      "[33]\tvalidation_0-rmse:0.46732\n",
      "[34]\tvalidation_0-rmse:0.46698\n",
      "[35]\tvalidation_0-rmse:0.46663\n",
      "[36]\tvalidation_0-rmse:0.46628\n",
      "[37]\tvalidation_0-rmse:0.46597\n",
      "[38]\tvalidation_0-rmse:0.46569\n",
      "[39]\tvalidation_0-rmse:0.46537\n",
      "[40]\tvalidation_0-rmse:0.46504\n",
      "[41]\tvalidation_0-rmse:0.46473\n",
      "[42]\tvalidation_0-rmse:0.46446\n",
      "[43]\tvalidation_0-rmse:0.46416\n",
      "[44]\tvalidation_0-rmse:0.46392\n",
      "[45]\tvalidation_0-rmse:0.46365\n",
      "[46]\tvalidation_0-rmse:0.46338\n",
      "[47]\tvalidation_0-rmse:0.46313\n",
      "[48]\tvalidation_0-rmse:0.46287\n",
      "[49]\tvalidation_0-rmse:0.46260\n",
      "[50]\tvalidation_0-rmse:0.46235\n",
      "[51]\tvalidation_0-rmse:0.46214\n",
      "[52]\tvalidation_0-rmse:0.46191\n",
      "[53]\tvalidation_0-rmse:0.46168\n",
      "[54]\tvalidation_0-rmse:0.46144\n",
      "[55]\tvalidation_0-rmse:0.46122\n",
      "[56]\tvalidation_0-rmse:0.46101\n",
      "[57]\tvalidation_0-rmse:0.46080\n",
      "[58]\tvalidation_0-rmse:0.46063\n",
      "[59]\tvalidation_0-rmse:0.46042\n",
      "[60]\tvalidation_0-rmse:0.46023\n",
      "[61]\tvalidation_0-rmse:0.46002\n",
      "[62]\tvalidation_0-rmse:0.45984\n",
      "[63]\tvalidation_0-rmse:0.45963\n",
      "[64]\tvalidation_0-rmse:0.45939\n",
      "[65]\tvalidation_0-rmse:0.45922\n",
      "[66]\tvalidation_0-rmse:0.45904\n",
      "[67]\tvalidation_0-rmse:0.45885\n",
      "[68]\tvalidation_0-rmse:0.45863\n",
      "[69]\tvalidation_0-rmse:0.45847\n",
      "[70]\tvalidation_0-rmse:0.45828\n",
      "[71]\tvalidation_0-rmse:0.45810\n",
      "[72]\tvalidation_0-rmse:0.45784\n",
      "[73]\tvalidation_0-rmse:0.45765\n",
      "[74]\tvalidation_0-rmse:0.45755\n",
      "[75]\tvalidation_0-rmse:0.45739\n",
      "[76]\tvalidation_0-rmse:0.45721\n",
      "[77]\tvalidation_0-rmse:0.45708\n",
      "[78]\tvalidation_0-rmse:0.45691\n",
      "[79]\tvalidation_0-rmse:0.45672\n",
      "[80]\tvalidation_0-rmse:0.45657\n",
      "[81]\tvalidation_0-rmse:0.45639\n",
      "[82]\tvalidation_0-rmse:0.45621\n",
      "[83]\tvalidation_0-rmse:0.45601\n",
      "[84]\tvalidation_0-rmse:0.45584\n",
      "[85]\tvalidation_0-rmse:0.45565\n",
      "[86]\tvalidation_0-rmse:0.45549\n",
      "[87]\tvalidation_0-rmse:0.45528\n",
      "[88]\tvalidation_0-rmse:0.45511\n",
      "[89]\tvalidation_0-rmse:0.45495\n",
      "[90]\tvalidation_0-rmse:0.45481\n",
      "[91]\tvalidation_0-rmse:0.45462\n",
      "[92]\tvalidation_0-rmse:0.45441\n",
      "[93]\tvalidation_0-rmse:0.45424\n",
      "[94]\tvalidation_0-rmse:0.45411\n",
      "[95]\tvalidation_0-rmse:0.45394\n",
      "[96]\tvalidation_0-rmse:0.45377\n",
      "[97]\tvalidation_0-rmse:0.45359\n",
      "[98]\tvalidation_0-rmse:0.45338\n",
      "[99]\tvalidation_0-rmse:0.45322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train final model w/ early stopping\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10,\n",
    "    # **grid_search.best_params_,\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 31.4%\n",
    "    # {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 30.9%\n",
    "    # {'colsample_bytree': 1.0, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.6}\n",
    ")\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    # **grid_search.best_params_,\n",
    "    # 67.3 w/ kelly adjustments 0.2, 0.01\n",
    "    # {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 350, 'subsample': 0.6}\n",
    "    # 67.2, dd 28.68 kelly 0.25, 0.014\n",
    "    # **{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 350, 'subsample': 0.5}\n",
    "    \n",
    "   # **{'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.5}\n",
    "    **{'colsample_bytree': 1.0, 'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "\n",
    ")\n",
    "model.fit(\n",
    "    conts_train,\n",
    "    y_train,\n",
    "    eval_set=[(conts_train, y_train)], # , (holdout_conts, holdout_y)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef6e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 8.57      , 1.08      , 3.98666667, 1.23444444])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perf_conts.shape\n",
    "perf_y_col.shape\n",
    "perf_y_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "177675db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-10-22' 'MIA' 'PHI']\n",
      "2023-10-22: w_odds:1.30 acct_val: 1000.00 usable cash: 900.00 won: True\n",
      "2023-10-22: w_odds:1.39 acct_val: 1030.27 usable cash: 796.97 won: True\n",
      "2023-10-22: w_odds:1.66 acct_val: 1070.90 usable cash: 689.88 won: False\n",
      "2023-10-22: w_odds:1.09 acct_val: 963.81 usable cash: 593.50 won: True\n",
      "2023-10-22: w_odds:2.05 acct_val: 972.74 usable cash: 496.23 won: False\n",
      "['2023-10-26' 'TAM' 'BUF']\n",
      "2023-10-26: w_odds:1.63 acct_val: 875.47 usable cash: 787.92 won: True\n",
      "2023-10-26: w_odds:1.83 acct_val: 930.78 usable cash: 694.84 won: False\n",
      "2023-10-26: w_odds:1.61 acct_val: 837.71 usable cash: 611.07 won: False\n",
      "2023-10-26: w_odds:1.22 acct_val: 753.93 usable cash: 535.68 won: True\n",
      "2023-10-26: w_odds:1.55 acct_val: 770.85 usable cash: 458.59 won: False\n",
      "2023-10-26: w_odds:2.15 acct_val: 693.77 usable cash: 389.21 won: True\n",
      "['2023-10-29' 'NWE' 'MIA']\n",
      "2023-10-29: w_odds:1.20 acct_val: 773.51 usable cash: 696.16 won: True\n",
      "['2023-10-30' 'LVR' 'DET']\n",
      "2023-10-30: w_odds:1.26 acct_val: 788.93 usable cash: 717.21 won: True\n",
      "2023-10-30: w_odds:1.60 acct_val: 807.62 usable cash: 643.79 won: True\n",
      "2023-10-30: w_odds:1.31 acct_val: 851.76 usable cash: 566.35 won: True\n",
      "2023-10-30: w_odds:1.32 acct_val: 875.38 usable cash: 486.77 won: True\n",
      "2023-10-30: w_odds:1.89 acct_val: 901.14 usable cash: 404.85 won: False\n",
      "2023-10-30: w_odds:1.74 acct_val: 819.22 usable cash: 330.38 won: False\n",
      "2023-10-30: w_odds:2.15 acct_val: 744.75 usable cash: 262.67 won: True\n",
      "2023-10-30: w_odds:1.49 acct_val: 822.78 usable cash: 187.87 won: True\n",
      "2023-10-30: w_odds:1.71 acct_val: 859.71 usable cash: 109.72 won: True\n",
      "2023-10-30: w_odds:1.22 acct_val: 915.54 usable cash: 26.49 won: True\n",
      "2023-10-30: w_odds:1.21 acct_val: 933.70 usable cash: 0.00 won: True\n",
      "['2023-11-02' 'TEN' 'PIT']\n",
      "2023-11-02: w_odds:1.30 acct_val: 939.22 usable cash: 845.30 won: True\n",
      "['2023-11-05' 'BUF' 'CIN']\n",
      "2023-11-05: w_odds:1.57 acct_val: 967.40 usable cash: 870.66 won: True\n",
      "['2023-11-06' 'LAC' 'NYJ']\n",
      "2023-11-06: w_odds:1.79 acct_val: 1022.66 usable cash: 920.40 won: False\n",
      "2023-11-06: w_odds:1.58 acct_val: 920.40 usable cash: 828.36 won: True\n",
      "2023-11-06: w_odds:1.36 acct_val: 973.67 usable cash: 730.99 won: True\n",
      "2023-11-06: w_odds:1.13 acct_val: 1009.02 usable cash: 630.09 won: True\n",
      "2023-11-06: w_odds:1.84 acct_val: 1021.89 usable cash: 527.90 won: True\n",
      "2023-11-06: w_odds:1.81 acct_val: 1107.66 usable cash: 417.13 won: True\n",
      "2023-11-06: w_odds:1.90 acct_val: 1197.45 usable cash: 297.39 won: True\n",
      "2023-11-06: w_odds:1.23 acct_val: 1305.41 usable cash: 166.85 won: True\n",
      "2023-11-06: w_odds:1.68 acct_val: 1335.35 usable cash: 33.31 won: True\n",
      "2023-11-06: w_odds:1.51 acct_val: 1425.99 usable cash: 0.00 won: True\n",
      "['2023-11-09' 'CAR' 'CHI']\n",
      "2023-11-09: w_odds:1.57 acct_val: 1442.93 usable cash: 1298.64 won: True\n",
      "['2023-11-12' 'NYG' 'DAL']\n",
      "2023-11-12: w_odds:1.56 acct_val: 1525.63 usable cash: 1373.07 won: True\n",
      "['2023-11-16' 'CIN' 'BAL']\n",
      "2023-11-16: w_odds:1.05 acct_val: 1610.69 usable cash: 1449.62 won: True\n",
      "2023-11-16: w_odds:1.93 acct_val: 1617.94 usable cash: 1287.82 won: False\n",
      "2023-11-16: w_odds:1.38 acct_val: 1456.14 usable cash: 1142.21 won: True\n",
      "2023-11-16: w_odds:1.69 acct_val: 1511.75 usable cash: 991.04 won: True\n",
      "2023-11-16: w_odds:1.74 acct_val: 1616.15 usable cash: 829.42 won: False\n",
      "2023-11-16: w_odds:1.58 acct_val: 1454.54 usable cash: 683.97 won: False\n",
      "2023-11-16: w_odds:1.58 acct_val: 1309.08 usable cash: 553.06 won: True\n",
      "2023-11-16: w_odds:2.10 acct_val: 1385.42 usable cash: 414.52 won: True\n",
      "2023-11-16: w_odds:1.81 acct_val: 1538.25 usable cash: 260.69 won: True\n",
      "['2023-11-19' 'LVR' 'MIA']\n",
      "2023-11-19: w_odds:1.50 acct_val: 1663.26 usable cash: 1496.93 won: True\n",
      "['2023-11-23' 'WAS' 'DAL']\n",
      "2023-11-23: w_odds:1.11 acct_val: 1746.75 usable cash: 1572.08 won: True\n",
      "2023-11-23: w_odds:1.25 acct_val: 1765.85 usable cash: 1395.49 won: True\n",
      "2023-11-23: w_odds:1.26 acct_val: 1810.70 usable cash: 1214.42 won: True\n",
      "2023-11-23: w_odds:1.32 acct_val: 1858.39 usable cash: 1028.58 won: True\n",
      "2023-11-23: w_odds:1.41 acct_val: 1918.35 usable cash: 836.75 won: True\n",
      "2023-11-23: w_odds:1.71 acct_val: 1996.87 usable cash: 637.06 won: True\n",
      "2023-11-23: w_odds:1.68 acct_val: 2139.58 usable cash: 423.10 won: False\n",
      "2023-11-23: w_odds:1.12 acct_val: 1925.63 usable cash: 230.54 won: True\n",
      "2023-11-23: w_odds:1.74 acct_val: 1947.83 usable cash: 35.76 won: True\n",
      "2023-11-23: w_odds:1.16 acct_val: 2092.36 usable cash: 0.00 won: True\n",
      "['2023-11-24' 'MIA' 'NYJ']\n",
      "2023-11-24: w_odds:1.13 acct_val: 2098.06 usable cash: 1888.25 won: True\n",
      "2023-11-24: w_odds:1.30 acct_val: 2125.06 usable cash: 1675.75 won: True\n",
      "['2023-11-26' 'TAM' 'IND']\n",
      "2023-11-26: w_odds:1.20 acct_val: 2189.80 usable cash: 1970.82 won: True\n",
      "['2023-11-30' 'SEA' 'DAL']\n",
      "2023-11-30: w_odds:1.68 acct_val: 2234.62 usable cash: 2011.16 won: True\n",
      "2023-11-30: w_odds:1.65 acct_val: 2385.97 usable cash: 1772.56 won: False\n",
      "2023-11-30: w_odds:1.68 acct_val: 2147.38 usable cash: 1557.82 won: True\n",
      "2023-11-30: w_odds:2.10 acct_val: 2292.40 usable cash: 1328.58 won: False\n",
      "2023-11-30: w_odds:1.56 acct_val: 2063.16 usable cash: 1122.26 won: True\n",
      "2023-11-30: w_odds:1.78 acct_val: 2177.73 usable cash: 904.49 won: False\n",
      "2023-11-30: w_odds:1.60 acct_val: 1959.96 usable cash: 708.50 won: True\n",
      "2023-11-30: w_odds:1.86 acct_val: 2076.64 usable cash: 500.83 won: False\n",
      "2023-11-30: w_odds:1.21 acct_val: 1868.98 usable cash: 313.93 won: True\n",
      "2023-11-30: w_odds:1.74 acct_val: 1908.60 usable cash: 123.07 won: False\n",
      "['2023-12-03' 'SFO' 'PHI']\n",
      "2023-12-03: w_odds:1.21 acct_val: 1717.74 usable cash: 1545.97 won: True\n",
      "['2023-12-10' 'PHI' 'DAL']\n",
      "2023-12-10: w_odds:1.63 acct_val: 1753.12 usable cash: 1577.81 won: True\n",
      "2023-12-10: w_odds:1.57 acct_val: 1863.69 usable cash: 1391.44 won: True\n",
      "2023-12-10: w_odds:1.44 acct_val: 1969.17 usable cash: 1194.53 won: True\n",
      "2023-12-10: w_odds:1.76 acct_val: 2056.08 usable cash: 988.92 won: True\n",
      "2023-12-10: w_odds:1.50 acct_val: 2212.75 usable cash: 767.64 won: False\n",
      "2023-12-10: w_odds:1.82 acct_val: 1991.48 usable cash: 568.50 won: False\n",
      "2023-12-10: w_odds:1.46 acct_val: 1792.33 usable cash: 389.26 won: True\n",
      "2023-12-10: w_odds:1.53 acct_val: 1875.57 usable cash: 201.70 won: False\n",
      "2023-12-10: w_odds:1.23 acct_val: 1688.02 usable cash: 32.90 won: True\n",
      "['2023-12-14' 'LAC' 'LVR']\n",
      "2023-12-14: w_odds:1.54 acct_val: 1726.95 usable cash: 1554.26 won: True\n",
      "2023-12-14: w_odds:1.28 acct_val: 1820.44 usable cash: 1372.21 won: True\n",
      "2023-12-14: w_odds:2.05 acct_val: 1871.80 usable cash: 1185.03 won: False\n",
      "2023-12-14: w_odds:1.71 acct_val: 1684.62 usable cash: 1016.57 won: False\n",
      "2023-12-14: w_odds:1.65 acct_val: 1516.16 usable cash: 864.96 won: True\n",
      "2023-12-14: w_odds:1.10 acct_val: 1615.11 usable cash: 703.44 won: True\n",
      "2023-12-14: w_odds:1.40 acct_val: 1631.70 usable cash: 540.27 won: True\n",
      "2023-12-14: w_odds:2.06 acct_val: 1697.07 usable cash: 370.57 won: False\n",
      "2023-12-14: w_odds:1.65 acct_val: 1527.36 usable cash: 217.83 won: True\n",
      "['2023-12-16' 'DEN' 'DET']\n",
      "2023-12-16: w_odds:1.64 acct_val: 1626.13 usable cash: 1463.52 won: False\n",
      "['2023-12-17' 'WAS' 'LAR']\n",
      "2023-12-17: w_odds:1.43 acct_val: 1463.52 usable cash: 1317.17 won: True\n",
      "2023-12-17: w_odds:1.83 acct_val: 1525.83 usable cash: 1164.59 won: True\n",
      "2023-12-17: w_odds:1.60 acct_val: 1653.12 usable cash: 999.27 won: True\n",
      "['2023-12-21' 'NOR' 'LAR']\n",
      "2023-12-21: w_odds:1.33 acct_val: 1752.07 usable cash: 1576.87 won: True\n",
      "2023-12-21: w_odds:1.14 acct_val: 1809.64 usable cash: 1395.90 won: True\n",
      "2023-12-21: w_odds:1.38 acct_val: 1834.20 usable cash: 1212.48 won: True\n",
      "2023-12-21: w_odds:1.48 acct_val: 1904.56 usable cash: 1022.03 won: True\n",
      "2023-12-21: w_odds:1.29 acct_val: 1995.70 usable cash: 822.46 won: True\n",
      "2023-12-21: w_odds:1.20 acct_val: 2053.29 usable cash: 617.13 won: True\n",
      "2023-12-21: w_odds:1.71 acct_val: 2094.07 usable cash: 407.72 won: False\n",
      "2023-12-21: w_odds:1.67 acct_val: 1884.66 usable cash: 219.25 won: True\n",
      "['2023-12-23' 'BUF' 'LAC']\n",
      "2023-12-23: w_odds:1.48 acct_val: 2011.07 usable cash: 1809.96 won: True\n",
      "['2023-12-24' 'DET' 'MIN']\n",
      "2023-12-24: w_odds:1.12 acct_val: 2107.17 usable cash: 1896.45 won: True\n",
      "['2023-12-25' 'NYG' 'PHI']\n",
      "2023-12-25: w_odds:1.69 acct_val: 2133.35 usable cash: 1920.02 won: False\n",
      "2023-12-25: w_odds:1.66 acct_val: 1920.02 usable cash: 1728.02 won: True\n",
      "2023-12-25: w_odds:1.51 acct_val: 2046.74 usable cash: 1523.34 won: True\n",
      "2023-12-25: w_odds:1.63 acct_val: 2151.12 usable cash: 1308.23 won: False\n",
      "2023-12-25: w_odds:2.12 acct_val: 1936.01 usable cash: 1114.63 won: False\n",
      "2023-12-25: w_odds:1.80 acct_val: 1742.41 usable cash: 940.39 won: True\n",
      "2023-12-25: w_odds:1.64 acct_val: 1881.80 usable cash: 752.21 won: False\n",
      "2023-12-25: w_odds:1.47 acct_val: 1693.62 usable cash: 582.85 won: True\n",
      "2023-12-25: w_odds:1.60 acct_val: 1773.22 usable cash: 405.52 won: True\n",
      "['2023-12-28' 'NYJ' 'CLE']\n",
      "2023-12-28: w_odds:1.11 acct_val: 1880.50 usable cash: 1692.45 won: True\n",
      "['2023-12-30' 'DET' 'DAL']\n",
      "2023-12-30: w_odds:1.30 acct_val: 1902.00 usable cash: 1711.80 won: True\n",
      "['2023-12-31' 'TEN' 'HOU']\n",
      "2023-12-31: w_odds:1.44 acct_val: 1958.38 usable cash: 1762.54 won: True\n",
      "['2024-01-06' 'PIT' 'BAL']\n",
      "2024-01-06: w_odds:1.42 acct_val: 2043.56 usable cash: 1857.79 won: True\n",
      "2024-01-06: w_odds:1.67 acct_val: 2120.93 usable cash: 1664.97 won: False\n",
      "2024-01-06: w_odds:1.51 acct_val: 1928.12 usable cash: 1489.69 won: True\n",
      "2024-01-06: w_odds:1.09 acct_val: 2017.51 usable cash: 1306.28 won: True\n",
      "2024-01-06: w_odds:1.29 acct_val: 2033.36 usable cash: 1121.43 won: True\n",
      "2024-01-06: w_odds:1.54 acct_val: 2086.84 usable cash: 931.72 won: True\n",
      "2024-01-06: w_odds:1.55 acct_val: 2189.01 usable cash: 732.72 won: True\n",
      "2024-01-06: w_odds:1.57 acct_val: 2298.60 usable cash: 523.75 won: True\n",
      "2024-01-06: w_odds:1.35 acct_val: 2418.68 usable cash: 303.87 won: True\n",
      "2024-01-06: w_odds:1.91 acct_val: 2494.85 usable cash: 77.07 won: False\n",
      "2024-01-06: w_odds:1.10 acct_val: 2268.05 usable cash: 0.00 won: True\n",
      "['2024-01-07' 'BUF' 'MIA']\n",
      "2024-01-07: w_odds:1.63 acct_val: 2275.42 usable cash: 2047.88 won: False\n",
      "2024-01-07: w_odds:1.80 acct_val: 2047.88 usable cash: 1843.09 won: False\n",
      "['2024-01-13' 'MIA' 'KAN']\n",
      "2024-01-13: w_odds:1.68 acct_val: 1843.09 usable cash: 1658.78 won: False\n",
      "2024-01-13: w_odds:1.52 acct_val: 1658.78 usable cash: 1492.90 won: True\n",
      "2024-01-13: w_odds:1.66 acct_val: 1744.33 usable cash: 1318.47 won: True\n",
      "2024-01-13: w_odds:1.11 acct_val: 1858.71 usable cash: 1132.60 won: True\n",
      "2024-01-13: w_odds:1.29 acct_val: 1879.02 usable cash: 944.70 won: True\n",
      "2024-01-13: w_odds:1.67 acct_val: 1933.78 usable cash: 751.32 won: True\n",
      "2024-01-13: w_odds:1.41 acct_val: 2063.90 usable cash: 544.93 won: True\n",
      "2024-01-13: w_odds:1.57 acct_val: 2148.66 usable cash: 330.07 won: True\n",
      "2024-01-13: w_odds:1.58 acct_val: 2270.98 usable cash: 102.97 won: True\n",
      "['2024-01-14' 'LAR' 'DET']\n",
      "2024-01-14: w_odds:1.44 acct_val: 2402.38 usable cash: 2162.14 won: True\n",
      "2024-01-14: w_odds:2.19 acct_val: 2507.05 usable cash: 1911.43 won: True\n",
      "['2024-01-15' 'PIT' 'BUF']\n",
      "2024-01-15: w_odds:1.61 acct_val: 2804.43 usable cash: 2523.98 won: True\n",
      "['2024-01-20' 'GNB' 'SFO']\n",
      "2024-01-20: w_odds:1.19 acct_val: 2974.69 usable cash: 2677.23 won: True\n",
      "['2024-01-21' 'TAM' 'DET']\n",
      "2024-01-21: w_odds:1.20 acct_val: 3031.85 usable cash: 2728.67 won: True\n",
      "2024-01-21: w_odds:1.21 acct_val: 3092.06 usable cash: 2419.46 won: True\n",
      "['2024-01-28' 'DET' 'SFO']\n",
      "2024-01-28: w_odds:1.35 acct_val: 3156.99 usable cash: 2841.29 won: True\n",
      "['2024-02-11' 'SFO' 'KAN']\n",
      "2024-02-11: w_odds:1.29 acct_val: 3266.36 usable cash: 2939.72 won: True\n",
      "['2024-10-10' 'SFO' 'SEA']\n",
      "2024-10-10: w_odds:2.08 acct_val: 3359.68 usable cash: 3023.71 won: True\n",
      "['2024-10-13' 'JAX' 'CHI']\n",
      "2024-10-13: w_odds:1.51 acct_val: 3723.25 usable cash: 3350.92 won: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'final_value': 3350.9208786503746,\n",
       " 'roi': 2.3509208786503746,\n",
       " 'win_rate': 0.7619047619047619,\n",
       " 'max_drawdown': 0.3866151453314816,\n",
       " 'total_bets': 147}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for test data\n",
    "# model = grid_search.best_estimator_\n",
    "y_pred = model.predict(perf_conts)\n",
    "\n",
    "nfl_utils.backtest_model(model, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.1, \n",
    "                   confidence_threshold=0.0, show_plot=True, max_won_odds=2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make confusion matrix\n",
    "cm = confusion_matrix(perf_y_col[:,0], y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7025ece",
   "metadata": {},
   "source": [
    "## Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a1a349",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
