{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70409bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from NFLUtils import NFLUtils\n",
    "import optuna\n",
    "%matplotlib inline\n",
    "nfl_utils = NFLUtils()\n",
    "\n",
    "# ANN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# XGBoost \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn as sns # confusion matrix\n",
    "\n",
    "# Set device to GPU if available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556dd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff2364",
   "metadata": {},
   "source": [
    "### Load CSV\n",
    "cp Combined.csv ~/drive/Notes/ML/Pytorch/footballData/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfebbf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5533 entries, 0 to 5532\n",
      "Columns: 209 entries, Unnamed: 0 to D_datediff\n",
      "dtypes: float64(133), int64(67), object(9)\n",
      "memory usage: 8.8+ MB\n",
      "df after perf set removed: (5333, 209)\n",
      "df perf set size (200, 209)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./footballData/CombinedSlidingWindow4.csv\", index_col=False, low_memory=False)\n",
    "\n",
    "# Shuffle dataFrame (don't do this?)\n",
    "# df = shuffle(df, random_state=101)\n",
    "# df.head()\n",
    "df.info()\n",
    "\n",
    "test_performance_size = 200\n",
    "test_performance_df = df[df.shape[0]-test_performance_size:]\n",
    "df = df[:df.shape[0]-test_performance_size]\n",
    "print(f'df after perf set removed: {df.shape}')\n",
    "print(f'df perf set size {test_performance_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26c9e0",
   "metadata": {},
   "source": [
    "### Remove items from performance set where you have no odds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593aec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_performance_df = test_performance_df.loc[test_performance_df['D_start_odds']!= 0]\n",
    "# test_performance_size = test_performance_df.shape[0]\n",
    "# test_performance_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc250",
   "metadata": {},
   "source": [
    "# Columns to use\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1174d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>H_Q1</th>\n",
       "      <th>H_Q2</th>\n",
       "      <th>H_Q3</th>\n",
       "      <th>H_Q4</th>\n",
       "      <th>H_OT</th>\n",
       "      <th>H_Final</th>\n",
       "      <th>...</th>\n",
       "      <th>D_punting_lng</th>\n",
       "      <th>D_punting_pnt</th>\n",
       "      <th>D_punting_yds</th>\n",
       "      <th>D_scoring_fga</th>\n",
       "      <th>D_scoring_fgm</th>\n",
       "      <th>D_scoring_xpa</th>\n",
       "      <th>D_scoring_xpm</th>\n",
       "      <th>D_start_odds</th>\n",
       "      <th>D_halftime_odds</th>\n",
       "      <th>D_datediff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>ARI</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6.576</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>1.424</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-1.528</td>\n",
       "      <td>-1.528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>CIN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936</td>\n",
       "      <td>0.392</td>\n",
       "      <td>19.296</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.520</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.256</td>\n",
       "      <td>-5.080</td>\n",
       "      <td>-237.168</td>\n",
       "      <td>2.176</td>\n",
       "      <td>1.376</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>-67.480</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-09</td>\n",
       "      <td>LAC</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>-81.712</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Season        Date Home_Team  H_Q1  H_Q2  H_Q3  H_Q4  H_OT  \\\n",
       "0         229    1995  1995-10-08       ARI     3     7    11     0     0   \n",
       "1         232    1995  1995-10-08       CIN     3     3     3     7     0   \n",
       "2         234    1995  1995-10-08       PIT     0     7     6     3     0   \n",
       "3         228    1995  1995-10-08       WAS    10     7     7    10     0   \n",
       "4         223    1995  1995-10-09       LAC     3    10     0    10     0   \n",
       "\n",
       "   H_Final  ... D_punting_lng  D_punting_pnt  D_punting_yds  D_scoring_fga  \\\n",
       "0       21  ...         6.576         -0.752        -25.640          1.424   \n",
       "1       16  ...         3.936          0.392         19.296          1.224   \n",
       "2       16  ...       -11.256         -5.080       -237.168          2.176   \n",
       "3       34  ...        -0.952         -1.120        -67.480          0.784   \n",
       "4       23  ...         2.944         -1.304        -81.712         -0.904   \n",
       "\n",
       "   D_scoring_fgm  D_scoring_xpa  D_scoring_xpm  D_start_odds  D_halftime_odds  \\\n",
       "0          1.024         -1.528         -1.528           0.0              0.0   \n",
       "1          0.744          1.520          1.520           0.0              0.0   \n",
       "2          1.376         -0.080         -0.080           0.0              0.0   \n",
       "3          0.784         -0.488         -0.488           0.0              0.0   \n",
       "4         -0.480         -0.408         -0.408           0.0              0.0   \n",
       "\n",
       "   D_datediff  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db79ec",
   "metadata": {},
   "source": [
    "## 1. Separate continuous, categorical, and label column names\n",
    "\n",
    "Pretty much everything is continuous. \n",
    "\n",
    "Note: the y_col is what you're trying to predict\n",
    "\n",
    "## Feature engineering\n",
    "New Columns\n",
    "- **h_win**: Home team won\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3960b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5333, 209)\n",
      "(5333, 59)\n",
      "(200, 5)\n",
      "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
      "5528    0.0         1.622         2.364              0.0              0.0\n",
      "5529    0.0         3.173         1.377              0.0              0.0\n",
      "5530    0.0         4.470         1.221              0.0              0.0\n",
      "5531    1.0         2.369         1.619              0.0              0.0\n",
      "5532    0.0         1.701         2.202              0.0              0.0\n",
      "      D_datediff  D_First_Downs  D_Rush  D_Yds  D_TDs  D_Cmp  D_Att  D_Yd  \\\n",
      "5528         0.0              8     -38     -1     13      5     51    -2   \n",
      "5529         0.0             -1     -45    -14     13     -1     79    -4   \n",
      "5530         0.0             -4     -46    -17     57      1     81    -7   \n",
      "5531         0.0             -2      78      7      0      2    -98     6   \n",
      "5532         0.0              7       8      4    -20     -1     11     9   \n",
      "\n",
      "      D_TD  D_INT  ...  D_punt_returns_ret  D_punt_returns_td  \\\n",
      "5528    -3     -1  ...           -0.042120                0.0   \n",
      "5529   -47      0  ...           -1.463857                0.0   \n",
      "5530   -82      1  ...           -0.816776                0.0   \n",
      "5531     5      1  ...           -0.297091                0.0   \n",
      "5532   109      1  ...            0.020735                0.0   \n",
      "\n",
      "      D_punt_returns_yds  D_punting_lng  D_punting_pnt  D_punting_yds  \\\n",
      "5528           -0.860678     -10.288913      -1.642740     -94.842075   \n",
      "5529          -10.443347       4.979253       0.211707       3.704291   \n",
      "5530           -0.655756      -0.960901       1.738123      78.530189   \n",
      "5531           12.030487      10.454111       0.711176      38.934519   \n",
      "5532           -1.534921      -2.231958      -1.295610     -69.996923   \n",
      "\n",
      "      D_scoring_fga  D_scoring_fgm  D_scoring_xpa  D_scoring_xpm  \n",
      "5528       1.242197       1.330447       1.449813       1.678750  \n",
      "5529      -0.990617      -0.634341      -0.807716      -0.789054  \n",
      "5530       0.291543       0.452790      -1.339396      -1.294153  \n",
      "5531      -0.661322      -0.984169      -1.169644      -1.241349  \n",
      "5532       0.916630       0.029206       1.434098       1.745706  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "cont_cols = [\n",
    "    # Home vs away days since last game\n",
    "    'H_datediff', 'V_datediff',\n",
    "    \n",
    "    # First Downs\n",
    "    'H_First_Downs', 'V_First_Downs',\n",
    "    \n",
    "    # Basic Stats\n",
    "    'H_Rush', 'V_Rush',\n",
    "    'H_Yds', 'V_Yds',\n",
    "    'H_TDs', 'V_TDs',\n",
    "    'H_Cmp', 'V_Cmp',\n",
    "    'H_Att', 'V_Att',\n",
    "    'H_Yd', 'V_Yd',\n",
    "    'H_TD', 'V_TD',\n",
    "    'H_INT', 'V_INT',\n",
    "    'H_Sacked', 'V_Sacked',\n",
    "    'H_Yards', 'V_Yards',\n",
    "    'H_Net_Pass_Yards', 'V_Net_Pass_Yards',\n",
    "    'H_Total_Yards', 'V_Total_Yards',\n",
    "    'H_Fumbles', 'V_Fumbles',\n",
    "    'H_Lost', 'V_Lost',\n",
    "    'H_Turnovers', 'V_Turnovers',\n",
    "    'H_Penalties', 'V_Penalties',\n",
    "    #'H_Third_Down_Conv', 'V_Third_Down_Conv',\n",
    "    #'H_Fourth_Down_Conv', 'V_Fourth_Down_Conv',\n",
    "    #'H_Time_of_Possession', 'V_Time_of_Possession',\n",
    "    \n",
    "    # Passing Detailed\n",
    "    'H_passing_att', 'V_passing_att',\n",
    "    'H_passing_cmp', 'V_passing_cmp',\n",
    "    'H_passing_int', 'V_passing_int',\n",
    "    'H_passing_lng', 'V_passing_lng',\n",
    "    'H_passing_sk', 'V_passing_sk',\n",
    "    'H_passing_td', 'V_passing_td',\n",
    "    'H_passing_yds', 'V_passing_yds',\n",
    "    \n",
    "    # Receiving\n",
    "    'H_receiving_lng', 'V_receiving_lng',\n",
    "    'H_receiving_td', 'V_receiving_td',\n",
    "    'H_receiving_yds', 'V_receiving_yds',\n",
    "    \n",
    "    # Rushing Detailed\n",
    "    'H_rushing_att', 'V_rushing_att',\n",
    "    'H_rushing_lng', 'V_rushing_lng',\n",
    "    'H_rushing_td', 'V_rushing_td',\n",
    "    'H_rushing_yds', 'V_rushing_yds',\n",
    "    \n",
    "    # Defense Interceptions\n",
    "    'H_def_interceptions_int', 'V_def_interceptions_int',\n",
    "    'H_def_interceptions_lng', 'V_def_interceptions_lng',\n",
    "    # 'H_def_interceptions_pd', 'V_def_interceptions_pd',\n",
    "    'H_def_interceptions_td', 'V_def_interceptions_td',\n",
    "    'H_def_interceptions_yds', 'V_def_interceptions_yds',\n",
    "    \n",
    "    # Defense Fumbles\n",
    "    'H_fumbles_ff', 'V_fumbles_ff',\n",
    "    'H_fumbles_fr', 'V_fumbles_fr',\n",
    "    'H_fumbles_td', 'V_fumbles_td',\n",
    "    'H_fumbles_yds', 'V_fumbles_yds',\n",
    "    \n",
    "    # Defense Tackles\n",
    "    'H_sk', 'V_sk',\n",
    "    'H_tackles_ast', 'V_tackles_ast',\n",
    "    'H_tackles_comb', 'V_tackles_comb',\n",
    "    # 'H_tackles_qbhits', 'V_tackles_qbhits',\n",
    "    'H_tackles_solo', 'V_tackles_solo',\n",
    "    # 'H_tackles_tfl', 'V_tackles_tfl',\n",
    "    \n",
    "    # Kick Returns\n",
    "    'H_kick_returns_lng', 'V_kick_returns_lng',\n",
    "    'H_kick_returns_rt', 'V_kick_returns_rt',\n",
    "    'H_kick_returns_td', 'V_kick_returns_td',\n",
    "    'H_kick_returns_yds', 'V_kick_returns_yds',\n",
    "    \n",
    "    # Punt Returns\n",
    "    'H_punt_returns_lng', 'V_punt_returns_lng',\n",
    "    'H_punt_returns_ret', 'V_punt_returns_ret',\n",
    "    'H_punt_returns_td', 'V_punt_returns_td',\n",
    "    'H_punt_returns_yds', 'V_punt_returns_yds',\n",
    "    \n",
    "    # Punting/Scoring\n",
    "    'H_punting_lng', 'V_punting_lng',\n",
    "    'H_punting_pnt', 'V_punting_pnt',\n",
    "    'H_punting_yds', 'V_punting_yds',\n",
    "    'H_scoring_fga', 'V_scoring_fga',\n",
    "    'H_scoring_fgm', 'V_scoring_fgm',\n",
    "    'H_scoring_xpa', 'V_scoring_xpa',\n",
    "    'H_scoring_xpm', 'V_scoring_xpm',\n",
    "    \n",
    "    # Odds\n",
    "    # 'H_start_odds', 'V_start_odds',\n",
    "    # 'H_halftime_odds', 'V_halftime_odds'\n",
    "]\n",
    "\n",
    "cont_cols = [\n",
    "    'D_datediff', # Days since last game (Home - visitor)\n",
    "    \n",
    "    # first downs\n",
    "    'D_First_Downs',\n",
    "    \n",
    "    # Basic Stats\n",
    "    'D_Rush',\n",
    "    'D_Yds',\n",
    "    'D_TDs',\n",
    "    'D_Cmp',\n",
    "    'D_Att',\n",
    "    'D_Yd',\n",
    "    'D_TD',\n",
    "    'D_INT',\n",
    "    'D_Sacked',\n",
    "    'D_Yards',\n",
    "    'D_Net_Pass_Yards',\n",
    "    'D_Total_Yards',\n",
    "    'D_Fumbles',\n",
    "    'D_Lost',\n",
    "    'D_Turnovers',\n",
    "    'D_Penalties',\n",
    "    \n",
    "    # Passing Detailed\n",
    "    'D_passing_att',\n",
    "    'D_passing_cmp',\n",
    "    'D_passing_int',\n",
    "    'D_passing_lng',\n",
    "    'D_passing_sk',\n",
    "    'D_passing_td',\n",
    "    'D_passing_yds',\n",
    "    \n",
    "    # Receiving\n",
    "    'D_receiving_lng',\n",
    "    'D_receiving_td',\n",
    "    'D_receiving_yds',\n",
    "    \n",
    "    # Rushing Detailed\n",
    "    'D_rushing_att',\n",
    "    'D_rushing_lng',\n",
    "    'D_rushing_td',\n",
    "    'D_rushing_yds',\n",
    "    \n",
    "    # Defense interceptions\n",
    "    'D_def_interceptions_int',\n",
    "    'D_def_interceptions_lng',\n",
    "    # 'D_def_interceptions_pd',\n",
    "    'D_def_interceptions_td',\n",
    "    'D_def_interceptions_yds',\n",
    "    \n",
    "    # Defense fumbles\n",
    "    'D_fumbles_ff',\n",
    "    'D_fumbles_fr',\n",
    "    'D_fumbles_td',\n",
    "    'D_fumbles_yds',\n",
    "    \n",
    "    # Defense tackles\n",
    "    'D_sk',\n",
    "    'D_tackles_ast',\n",
    "    'D_tackles_comb',\n",
    "    # 'D_tackles_qbhits',\n",
    "    'D_tackles_solo',\n",
    "    # 'D_tackles_tfl',\n",
    "    \n",
    "    # Kick Returns\n",
    "    'D_kick_returns_lng',\n",
    "    'D_kick_returns_rt',\n",
    "    'D_kick_returns_td',\n",
    "    'D_kick_returns_yds',\n",
    "    \n",
    "    # Punt Returns\n",
    "    'D_punt_returns_lng',\n",
    "    'D_punt_returns_ret',\n",
    "    'D_punt_returns_td',\n",
    "    'D_punt_returns_yds',\n",
    "    \n",
    "    # Punting / Scoring\n",
    "    'D_punting_lng',\n",
    "    'D_punting_pnt',\n",
    "    'D_punting_yds',\n",
    "    'D_scoring_fga',\n",
    "    'D_scoring_fgm',\n",
    "    'D_scoring_xpa',\n",
    "    'D_scoring_xpm'\n",
    "]\n",
    "\n",
    "\n",
    "y_col = ['H_Won']\n",
    "y_col_perf = ['H_Won', 'H_start_odds', 'V_start_odds', 'H_halftime_odds', 'V_halftime_odds']\n",
    "\n",
    "\n",
    "# create cont_df and y_df from the df\n",
    "print(df.shape)\n",
    "cont_df = df[cont_cols]\n",
    "y_df = df[y_col]\n",
    "\n",
    "# test performance set\n",
    "perf_conts_df = test_performance_df[cont_cols]\n",
    "perf_y_df = test_performance_df[y_col_perf]\n",
    "perf_date_df = test_performance_df[['Date','Home_Team', 'Visitor_Team']]\n",
    "\n",
    "# print(cont_df.dtypes)\n",
    "print(cont_df.shape)\n",
    "print(perf_y_df.shape)\n",
    "print(perf_y_df.tail())\n",
    "print(perf_conts_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0a853",
   "metadata": {},
   "source": [
    "## Monotone constraints dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147aeb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1)\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "monotone_constraints = {\n",
    "    # Time between games - More rest is better\n",
    "    'D_datediff': 1,\n",
    "    \n",
    "    # Offensive positive indicators\n",
    "    'D_First_Downs': 1,\n",
    "    'D_Rush': 1,\n",
    "    'D_Yds': 1,\n",
    "    'D_TDs': 1,\n",
    "    'D_Cmp': 1,\n",
    "    'D_Yd': 1,\n",
    "    'D_TD': 1,\n",
    "    'D_Net_Pass_Yards': 1,\n",
    "    'D_Total_Yards': 1,\n",
    "    \n",
    "    # Negative indicators\n",
    "    'D_INT': -1,\n",
    "    'D_Sacked': -1,\n",
    "    'D_Fumbles': -1,\n",
    "    'D_Lost': -1,\n",
    "    'D_Turnovers': -1,\n",
    "    'D_Penalties': -1,\n",
    "    \n",
    "    # Passing detail - positive\n",
    "    'D_passing_cmp': 1,\n",
    "    'D_passing_td': 1,\n",
    "    'D_passing_yds': 1,\n",
    "    'D_passing_lng': 1,\n",
    "    \n",
    "    # Passing detail - negative\n",
    "    'D_passing_int': -1,\n",
    "    'D_passing_sk': -1,\n",
    "    \n",
    "    # Receiving/Rushing - all positive\n",
    "    'D_receiving_td': 1,\n",
    "    'D_receiving_yds': 1,\n",
    "    'D_receiving_lng': 1,\n",
    "    'D_rushing_td': 1,\n",
    "    'D_rushing_yds': 1,\n",
    "    'D_rushing_lng': 1,\n",
    "    \n",
    "    # Defense - generally positive when in your favor\n",
    "    'D_def_interceptions_int': 1,\n",
    "    'D_def_interceptions_td': 1,\n",
    "    'D_def_interceptions_yds': 1,\n",
    "    'D_fumbles_fr': 1,\n",
    "    'D_fumbles_td': 1,\n",
    "    'D_sk': 1,\n",
    "    # 'D_tackles_qbhits': 1,\n",
    "    # 'D_tackles_tfl': 1,\n",
    "    \n",
    "    # Special teams - positive indicators\n",
    "    'D_kick_returns_td': 1,\n",
    "    'D_kick_returns_yds': 1,\n",
    "    'D_punt_returns_td': 1,\n",
    "    'D_punt_returns_yds': 1,\n",
    "    \n",
    "    # Scoring - positive\n",
    "    'D_scoring_fgm': 1,\n",
    "    'D_scoring_xpm': 1\n",
    "}\n",
    "\n",
    "monotone_constraints_tuple = ()\n",
    "no_monotone_constraints_tuple = ()\n",
    "for col in cont_cols:\n",
    "    monotone_constraints_tuple = monotone_constraints_tuple + (monotone_constraints[col],) if col in monotone_constraints else monotone_constraints_tuple + (0,)\n",
    "    no_monotone_constraints_tuple = no_monotone_constraints_tuple + (0,)\n",
    "print(monotone_constraints_tuple)\n",
    "print(no_monotone_constraints_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05613417",
   "metadata": {},
   "source": [
    "#### 1a. Normalize cont_df\n",
    "StandardScaler is instead used by the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e76a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# cont_scaled = min_max_scaler.fit_transform(cont_df.values)\n",
    "# cont_df = pd.DataFrame(cont_scaled)\n",
    "# cont_df.head()\n",
    "\n",
    "# # test performance set\n",
    "# perf_conts_df_scaled = min_max_scaler.fit_transform(perf_conts_df.values)\n",
    "# perf_conts_df = pd.DataFrame(perf_conts_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1912ae",
   "metadata": {},
   "source": [
    "### 3. Create an array of continuous values\n",
    "Numpy array 'conts' containing stack of each continuous column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([cont_df[col].values for col in list(cont_df.columns)], 1)\n",
    "conts[:5]\n",
    "\n",
    "y_col = np.stack([y_df[col].values for col in y_col], 1)\n",
    "\n",
    "# test performance set\n",
    "perf_conts = np.stack([perf_conts_df[col].values for col in list(perf_conts_df.columns)], 1)\n",
    "perf_y_col = np.stack([perf_y_df[col].values for col in list(perf_y_df.columns)], 1)\n",
    "perf_date_col = np.stack([perf_date_df[col].values for col in list(perf_date_df.columns)], 1)\n",
    "\n",
    "\n",
    "conts_train = conts\n",
    "y_train = y_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2547a",
   "metadata": {},
   "source": [
    "### 4. Convert conts to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5333, 59)\n",
      "(5333, 1)\n"
     ]
    }
   ],
   "source": [
    "print(conts.shape)\n",
    "print(y_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handled by model.fit()\n",
    "# conts = torch.tensor(conts, dtype=torch.float32)\n",
    "# y_col = torch.tensor(y_col, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331d34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, criterion=nn.BCELoss(),\n",
    "                optimizer_class=torch.optim.Adam, lr=0.001, n_epochs=10, confidence_threshold=0.1):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Training params\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.n_epochs = n_epochs\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # BatchNorm layer for continuous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([\n",
    "            nn.Linear(self.layer_shape[-1], out_sz),\n",
    "            # nn.Sigmoid()  # Ensures output between 0 and 1\n",
    "        ])\n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Training loop\n",
    "        self.train()\n",
    "        for _ in range(self.n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        # return (probas > 0.5).astype(int)\n",
    "        return probas\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X, torch.Tensor):\n",
    "                X = torch.FloatTensor(X)\n",
    "            return self(X).numpy()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"        \n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        # First apply confidence thresholding\n",
    "        mask = (probas < 0.5 - self.confidence_threshold) | (probas > 0.5 + self.confidence_threshold)\n",
    "        predictions = np.where(mask, (probas > 0.5).astype(np.int32), np.nan)\n",
    "\n",
    "        # Use numpy mask for nan values\n",
    "        valid_mask = ~np.isnan(predictions)\n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = y[valid_mask]\n",
    "        \n",
    "        # Apply f1 score\n",
    "        score = f1_score(valid_predictions.flatten(), valid_targets)\n",
    "        return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9875b494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TabularModelUpdated(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, criterion=nn.MSELoss(),\n",
    "                optimizer_class=torch.optim.Adam, lr=0.001, confidence_threshold=0.1):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Training params\n",
    "        self.criterion = criterion\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # BatchNorm layer for continuous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([\n",
    "            nn.Linear(self.layer_shape[-1], out_sz),\n",
    "            # nn.Sigmoid()  # Ensures output between 0 and 1\n",
    "        ])\n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        # Initialize the optimizer\n",
    "        self.optimizer = optimizer_class(self.parameters(), lr=self.lr)\n",
    "\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        # optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        # Training loop\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred = self.forward(X)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas > 0.5).astype(int)\n",
    "        # return probas\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X, torch.Tensor):\n",
    "                X = torch.FloatTensor(X)\n",
    "            return self(X).numpy()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"        \n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        # First apply confidence thresholding\n",
    "        mask = (probas < 0.5 - self.confidence_threshold) | (probas > 0.5 + self.confidence_threshold)\n",
    "        predictions = np.where(mask, (probas > 0.5).astype(np.int32), np.nan)\n",
    "\n",
    "        # Use numpy mask for nan values\n",
    "        valid_mask = ~np.isnan(predictions)\n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = y[valid_mask]\n",
    "        \n",
    "        # Penalize if < 80% predicted\n",
    "        if (1.0* len(valid_predictions) / len(X)) < 0.85:\n",
    "            # print(f\"mask {len(valid_predictions)}  pred {len(X)}\")\n",
    "            return 0.0\n",
    "\n",
    "        # Apply f1 score\n",
    "        score = f1_score(valid_predictions.flatten(), valid_targets)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b31ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- Suggest hyperparameters ---\n",
    "\n",
    "    criterion = trial.suggest_categorical('criterion', nfl_utils.map_losses(None).keys())\n",
    "    first_layer_size = trial.suggest_categorical('first_layer_size', [64, 56, 48, 32, 16, 12])\n",
    "    min_layers = math.floor(math.sqrt(first_layer_size))\n",
    "    num_layers = trial.suggest_int('num_layers', 2, min_layers)\n",
    "    confidence_threshold = trial.suggest_float('confidence_threshold', 0, 0.05)\n",
    "    layer_shape = [first_layer_size]\n",
    "    for i in range(1, num_layers):\n",
    "        layer_shape.append(first_layer_size//(2*i))\n",
    "    \n",
    "    # Set random state to have consistent results (42 is arbitrary)\n",
    "    set_all_seeds()\n",
    "    \n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Split once\n",
    "    X_train_fold = []\n",
    "    X_val = []\n",
    "    y_train_fold = []\n",
    "    y_val = []\n",
    "    models = []\n",
    "    for train_index, val_index in kf.split(conts_train):\n",
    "        # print(f\"train {train_index.shape} val {val_index.shape}\")\n",
    "        X_train_fold.append(torch.FloatTensor(conts_train[train_index]).to(device))\n",
    "        X_val.append(torch.FloatTensor(conts_train[val_index]).to(device))\n",
    "\n",
    "        y_train_fold.append(torch.FloatTensor(y_train[train_index]).to(device))\n",
    "        y_val.append(torch.FloatTensor(y_train[val_index]).to(device))\n",
    "\n",
    "        model = TabularModelUpdated(\n",
    "            n_cont=conts.shape[1],\n",
    "            out_sz=1,\n",
    "            layer_shape=layer_shape,\n",
    "            p=trial.suggest_float('dropout', 0.28, 0.38),     # Dropout\n",
    "            criterion=nfl_utils.map_losses(criterion),\n",
    "            optimizer_class=torch.optim.Adam,\n",
    "            lr=trial.suggest_float('lr', 1e-3, 1e-2, log=True),   # Learning rate \n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "            # ('regressor', LinearRegression()), # Apply a regression model\n",
    "            ('model', model)\n",
    "        ])\n",
    "        models.append(pipeline)\n",
    "\n",
    "    # Run once on each split, track average loss, stop if > max patience\n",
    "    max_patience = 10\n",
    "    current_patience = max_patience\n",
    "    tracked_loss = 0.0\n",
    "    n_epochs = 0\n",
    "    while current_patience > 0 or n_epochs < 100:\n",
    "        n_epochs = n_epochs + 1\n",
    "        running_loss = []\n",
    "        for i in range(0,n_splits):\n",
    "            # ----- Train -----\n",
    "            models[i].fit(X_train_fold[i], y_train_fold[i])\n",
    "\n",
    "            # ----- Eval -----\n",
    "            running_loss.append(models[i].score(X_val[i], y_val[i]))\n",
    "            # y_pred = models[i].predict(X_val[i])\n",
    "            # running_loss.append(f1_score(y_val[i], y_pred))\n",
    "        running_loss = np.mean(running_loss)\n",
    "\n",
    "        # ----- Current epoch loss > previous -----\n",
    "        # print(f\"{tracked_loss} {running_loss} {tracked_loss < running_loss}\")\n",
    "        if tracked_loss < running_loss:\n",
    "            current_patience = max_patience\n",
    "            tracked_loss = running_loss\n",
    "        else:\n",
    "            current_patience = current_patience - 1\n",
    "    trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "    trial.report(tracked_loss, n_epochs)\n",
    "    return tracked_loss\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value}\")\n",
    "    print(f\"Best trial so far: {study.best_trial.number}, value: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd663af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 10:05:40,452] A new study created in memory with name: no-name-ed59f111-95cb-43fb-bf26-8896707b4ad2\n",
      "[I 2025-01-14 10:05:46,438] Trial 0 finished with value: 0.0 and parameters: {'criterion': 'L1Loss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.023774481008761353, 'dropout': 0.2815631616933799, 'lr': 0.0018227142905140393, 'n_epochs': 100}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.0\n",
      "Best trial so far: 0, value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-14 10:05:51,223] Trial 1 finished with value: 0.4559828058043684 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 32, 'num_layers': 2, 'confidence_threshold': 0.02240661266725044, 'dropout': 0.31419688289222003, 'lr': 0.009201099527876523, 'n_epochs': 100}. Best is trial 1 with value: 0.4559828058043684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.4559828058043684\n",
      "Best trial so far: 1, value: 0.4559828058043684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-14 10:05:53,646] Trial 2 failed with parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 64, 'num_layers': 4, 'confidence_threshold': 0.005973481239590695, 'dropout': 0.284747402551489, 'lr': 0.0027029354763241854} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_3860/1515200931.py\", line 60, in objective\n",
      "    models[i].fit(X_train_fold[i], y_train_fold[i])\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/joblib/memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\", line 980, in transform\n",
      "    force_all_finite=\"allow-nan\",\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    if is_float and (np.isfinite(_safe_accumulator_op(np.sum, X))):\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/extmath.py\", line 895, in _safe_accumulator_op\n",
      "    result = op(x, *args, **kwargs)\n",
      "  File \"<__array_function__ internals>\", line 6, in sum\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 2260, in sum\n",
      "    initial=initial, where=where)\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-14 10:05:53,659] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_3860/2076904166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Uncomment to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# study.optimize(objective, n_trials=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best trial:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_3860/1515200931.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# ----- Train -----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# ----- Eval -----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         )\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"fc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2260\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',   # max because using f1\n",
    "    pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1,\n",
    "        max_resource=1000\n",
    "    )\n",
    ")\n",
    "# Uncomment to run\n",
    "if True:\n",
    "    study.optimize(objective, n_trials=2000, callbacks=[print_callback])\n",
    "    # study.optimize(objective, n_trials=3)\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"Value: \", trial.value)\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = study.best_trial.params\n",
    "best_params = {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}\n",
    "layer_shape = [best_params['first_layer_size']]\n",
    "for i in range(1, best_params['num_layers']):\n",
    "    layer_shape.append(best_params['first_layer_size']//(2*i))\n",
    "\n",
    "# Set random state to have consistent results (42 is arbitrary)\n",
    "set_all_seeds()\n",
    "model = TabularModelUpdated(\n",
    "    n_cont=conts.shape[1],\n",
    "    out_sz=1,\n",
    "    layer_shape=layer_shape,\n",
    "    p=best_params['dropout'],     # Dropout\n",
    "    criterion=nfl_utils.map_losses(best_params['criterion']),\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    lr= best_params['lr'],   # Learning rate \n",
    "    confidence_threshold=best_params['confidence_threshold']\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "    # ('regressor', LinearRegression()), # Apply a regression model\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Run once on each split, track average loss, stop if > max patience\n",
    "for _ in range(0, (best_params['n_epochs'] - 10)):\n",
    "    running_loss = 0.0\n",
    "    # ----- Train -----\n",
    "    pipeline.fit(conts_train, y_train)\n",
    "\n",
    "    # ----- Eval -----\n",
    "    # loss = pipeline.score(perf_conts, perf_y_col)\n",
    "    #print(f\"loss: {loss}\")\n",
    "\n",
    "# pipeline.fit(conts_train, y_train)\n",
    "probas = pipeline.predict(perf_conts)\n",
    "confidence_threshold = best_params['confidence_threshold']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109e37c",
   "metadata": {},
   "source": [
    "Value:  0.37491718013436764\n",
    "\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 39\n",
    "    dropout: 0.47875406200808335\n",
    "    lr: 0.009997751942238913\n",
    "    \n",
    "\n",
    "\n",
    "Value:  0.3759073484440955\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 68\n",
    "    dropout: 0.4497689844977892\n",
    "    lr: 0.007977206154472633\n",
    "    \n",
    "    \n",
    "    \n",
    "12/6\n",
    "\n",
    "Trial 206 finished with value: 0.547218605316966 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.05966702820817666, 'n_epochs': 379, 'dropout': 0.36961850006275193, 'lr': 0.008649806179332952}. Best is trial 206 with value: 0.547218605316966.\n",
    "\n",
    "[I 2024-12-06 12:49:28,047] Trial 579 finished with value: 0.5335308702482566 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.059979796814548306, 'n_epochs': 481, 'dropout': 0.2511747953677191, 'lr': 0.007942836869449217}. Best is trial 579 with value: 0.5335308702482566.\n",
    "\n",
    "\n",
    "[I 2024-12-06 14:53:00,850] Trial 385 finished with value: 0.5547767877242975 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.003263372268063613, 'n_epochs': 300, 'dropout': 0.3153661030384182, 'lr': 0.00593138298730814}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:32:38,969] Trial 583 finished with value: 0.550872165273167 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.010458110701511005, 'n_epochs': 336, 'dropout': 0.3188974735143638, 'lr': 0.006976522077116529}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:55:26,133] Trial 669 finished with value: 0.5645423555160363 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.0243907527056759, 'n_epochs': 370, 'dropout': 0.32998724447261185, 'lr': 0.0075018456671685696}. Best is trial 669 with value: 0.5645423555160363.\n",
    "\n",
    "[I 2024-12-06 20:33:46,555] Trial 1737 finished with value: 0.5716002919237433 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.015368961704784596, 'n_epochs': 328, 'dropout': 0.348927921024466, 'lr': 0.009575624984802092}. Best is trial 1737 with value: 0.5716002919237433.\n",
    "\n",
    "\n",
    "[I 2024-12-06 21:17:06,545] Trial 1889 finished with value: 0.5739803740995499 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.014029751567812504, 'n_epochs': 357, 'dropout': 0.34275064196127053, 'lr': 0.008692336113071646}. Best is trial 1889 with value: 0.5739803740995499.\n",
    "\n",
    "[I 2024-12-10 09:39:54,796] Trial 1612 finished with value: 0.5748324966932515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.003855147984840053, 'dropout': 0.3182765851196762, 'lr': 0.008210651343970551, 'n_epochs': 219}. Best is trial 1612 with value: 0.5748324966932515.\n",
    "\n",
    "\n",
    "\n",
    "Trial 1749 finished with value: 0.5772962775717783 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328981",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nfl_utils.backtest_model(pipeline, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.05, confidence_threshold=best_params['confidence_threshold'], show_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outside of confidence threshold\n",
    "mask = (probas < 0.5 - confidence_threshold) | (probas > 0.5 + confidence_threshold)\n",
    "predictions = np.where(mask, probas, np.nan)\n",
    "\n",
    "# Use numpy mask for nan values\n",
    "valid_mask = ~np.isnan(predictions)\n",
    "valid_predictions = predictions[valid_mask]\n",
    "valid_mask = valid_mask.flatten()\n",
    "perf_y_col_mask = perf_y_col[valid_mask]\n",
    "\n",
    "\n",
    "true_values = perf_y_col_mask[:,0].astype(np.int32)\n",
    "pred_values = valid_predictions.flatten()\n",
    "pred_values_int = np.rint(valid_predictions).flatten().astype(np.int32)\n",
    "\n",
    "model_win_prob = (1.0*(true_values == pred_values_int).sum()) / (true_values.shape[0])\n",
    "print(model_win_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d6ca8",
   "metadata": {},
   "source": [
    "# Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8524f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.008, 0.01, 0.03],           # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3, 6, 9],                      # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [100, 200],                  # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.8, 1.0],                     # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.8, 1.0],              # Same as above\n",
    "    'min_child_weight': [1, 3],                  # Removed 5 as it might be too restrictive\n",
    "    # 'monotone_constraints': [monotone_constraints_tuple, no_monotone_constraints_tuple]\n",
    "    'monotone_constraints': [no_monotone_constraints_tuple]\n",
    "}\n",
    "param_grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],        # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3],                         # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [300, 350, 400],             # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.5, 0.6, 0.7],                # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],         # Same as above\n",
    "    'min_child_weight': [3, 4],                  # Removed 5 as it might be too restrictive\n",
    "    'monotone_constraints': [monotone_constraints_tuple, no_monotone_constraints_tuple]\n",
    "}\n",
    "\n",
    "# model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create a custom scorer using the F1 score\n",
    "# f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "# Tune hyperparameters using GridSearchCV with the custom F1 scorer\n",
    "# grid_search = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=5, verbose=1)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "grid_search.fit(conts_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "# No monotone constraints\n",
    "# 60.15%, {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "# 65% {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "\n",
    "# Monotone constraints\n",
    "# {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 200, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee2ec9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.49958\n",
      "[1]\tvalidation_0-rmse:0.49919\n",
      "[2]\tvalidation_0-rmse:0.49876\n",
      "[3]\tvalidation_0-rmse:0.49838\n",
      "[4]\tvalidation_0-rmse:0.49801\n",
      "[5]\tvalidation_0-rmse:0.49762\n",
      "[6]\tvalidation_0-rmse:0.49724\n",
      "[7]\tvalidation_0-rmse:0.49685\n",
      "[8]\tvalidation_0-rmse:0.49648\n",
      "[9]\tvalidation_0-rmse:0.49613\n",
      "[10]\tvalidation_0-rmse:0.49576\n",
      "[11]\tvalidation_0-rmse:0.49539\n",
      "[12]\tvalidation_0-rmse:0.49505\n",
      "[13]\tvalidation_0-rmse:0.49469\n",
      "[14]\tvalidation_0-rmse:0.49431\n",
      "[15]\tvalidation_0-rmse:0.49393\n",
      "[16]\tvalidation_0-rmse:0.49360\n",
      "[17]\tvalidation_0-rmse:0.49324\n",
      "[18]\tvalidation_0-rmse:0.49294\n",
      "[19]\tvalidation_0-rmse:0.49262\n",
      "[20]\tvalidation_0-rmse:0.49229\n",
      "[21]\tvalidation_0-rmse:0.49197\n",
      "[22]\tvalidation_0-rmse:0.49171\n",
      "[23]\tvalidation_0-rmse:0.49139\n",
      "[24]\tvalidation_0-rmse:0.49110\n",
      "[25]\tvalidation_0-rmse:0.49081\n",
      "[26]\tvalidation_0-rmse:0.49052\n",
      "[27]\tvalidation_0-rmse:0.49020\n",
      "[28]\tvalidation_0-rmse:0.48994\n",
      "[29]\tvalidation_0-rmse:0.48964\n",
      "[30]\tvalidation_0-rmse:0.48935\n",
      "[31]\tvalidation_0-rmse:0.48911\n",
      "[32]\tvalidation_0-rmse:0.48883\n",
      "[33]\tvalidation_0-rmse:0.48856\n",
      "[34]\tvalidation_0-rmse:0.48828\n",
      "[35]\tvalidation_0-rmse:0.48803\n",
      "[36]\tvalidation_0-rmse:0.48776\n",
      "[37]\tvalidation_0-rmse:0.48751\n",
      "[38]\tvalidation_0-rmse:0.48726\n",
      "[39]\tvalidation_0-rmse:0.48702\n",
      "[40]\tvalidation_0-rmse:0.48679\n",
      "[41]\tvalidation_0-rmse:0.48657\n",
      "[42]\tvalidation_0-rmse:0.48633\n",
      "[43]\tvalidation_0-rmse:0.48612\n",
      "[44]\tvalidation_0-rmse:0.48589\n",
      "[45]\tvalidation_0-rmse:0.48568\n",
      "[46]\tvalidation_0-rmse:0.48548\n",
      "[47]\tvalidation_0-rmse:0.48526\n",
      "[48]\tvalidation_0-rmse:0.48506\n",
      "[49]\tvalidation_0-rmse:0.48487\n",
      "[50]\tvalidation_0-rmse:0.48469\n",
      "[51]\tvalidation_0-rmse:0.48446\n",
      "[52]\tvalidation_0-rmse:0.48424\n",
      "[53]\tvalidation_0-rmse:0.48401\n",
      "[54]\tvalidation_0-rmse:0.48378\n",
      "[55]\tvalidation_0-rmse:0.48358\n",
      "[56]\tvalidation_0-rmse:0.48337\n",
      "[57]\tvalidation_0-rmse:0.48320\n",
      "[58]\tvalidation_0-rmse:0.48300\n",
      "[59]\tvalidation_0-rmse:0.48282\n",
      "[60]\tvalidation_0-rmse:0.48260\n",
      "[61]\tvalidation_0-rmse:0.48241\n",
      "[62]\tvalidation_0-rmse:0.48222\n",
      "[63]\tvalidation_0-rmse:0.48204\n",
      "[64]\tvalidation_0-rmse:0.48185\n",
      "[65]\tvalidation_0-rmse:0.48168\n",
      "[66]\tvalidation_0-rmse:0.48151\n",
      "[67]\tvalidation_0-rmse:0.48135\n",
      "[68]\tvalidation_0-rmse:0.48120\n",
      "[69]\tvalidation_0-rmse:0.48102\n",
      "[70]\tvalidation_0-rmse:0.48083\n",
      "[71]\tvalidation_0-rmse:0.48066\n",
      "[72]\tvalidation_0-rmse:0.48049\n",
      "[73]\tvalidation_0-rmse:0.48034\n",
      "[74]\tvalidation_0-rmse:0.48017\n",
      "[75]\tvalidation_0-rmse:0.48000\n",
      "[76]\tvalidation_0-rmse:0.47986\n",
      "[77]\tvalidation_0-rmse:0.47971\n",
      "[78]\tvalidation_0-rmse:0.47954\n",
      "[79]\tvalidation_0-rmse:0.47940\n",
      "[80]\tvalidation_0-rmse:0.47925\n",
      "[81]\tvalidation_0-rmse:0.47910\n",
      "[82]\tvalidation_0-rmse:0.47895\n",
      "[83]\tvalidation_0-rmse:0.47881\n",
      "[84]\tvalidation_0-rmse:0.47864\n",
      "[85]\tvalidation_0-rmse:0.47848\n",
      "[86]\tvalidation_0-rmse:0.47834\n",
      "[87]\tvalidation_0-rmse:0.47820\n",
      "[88]\tvalidation_0-rmse:0.47806\n",
      "[89]\tvalidation_0-rmse:0.47792\n",
      "[90]\tvalidation_0-rmse:0.47778\n",
      "[91]\tvalidation_0-rmse:0.47765\n",
      "[92]\tvalidation_0-rmse:0.47752\n",
      "[93]\tvalidation_0-rmse:0.47738\n",
      "[94]\tvalidation_0-rmse:0.47725\n",
      "[95]\tvalidation_0-rmse:0.47712\n",
      "[96]\tvalidation_0-rmse:0.47700\n",
      "[97]\tvalidation_0-rmse:0.47688\n",
      "[98]\tvalidation_0-rmse:0.47674\n",
      "[99]\tvalidation_0-rmse:0.47663\n",
      "[100]\tvalidation_0-rmse:0.47649\n",
      "[101]\tvalidation_0-rmse:0.47638\n",
      "[102]\tvalidation_0-rmse:0.47626\n",
      "[103]\tvalidation_0-rmse:0.47615\n",
      "[104]\tvalidation_0-rmse:0.47602\n",
      "[105]\tvalidation_0-rmse:0.47591\n",
      "[106]\tvalidation_0-rmse:0.47581\n",
      "[107]\tvalidation_0-rmse:0.47570\n",
      "[108]\tvalidation_0-rmse:0.47558\n",
      "[109]\tvalidation_0-rmse:0.47545\n",
      "[110]\tvalidation_0-rmse:0.47535\n",
      "[111]\tvalidation_0-rmse:0.47524\n",
      "[112]\tvalidation_0-rmse:0.47514\n",
      "[113]\tvalidation_0-rmse:0.47502\n",
      "[114]\tvalidation_0-rmse:0.47491\n",
      "[115]\tvalidation_0-rmse:0.47481\n",
      "[116]\tvalidation_0-rmse:0.47469\n",
      "[117]\tvalidation_0-rmse:0.47459\n",
      "[118]\tvalidation_0-rmse:0.47449\n",
      "[119]\tvalidation_0-rmse:0.47438\n",
      "[120]\tvalidation_0-rmse:0.47428\n",
      "[121]\tvalidation_0-rmse:0.47416\n",
      "[122]\tvalidation_0-rmse:0.47405\n",
      "[123]\tvalidation_0-rmse:0.47395\n",
      "[124]\tvalidation_0-rmse:0.47384\n",
      "[125]\tvalidation_0-rmse:0.47373\n",
      "[126]\tvalidation_0-rmse:0.47362\n",
      "[127]\tvalidation_0-rmse:0.47353\n",
      "[128]\tvalidation_0-rmse:0.47343\n",
      "[129]\tvalidation_0-rmse:0.47332\n",
      "[130]\tvalidation_0-rmse:0.47323\n",
      "[131]\tvalidation_0-rmse:0.47314\n",
      "[132]\tvalidation_0-rmse:0.47304\n",
      "[133]\tvalidation_0-rmse:0.47294\n",
      "[134]\tvalidation_0-rmse:0.47284\n",
      "[135]\tvalidation_0-rmse:0.47275\n",
      "[136]\tvalidation_0-rmse:0.47266\n",
      "[137]\tvalidation_0-rmse:0.47255\n",
      "[138]\tvalidation_0-rmse:0.47246\n",
      "[139]\tvalidation_0-rmse:0.47236\n",
      "[140]\tvalidation_0-rmse:0.47227\n",
      "[141]\tvalidation_0-rmse:0.47216\n",
      "[142]\tvalidation_0-rmse:0.47209\n",
      "[143]\tvalidation_0-rmse:0.47200\n",
      "[144]\tvalidation_0-rmse:0.47191\n",
      "[145]\tvalidation_0-rmse:0.47183\n",
      "[146]\tvalidation_0-rmse:0.47174\n",
      "[147]\tvalidation_0-rmse:0.47164\n",
      "[148]\tvalidation_0-rmse:0.47158\n",
      "[149]\tvalidation_0-rmse:0.47149\n",
      "[150]\tvalidation_0-rmse:0.47139\n",
      "[151]\tvalidation_0-rmse:0.47130\n",
      "[152]\tvalidation_0-rmse:0.47123\n",
      "[153]\tvalidation_0-rmse:0.47115\n",
      "[154]\tvalidation_0-rmse:0.47106\n",
      "[155]\tvalidation_0-rmse:0.47101\n",
      "[156]\tvalidation_0-rmse:0.47092\n",
      "[157]\tvalidation_0-rmse:0.47085\n",
      "[158]\tvalidation_0-rmse:0.47077\n",
      "[159]\tvalidation_0-rmse:0.47067\n",
      "[160]\tvalidation_0-rmse:0.47058\n",
      "[161]\tvalidation_0-rmse:0.47049\n",
      "[162]\tvalidation_0-rmse:0.47041\n",
      "[163]\tvalidation_0-rmse:0.47036\n",
      "[164]\tvalidation_0-rmse:0.47029\n",
      "[165]\tvalidation_0-rmse:0.47022\n",
      "[166]\tvalidation_0-rmse:0.47013\n",
      "[167]\tvalidation_0-rmse:0.47007\n",
      "[168]\tvalidation_0-rmse:0.47000\n",
      "[169]\tvalidation_0-rmse:0.46992\n",
      "[170]\tvalidation_0-rmse:0.46985\n",
      "[171]\tvalidation_0-rmse:0.46977\n",
      "[172]\tvalidation_0-rmse:0.46967\n",
      "[173]\tvalidation_0-rmse:0.46959\n",
      "[174]\tvalidation_0-rmse:0.46951\n",
      "[175]\tvalidation_0-rmse:0.46942\n",
      "[176]\tvalidation_0-rmse:0.46936\n",
      "[177]\tvalidation_0-rmse:0.46927\n",
      "[178]\tvalidation_0-rmse:0.46918\n",
      "[179]\tvalidation_0-rmse:0.46908\n",
      "[180]\tvalidation_0-rmse:0.46899\n",
      "[181]\tvalidation_0-rmse:0.46891\n",
      "[182]\tvalidation_0-rmse:0.46884\n",
      "[183]\tvalidation_0-rmse:0.46879\n",
      "[184]\tvalidation_0-rmse:0.46869\n",
      "[185]\tvalidation_0-rmse:0.46861\n",
      "[186]\tvalidation_0-rmse:0.46853\n",
      "[187]\tvalidation_0-rmse:0.46845\n",
      "[188]\tvalidation_0-rmse:0.46837\n",
      "[189]\tvalidation_0-rmse:0.46828\n",
      "[190]\tvalidation_0-rmse:0.46822\n",
      "[191]\tvalidation_0-rmse:0.46816\n",
      "[192]\tvalidation_0-rmse:0.46810\n",
      "[193]\tvalidation_0-rmse:0.46799\n",
      "[194]\tvalidation_0-rmse:0.46792\n",
      "[195]\tvalidation_0-rmse:0.46784\n",
      "[196]\tvalidation_0-rmse:0.46778\n",
      "[197]\tvalidation_0-rmse:0.46770\n",
      "[198]\tvalidation_0-rmse:0.46760\n",
      "[199]\tvalidation_0-rmse:0.46755\n",
      "[200]\tvalidation_0-rmse:0.46749\n",
      "[201]\tvalidation_0-rmse:0.46743\n",
      "[202]\tvalidation_0-rmse:0.46735\n",
      "[203]\tvalidation_0-rmse:0.46727\n",
      "[204]\tvalidation_0-rmse:0.46719\n",
      "[205]\tvalidation_0-rmse:0.46711\n",
      "[206]\tvalidation_0-rmse:0.46707\n",
      "[207]\tvalidation_0-rmse:0.46699\n",
      "[208]\tvalidation_0-rmse:0.46693\n",
      "[209]\tvalidation_0-rmse:0.46687\n",
      "[210]\tvalidation_0-rmse:0.46683\n",
      "[211]\tvalidation_0-rmse:0.46677\n",
      "[212]\tvalidation_0-rmse:0.46672\n",
      "[213]\tvalidation_0-rmse:0.46667\n",
      "[214]\tvalidation_0-rmse:0.46660\n",
      "[215]\tvalidation_0-rmse:0.46653\n",
      "[216]\tvalidation_0-rmse:0.46647\n",
      "[217]\tvalidation_0-rmse:0.46640\n",
      "[218]\tvalidation_0-rmse:0.46634\n",
      "[219]\tvalidation_0-rmse:0.46628\n",
      "[220]\tvalidation_0-rmse:0.46621\n",
      "[221]\tvalidation_0-rmse:0.46613\n",
      "[222]\tvalidation_0-rmse:0.46607\n",
      "[223]\tvalidation_0-rmse:0.46601\n",
      "[224]\tvalidation_0-rmse:0.46593\n",
      "[225]\tvalidation_0-rmse:0.46587\n",
      "[226]\tvalidation_0-rmse:0.46580\n",
      "[227]\tvalidation_0-rmse:0.46575\n",
      "[228]\tvalidation_0-rmse:0.46568\n",
      "[229]\tvalidation_0-rmse:0.46561\n",
      "[230]\tvalidation_0-rmse:0.46554\n",
      "[231]\tvalidation_0-rmse:0.46546\n",
      "[232]\tvalidation_0-rmse:0.46540\n",
      "[233]\tvalidation_0-rmse:0.46531\n",
      "[234]\tvalidation_0-rmse:0.46525\n",
      "[235]\tvalidation_0-rmse:0.46517\n",
      "[236]\tvalidation_0-rmse:0.46510\n",
      "[237]\tvalidation_0-rmse:0.46506\n",
      "[238]\tvalidation_0-rmse:0.46499\n",
      "[239]\tvalidation_0-rmse:0.46494\n",
      "[240]\tvalidation_0-rmse:0.46487\n",
      "[241]\tvalidation_0-rmse:0.46481\n",
      "[242]\tvalidation_0-rmse:0.46475\n",
      "[243]\tvalidation_0-rmse:0.46469\n",
      "[244]\tvalidation_0-rmse:0.46462\n",
      "[245]\tvalidation_0-rmse:0.46456\n",
      "[246]\tvalidation_0-rmse:0.46449\n",
      "[247]\tvalidation_0-rmse:0.46443\n",
      "[248]\tvalidation_0-rmse:0.46436\n",
      "[249]\tvalidation_0-rmse:0.46429\n",
      "[250]\tvalidation_0-rmse:0.46421\n",
      "[251]\tvalidation_0-rmse:0.46415\n",
      "[252]\tvalidation_0-rmse:0.46410\n",
      "[253]\tvalidation_0-rmse:0.46405\n",
      "[254]\tvalidation_0-rmse:0.46398\n",
      "[255]\tvalidation_0-rmse:0.46394\n",
      "[256]\tvalidation_0-rmse:0.46388\n",
      "[257]\tvalidation_0-rmse:0.46381\n",
      "[258]\tvalidation_0-rmse:0.46374\n",
      "[259]\tvalidation_0-rmse:0.46368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\tvalidation_0-rmse:0.46363\n",
      "[261]\tvalidation_0-rmse:0.46358\n",
      "[262]\tvalidation_0-rmse:0.46351\n",
      "[263]\tvalidation_0-rmse:0.46346\n",
      "[264]\tvalidation_0-rmse:0.46339\n",
      "[265]\tvalidation_0-rmse:0.46331\n",
      "[266]\tvalidation_0-rmse:0.46327\n",
      "[267]\tvalidation_0-rmse:0.46322\n",
      "[268]\tvalidation_0-rmse:0.46315\n",
      "[269]\tvalidation_0-rmse:0.46311\n",
      "[270]\tvalidation_0-rmse:0.46308\n",
      "[271]\tvalidation_0-rmse:0.46301\n",
      "[272]\tvalidation_0-rmse:0.46295\n",
      "[273]\tvalidation_0-rmse:0.46289\n",
      "[274]\tvalidation_0-rmse:0.46283\n",
      "[275]\tvalidation_0-rmse:0.46276\n",
      "[276]\tvalidation_0-rmse:0.46271\n",
      "[277]\tvalidation_0-rmse:0.46268\n",
      "[278]\tvalidation_0-rmse:0.46265\n",
      "[279]\tvalidation_0-rmse:0.46259\n",
      "[280]\tvalidation_0-rmse:0.46253\n",
      "[281]\tvalidation_0-rmse:0.46248\n",
      "[282]\tvalidation_0-rmse:0.46242\n",
      "[283]\tvalidation_0-rmse:0.46236\n",
      "[284]\tvalidation_0-rmse:0.46232\n",
      "[285]\tvalidation_0-rmse:0.46226\n",
      "[286]\tvalidation_0-rmse:0.46219\n",
      "[287]\tvalidation_0-rmse:0.46214\n",
      "[288]\tvalidation_0-rmse:0.46211\n",
      "[289]\tvalidation_0-rmse:0.46207\n",
      "[290]\tvalidation_0-rmse:0.46202\n",
      "[291]\tvalidation_0-rmse:0.46197\n",
      "[292]\tvalidation_0-rmse:0.46193\n",
      "[293]\tvalidation_0-rmse:0.46187\n",
      "[294]\tvalidation_0-rmse:0.46181\n",
      "[295]\tvalidation_0-rmse:0.46176\n",
      "[296]\tvalidation_0-rmse:0.46171\n",
      "[297]\tvalidation_0-rmse:0.46166\n",
      "[298]\tvalidation_0-rmse:0.46161\n",
      "[299]\tvalidation_0-rmse:0.46155\n",
      "[300]\tvalidation_0-rmse:0.46152\n",
      "[301]\tvalidation_0-rmse:0.46145\n",
      "[302]\tvalidation_0-rmse:0.46140\n",
      "[303]\tvalidation_0-rmse:0.46134\n",
      "[304]\tvalidation_0-rmse:0.46130\n",
      "[305]\tvalidation_0-rmse:0.46124\n",
      "[306]\tvalidation_0-rmse:0.46119\n",
      "[307]\tvalidation_0-rmse:0.46115\n",
      "[308]\tvalidation_0-rmse:0.46109\n",
      "[309]\tvalidation_0-rmse:0.46103\n",
      "[310]\tvalidation_0-rmse:0.46099\n",
      "[311]\tvalidation_0-rmse:0.46091\n",
      "[312]\tvalidation_0-rmse:0.46087\n",
      "[313]\tvalidation_0-rmse:0.46079\n",
      "[314]\tvalidation_0-rmse:0.46073\n",
      "[315]\tvalidation_0-rmse:0.46068\n",
      "[316]\tvalidation_0-rmse:0.46064\n",
      "[317]\tvalidation_0-rmse:0.46058\n",
      "[318]\tvalidation_0-rmse:0.46052\n",
      "[319]\tvalidation_0-rmse:0.46045\n",
      "[320]\tvalidation_0-rmse:0.46039\n",
      "[321]\tvalidation_0-rmse:0.46036\n",
      "[322]\tvalidation_0-rmse:0.46029\n",
      "[323]\tvalidation_0-rmse:0.46025\n",
      "[324]\tvalidation_0-rmse:0.46020\n",
      "[325]\tvalidation_0-rmse:0.46015\n",
      "[326]\tvalidation_0-rmse:0.46010\n",
      "[327]\tvalidation_0-rmse:0.46006\n",
      "[328]\tvalidation_0-rmse:0.46000\n",
      "[329]\tvalidation_0-rmse:0.45995\n",
      "[330]\tvalidation_0-rmse:0.45989\n",
      "[331]\tvalidation_0-rmse:0.45982\n",
      "[332]\tvalidation_0-rmse:0.45978\n",
      "[333]\tvalidation_0-rmse:0.45973\n",
      "[334]\tvalidation_0-rmse:0.45968\n",
      "[335]\tvalidation_0-rmse:0.45965\n",
      "[336]\tvalidation_0-rmse:0.45962\n",
      "[337]\tvalidation_0-rmse:0.45956\n",
      "[338]\tvalidation_0-rmse:0.45953\n",
      "[339]\tvalidation_0-rmse:0.45948\n",
      "[340]\tvalidation_0-rmse:0.45942\n",
      "[341]\tvalidation_0-rmse:0.45936\n",
      "[342]\tvalidation_0-rmse:0.45933\n",
      "[343]\tvalidation_0-rmse:0.45928\n",
      "[344]\tvalidation_0-rmse:0.45923\n",
      "[345]\tvalidation_0-rmse:0.45917\n",
      "[346]\tvalidation_0-rmse:0.45911\n",
      "[347]\tvalidation_0-rmse:0.45906\n",
      "[348]\tvalidation_0-rmse:0.45902\n",
      "[349]\tvalidation_0-rmse:0.45896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=3,\n",
       "             missing=nan,\n",
       "             monotone_constraints=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...),\n",
       "             n_estimators=350, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train final model w/ early stopping\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10,\n",
    "    # **grid_search.best_params_\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # **{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 90, 'subsample': 1.0},\n",
    "    \n",
    "    # **{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 200, 'subsample': 1.0}\n",
    "\n",
    "    # **grid_search.best_params_,\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 31.4%\n",
    "    # {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 30.9%\n",
    "    # {'colsample_bytree': 1.0, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 300, 'subsample': 0.6}\n",
    ")\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    # **grid_search.best_params_,\n",
    "    # 67.3 w/ kelly adjustments 0.2, 0.01\n",
    "    # {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 4, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 350, 'subsample': 0.6}\n",
    "    # 67.2, dd 28.68 kelly 0.25, 0.014\n",
    "    **{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 350, 'subsample': 0.5}\n",
    ")\n",
    "model.fit(\n",
    "    conts_train,\n",
    "    y_train,\n",
    "    eval_set=[(conts_train, y_train)], # , (holdout_conts, holdout_y)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef6e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 3.35714286, 1.34642857, 2.355     , 1.5675    ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perf_conts.shape\n",
    "perf_y_col.shape\n",
    "perf_y_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177675db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-10-14' 'BUF' 'NYJ']\n",
      "2024-10-14: w_odds:1.33 acct_val: 1000.00 usable cash: 900.00 won: True\n",
      "2024-10-14: w_odds:1.46 acct_val: 1033.30 usable cash: 796.67 won: True\n",
      "2024-10-14: w_odds:2.04 acct_val: 1080.42 usable cash: 688.63 won: True\n",
      "2024-10-14: w_odds:1.54 acct_val: 1192.57 usable cash: 569.37 won: True\n",
      "2024-10-14: w_odds:1.37 acct_val: 1257.32 usable cash: 443.64 won: False\n",
      "2024-10-14: w_odds:1.40 acct_val: 1131.59 usable cash: 330.48 won: True\n",
      "2024-10-14: w_odds:1.31 acct_val: 1176.40 usable cash: 212.84 won: True\n",
      "['2024-10-17' 'DEN' 'NOR']\n",
      "2024-10-17: w_odds:1.85 acct_val: 1212.52 usable cash: 1091.26 won: True\n",
      "['2024-10-20' 'TEN' 'BUF']\n",
      "2024-10-20: w_odds:1.68 acct_val: 1315.34 usable cash: 1183.80 won: False\n",
      "['2024-10-21' 'LAC' 'ARI']\n",
      "2024-10-21: w_odds:1.20 acct_val: 1183.80 usable cash: 1065.42 won: True\n",
      "2024-10-21: w_odds:1.30 acct_val: 1207.13 usable cash: 944.71 won: True\n",
      "2024-10-21: w_odds:1.42 acct_val: 1243.47 usable cash: 820.36 won: True\n",
      "2024-10-21: w_odds:1.28 acct_val: 1295.08 usable cash: 690.86 won: True\n",
      "2024-10-21: w_odds:1.67 acct_val: 1331.99 usable cash: 557.66 won: True\n",
      "2024-10-21: w_odds:1.57 acct_val: 1420.96 usable cash: 415.56 won: True\n",
      "2024-10-21: w_odds:1.19 acct_val: 1502.24 usable cash: 265.34 won: True\n",
      "2024-10-21: w_odds:2.05 acct_val: 1530.48 usable cash: 112.29 won: False\n",
      "2024-10-21: w_odds:1.60 acct_val: 1377.44 usable cash: 0.00 won: False\n",
      "['2024-10-27' 'CHI' 'WAS']\n",
      "2024-10-27: w_odds:2.00 acct_val: 1265.15 usable cash: 1138.63 won: True\n",
      "2024-10-27: w_odds:1.45 acct_val: 1392.30 usable cash: 999.40 won: True\n",
      "['2024-10-28' 'NYG' 'PIT']\n",
      "2024-10-28: w_odds:1.80 acct_val: 1454.95 usable cash: 1309.45 won: True\n",
      "2024-10-28: w_odds:1.13 acct_val: 1572.07 usable cash: 1152.25 won: True\n",
      "2024-10-28: w_odds:1.41 acct_val: 1592.35 usable cash: 993.01 won: True\n",
      "2024-10-28: w_odds:1.12 acct_val: 1657.96 usable cash: 827.22 won: True\n",
      "2024-10-28: w_odds:1.79 acct_val: 1678.35 usable cash: 659.38 won: False\n",
      "2024-10-28: w_odds:1.54 acct_val: 1510.51 usable cash: 508.33 won: True\n",
      "2024-10-28: w_odds:1.22 acct_val: 1592.38 usable cash: 349.09 won: True\n",
      "2024-10-28: w_odds:1.42 acct_val: 1627.89 usable cash: 186.30 won: True\n",
      "2024-10-28: w_odds:1.28 acct_val: 1696.59 usable cash: 16.64 won: True\n",
      "2024-10-28: w_odds:1.61 acct_val: 1744.27 usable cash: 0.00 won: True\n",
      "['2024-10-31' 'HOU' 'NYJ']\n",
      "2024-10-31: w_odds:1.38 acct_val: 1754.43 usable cash: 1578.99 won: True\n",
      "['2024-11-03' 'NWE' 'TEN']\n",
      "2024-11-03: w_odds:1.67 acct_val: 1820.58 usable cash: 1638.52 won: False\n",
      "['2024-11-04' 'TAM' 'KAN']\n",
      "2024-11-04: w_odds:1.57 acct_val: 1638.52 usable cash: 1501.98 won: True\n",
      "2024-11-04: w_odds:1.28 acct_val: 1716.76 usable cash: 1358.91 won: True\n",
      "2024-11-04: w_odds:1.77 acct_val: 1757.39 usable cash: 1212.46 won: False\n",
      "2024-11-04: w_odds:1.26 acct_val: 1610.94 usable cash: 1078.22 won: True\n",
      "2024-11-04: w_odds:1.79 acct_val: 1645.31 usable cash: 941.11 won: False\n",
      "2024-11-04: w_odds:1.37 acct_val: 1508.20 usable cash: 815.43 won: True\n",
      "2024-11-04: w_odds:1.77 acct_val: 1554.20 usable cash: 685.91 won: True\n",
      "2024-11-04: w_odds:1.47 acct_val: 1654.05 usable cash: 548.07 won: True\n",
      "2024-11-04: w_odds:1.58 acct_val: 1719.39 usable cash: 404.79 won: True\n",
      "2024-11-04: w_odds:1.70 acct_val: 1803.07 usable cash: 254.53 won: True\n",
      "2024-11-04: w_odds:1.23 acct_val: 1908.09 usable cash: 95.53 won: True\n",
      "2024-11-04: w_odds:1.40 acct_val: 1944.51 usable cash: 0.00 won: True\n",
      "['2024-11-07' 'CIN' 'BAL']\n",
      "2024-11-07: w_odds:1.24 acct_val: 1982.91 usable cash: 1784.62 won: True\n",
      "['2024-11-10' 'PHI' 'DAL']\n",
      "2024-11-10: w_odds:1.36 acct_val: 2029.51 usable cash: 1826.56 won: True\n",
      "['2024-11-14' 'WAS' 'PHI']\n",
      "2024-11-14: w_odds:1.29 acct_val: 2103.25 usable cash: 1892.92 won: True\n",
      "2024-11-14: w_odds:2.03 acct_val: 2163.61 usable cash: 1676.56 won: False\n",
      "2024-11-14: w_odds:1.28 acct_val: 1947.25 usable cash: 1481.84 won: True\n",
      "2024-11-14: w_odds:1.44 acct_val: 2001.58 usable cash: 1281.68 won: True\n",
      "2024-11-14: w_odds:1.24 acct_val: 2089.85 usable cash: 1072.69 won: True\n",
      "2024-11-14: w_odds:1.34 acct_val: 2139.79 usable cash: 858.71 won: False\n",
      "2024-11-14: w_odds:1.45 acct_val: 1925.81 usable cash: 666.13 won: True\n",
      "2024-11-14: w_odds:1.30 acct_val: 2011.71 usable cash: 464.96 won: False\n",
      "['2024-11-17' 'GNB' 'CHI']\n",
      "2024-11-17: w_odds:1.44 acct_val: 1810.53 usable cash: 1629.48 won: True\n",
      "['2024-11-18' 'HOU' 'DAL']\n",
      "2024-11-18: w_odds:1.37 acct_val: 1890.56 usable cash: 1701.50 won: True\n",
      "2024-11-18: w_odds:1.99 acct_val: 1960.70 usable cash: 1505.43 won: True\n",
      "2024-11-18: w_odds:1.36 acct_val: 2155.40 usable cash: 1289.89 won: True\n",
      "2024-11-18: w_odds:1.76 acct_val: 2234.07 usable cash: 1066.49 won: True\n",
      "2024-11-18: w_odds:1.85 acct_val: 2402.97 usable cash: 826.19 won: True\n",
      "2024-11-18: w_odds:1.10 acct_val: 2607.94 usable cash: 565.40 won: True\n",
      "2024-11-18: w_odds:1.48 acct_val: 2633.76 usable cash: 302.02 won: True\n",
      "2024-11-18: w_odds:1.24 acct_val: 2761.23 usable cash: 25.90 won: True\n",
      "2024-11-18: w_odds:1.65 acct_val: 2828.05 usable cash: 0.00 won: True\n",
      "['2024-11-24' 'TAM' 'NYG']\n",
      "2024-11-24: w_odds:1.28 acct_val: 2844.99 usable cash: 2560.49 won: False\n",
      "['2024-11-25' 'BAL' 'LAC']\n",
      "2024-11-25: w_odds:1.36 acct_val: 2560.49 usable cash: 2304.44 won: True\n",
      "2024-11-25: w_odds:2.02 acct_val: 2653.69 usable cash: 2039.07 won: True\n",
      "2024-11-25: w_odds:1.40 acct_val: 2923.04 usable cash: 1746.77 won: False\n",
      "2024-11-25: w_odds:1.27 acct_val: 2630.74 usable cash: 1483.69 won: True\n",
      "2024-11-25: w_odds:1.15 acct_val: 2703.08 usable cash: 1213.39 won: True\n",
      "2024-11-25: w_odds:1.62 acct_val: 2743.63 usable cash: 939.02 won: True\n",
      "2024-11-25: w_odds:1.61 acct_val: 2912.64 usable cash: 647.76 won: True\n",
      "2024-11-25: w_odds:1.35 acct_val: 3090.31 usable cash: 338.73 won: False\n",
      "2024-11-25: w_odds:1.26 acct_val: 2781.28 usable cash: 60.60 won: True\n",
      "['2024-11-28' 'CHI' 'DET']\n",
      "2024-11-28: w_odds:1.62 acct_val: 2854.43 usable cash: 2568.98 won: False\n",
      "['2024-11-29' 'LVR' 'KAN']\n",
      "2024-11-29: w_odds:1.20 acct_val: 2568.98 usable cash: 2312.08 won: True\n",
      "2024-11-29: w_odds:1.45 acct_val: 2619.59 usable cash: 2050.13 won: True\n",
      "2024-11-29: w_odds:1.54 acct_val: 2737.74 usable cash: 1776.35 won: True\n",
      "['2024-12-01' 'SEA' 'NYJ']\n",
      "2024-12-01: w_odds:1.12 acct_val: 2886.12 usable cash: 2597.51 won: True\n",
      "['2024-12-02' 'CLE' 'DEN']\n",
      "2024-12-02: w_odds:2.02 acct_val: 2921.04 usable cash: 2628.94 won: False\n",
      "2024-12-02: w_odds:1.65 acct_val: 2628.94 usable cash: 2366.04 won: True\n",
      "2024-12-02: w_odds:1.73 acct_val: 2799.29 usable cash: 2086.12 won: False\n",
      "2024-12-02: w_odds:1.31 acct_val: 2519.36 usable cash: 1834.18 won: True\n",
      "2024-12-02: w_odds:1.55 acct_val: 2597.21 usable cash: 1574.46 won: True\n",
      "2024-12-02: w_odds:1.33 acct_val: 2739.02 usable cash: 1300.56 won: True\n",
      "2024-12-02: w_odds:1.39 acct_val: 2829.13 usable cash: 1017.64 won: True\n",
      "2024-12-02: w_odds:1.57 acct_val: 2938.34 usable cash: 723.81 won: True\n",
      "2024-12-02: w_odds:1.90 acct_val: 3105.24 usable cash: 413.28 won: True\n",
      "['2024-12-05' 'GNB' 'DET']\n",
      "2024-12-05: w_odds:1.34 acct_val: 3386.09 usable cash: 3047.48 won: True\n",
      "['2024-12-08' 'ATL' 'MIN']\n",
      "2024-12-08: w_odds:1.59 acct_val: 3501.89 usable cash: 3151.70 won: True\n",
      "['2024-12-09' 'CIN' 'DAL']\n",
      "2024-12-09: w_odds:1.37 acct_val: 3708.50 usable cash: 3337.65 won: True\n",
      "2024-12-09: w_odds:1.42 acct_val: 3846.09 usable cash: 2953.04 won: True\n",
      "2024-12-09: w_odds:1.60 acct_val: 4008.78 usable cash: 2552.17 won: True\n",
      "2024-12-09: w_odds:1.40 acct_val: 4249.71 usable cash: 2127.20 won: True\n",
      "2024-12-09: w_odds:1.33 acct_val: 4419.70 usable cash: 1685.23 won: True\n",
      "2024-12-09: w_odds:1.36 acct_val: 4565.10 usable cash: 1228.72 won: True\n",
      "2024-12-09: w_odds:1.10 acct_val: 4728.99 usable cash: 755.82 won: True\n",
      "2024-12-09: w_odds:1.31 acct_val: 4775.33 usable cash: 278.28 won: True\n",
      "['2024-12-15' 'NYJ' 'JAX']\n",
      "2024-12-15: w_odds:1.42 acct_val: 4924.32 usable cash: 4431.89 won: True\n",
      "['2024-12-16' 'CHI' 'MIN']\n",
      "2024-12-16: w_odds:1.56 acct_val: 5132.62 usable cash: 4619.36 won: False\n",
      "2024-12-16: w_odds:1.65 acct_val: 4619.36 usable cash: 4157.43 won: True\n",
      "2024-12-16: w_odds:1.38 acct_val: 4919.62 usable cash: 3665.46 won: True\n",
      "2024-12-16: w_odds:1.45 acct_val: 5107.55 usable cash: 3154.71 won: True\n",
      "2024-12-16: w_odds:1.64 acct_val: 5338.92 usable cash: 2620.82 won: True\n",
      "2024-12-16: w_odds:1.43 acct_val: 5681.15 usable cash: 2052.70 won: False\n",
      "2024-12-16: w_odds:1.06 acct_val: 5113.03 usable cash: 1541.40 won: True\n",
      "2024-12-16: w_odds:1.40 acct_val: 5142.69 usable cash: 1027.13 won: True\n",
      "2024-12-16: w_odds:1.36 acct_val: 5348.39 usable cash: 492.29 won: True\n",
      "2024-12-16: w_odds:1.26 acct_val: 5540.40 usable cash: 0.00 won: False\n",
      "['2024-12-19' 'DEN' 'LAC']\n",
      "2024-12-19: w_odds:1.30 acct_val: 5048.11 usable cash: 4543.30 won: True\n",
      "2024-12-19: w_odds:1.33 acct_val: 5198.55 usable cash: 4023.45 won: False\n",
      "['2024-12-21' 'PIT' 'BAL']\n",
      "2024-12-21: w_odds:1.65 acct_val: 4678.69 usable cash: 4210.82 won: False\n",
      "['2024-12-22' 'DET' 'CHI']\n",
      "2024-12-22: w_odds:1.28 acct_val: 4210.82 usable cash: 3789.74 won: True\n",
      "2024-12-22: w_odds:1.54 acct_val: 4329.57 usable cash: 3356.78 won: True\n",
      "['2024-12-23' 'NOR' 'GNB']\n",
      "2024-12-23: w_odds:1.29 acct_val: 4561.63 usable cash: 4105.47 won: True\n",
      "2024-12-23: w_odds:2.06 acct_val: 4695.74 usable cash: 3635.89 won: True\n",
      "2024-12-23: w_odds:1.18 acct_val: 5194.90 usable cash: 3116.40 won: True\n",
      "2024-12-23: w_odds:1.63 acct_val: 5289.45 usable cash: 2587.46 won: False\n",
      "2024-12-23: w_odds:1.08 acct_val: 4760.50 usable cash: 2111.41 won: True\n",
      "2024-12-23: w_odds:1.49 acct_val: 4798.59 usable cash: 1631.55 won: True\n",
      "2024-12-23: w_odds:1.72 acct_val: 5031.80 usable cash: 1128.37 won: True\n",
      "2024-12-23: w_odds:1.73 acct_val: 5393.59 usable cash: 589.01 won: True\n",
      "2024-12-23: w_odds:1.20 acct_val: 5787.86 usable cash: 10.23 won: True\n",
      "['2024-12-25' 'KAN' 'PIT']\n",
      "2024-12-25: w_odds:1.08 acct_val: 5904.77 usable cash: 5314.29 won: True\n",
      "['2024-12-26' 'SEA' 'CHI']\n",
      "2024-12-26: w_odds:1.76 acct_val: 5953.19 usable cash: 5357.87 won: False\n",
      "2024-12-26: w_odds:1.30 acct_val: 5357.87 usable cash: 4822.08 won: False\n",
      "['2024-12-28' 'LAC' 'NWE']\n",
      "2024-12-28: w_odds:1.44 acct_val: 4822.08 usable cash: 4339.88 won: False\n",
      "['2024-12-29' 'ATL' 'WAS']\n",
      "2024-12-29: w_odds:1.34 acct_val: 4339.88 usable cash: 3905.89 won: False\n",
      "2024-12-29: w_odds:1.57 acct_val: 3905.89 usable cash: 3515.30 won: True\n",
      "2024-12-29: w_odds:1.31 acct_val: 4128.13 usable cash: 3102.49 won: True\n",
      "['2024-12-30' 'DET' 'SFO']\n",
      "2024-12-30: w_odds:1.51 acct_val: 4256.52 usable cash: 3830.87 won: True\n",
      "2024-12-30: w_odds:1.57 acct_val: 4474.03 usable cash: 3383.46 won: False\n",
      "2024-12-30: w_odds:1.18 acct_val: 4026.62 usable cash: 2980.80 won: True\n",
      "2024-12-30: w_odds:1.93 acct_val: 4098.30 usable cash: 2570.97 won: True\n",
      "2024-12-30: w_odds:1.79 acct_val: 4477.68 usable cash: 2123.20 won: False\n",
      "2024-12-30: w_odds:1.18 acct_val: 4029.91 usable cash: 1720.21 won: True\n",
      "2024-12-30: w_odds:0.00 acct_val: 4102.45 usable cash: 1309.97 won: True\n",
      "2024-12-30: w_odds:1.88 acct_val: 3692.21 usable cash: 940.75 won: True\n",
      "['2025-01-04' 'CIN' 'PIT']\n",
      "2025-01-04: w_odds:1.44 acct_val: 4017.12 usable cash: 3615.41 won: True\n",
      "['2025-01-05' 'MIN' 'DET']\n",
      "2025-01-05: w_odds:1.72 acct_val: 4194.68 usable cash: 3775.21 won: True\n",
      "2025-01-05: w_odds:1.03 acct_val: 4495.02 usable cash: 3325.71 won: True\n",
      "['2025-01-11' 'PIT' 'BAL']\n",
      "2025-01-11: w_odds:1.62 acct_val: 4508.50 usable cash: 4057.65 won: True\n",
      "2025-01-11: w_odds:1.08 acct_val: 4789.38 usable cash: 3578.71 won: True\n",
      "2025-01-11: w_odds:1.61 acct_val: 4825.78 usable cash: 3096.14 won: True\n",
      "2025-01-11: w_odds:1.44 acct_val: 5122.08 usable cash: 2583.93 won: True\n",
      "2025-01-11: w_odds:1.74 acct_val: 5350.02 usable cash: 2048.93 won: True\n",
      "2025-01-11: w_odds:1.29 acct_val: 5746.45 usable cash: 1474.28 won: False\n",
      "2025-01-11: w_odds:1.53 acct_val: 5171.81 usable cash: 957.10 won: True\n",
      "2025-01-11: w_odds:1.17 acct_val: 5446.95 usable cash: 412.40 won: True\n",
      "2025-01-11: w_odds:1.30 acct_val: 5541.18 usable cash: 0.00 won: False\n",
      "2025-01-11: w_odds:1.31 acct_val: 5128.78 usable cash: 0.00 won: False\n",
      "['2025-01-12' 'GNB' 'PHI']\n",
      "2025-01-12: w_odds:1.18 acct_val: 5128.78 usable cash: 4615.90 won: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'final_value': 5223.6585768418445,\n",
       " 'roi': 4.223658576841845,\n",
       " 'win_rate': 0.7894736842105263,\n",
       " 'max_drawdown': 0.37979344685290845,\n",
       " 'total_bets': 152}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for test data\n",
    "# model = grid_search.best_estimator_\n",
    "y_pred = model.predict(perf_conts)\n",
    "\n",
    "nfl_utils.backtest_model(model, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.1, \n",
    "                   confidence_threshold=0.0, show_plot=True, max_won_odds=2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make confusion matrix\n",
    "cm = confusion_matrix(perf_y_col[:,0], y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7025ece",
   "metadata": {},
   "source": [
    "## Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94a74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6577d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a1a349",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
