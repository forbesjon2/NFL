{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70409bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from NFLUtils import NFLUtils\n",
    "nfl_utils = NFLUtils()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# ANN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Set pandas display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# XGBoost \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn as sns # confusion matrix\n",
    "\n",
    "# Set device to GPU if available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556dd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff2364",
   "metadata": {},
   "source": [
    "### Load CSV & UMAP model\n",
    "cp Combined.csv ~/drive/Notes/ML/Pytorch/footballData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfebbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5464 entries, 0 to 5463\n",
      "Data columns (total 70 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Unnamed: 0               5464 non-null   int64  \n",
      " 1   Season                   5464 non-null   int64  \n",
      " 2   Date                     5464 non-null   object \n",
      " 3   Home_Team                5464 non-null   object \n",
      " 4   Visitor_Team             5464 non-null   object \n",
      " 5   H_halftime_odds          5464 non-null   float64\n",
      " 6   V_halftime_odds          5464 non-null   float64\n",
      " 7   H_start_odds             5464 non-null   float64\n",
      " 8   V_start_odds             5464 non-null   float64\n",
      " 9   H_Won                    5464 non-null   float64\n",
      " 10  D_First_Downs            5464 non-null   float64\n",
      " 11  D_Rush                   5464 non-null   float64\n",
      " 12  D_Yds                    5464 non-null   float64\n",
      " 13  D_TDs                    5464 non-null   float64\n",
      " 14  D_Cmp                    5464 non-null   float64\n",
      " 15  D_Att                    5464 non-null   float64\n",
      " 16  D_Yd                     5464 non-null   float64\n",
      " 17  D_TD                     5464 non-null   float64\n",
      " 18  D_INT                    5464 non-null   float64\n",
      " 19  D_Sacked                 5464 non-null   float64\n",
      " 20  D_Sacked_Yards           5464 non-null   float64\n",
      " 21  D_Net_Pass_Yards         5464 non-null   float64\n",
      " 22  D_Total_Yards            5464 non-null   float64\n",
      " 23  D_Fumbles                5464 non-null   float64\n",
      " 24  D_Lost                   5464 non-null   float64\n",
      " 25  D_Turnovers              5464 non-null   float64\n",
      " 26  D_Penalties              5464 non-null   float64\n",
      " 27  D_Third_Down_Conv        5464 non-null   float64\n",
      " 28  D_Fourth_Down_Conv       5464 non-null   float64\n",
      " 29  D_Time_of_Possession     5464 non-null   float64\n",
      " 30  D_passing_att            5464 non-null   float64\n",
      " 31  D_passing_cmp            5464 non-null   float64\n",
      " 32  D_passing_int            5464 non-null   float64\n",
      " 33  D_passing_lng            5464 non-null   float64\n",
      " 34  D_passing_sk             5464 non-null   float64\n",
      " 35  D_passing_td             5464 non-null   float64\n",
      " 36  D_receiving_lng          5464 non-null   float64\n",
      " 37  D_rushing_att            5464 non-null   float64\n",
      " 38  D_rushing_lng            5464 non-null   float64\n",
      " 39  D_rushing_td             5464 non-null   float64\n",
      " 40  D_rushing_yds            5464 non-null   float64\n",
      " 41  D_passing_rushing_td     5464 non-null   float64\n",
      " 42  D_def_interceptions_int  5464 non-null   float64\n",
      " 43  D_def_interceptions_td   5464 non-null   float64\n",
      " 44  D_def_interceptions_yds  5464 non-null   float64\n",
      " 45  D_fumbles_ff             5464 non-null   float64\n",
      " 46  D_fumbles_fr             5464 non-null   float64\n",
      " 47  D_fumbles_td             5464 non-null   float64\n",
      " 48  D_fumbles_yds            5464 non-null   float64\n",
      " 49  D_sk                     5464 non-null   float64\n",
      " 50  D_tackles_ast            5464 non-null   float64\n",
      " 51  D_tackles_comb           5464 non-null   float64\n",
      " 52  D_tackles_solo           5464 non-null   float64\n",
      " 53  D_kick_punt_returns_lng  5464 non-null   float64\n",
      " 54  D_kick_punt_returns_rt   5464 non-null   float64\n",
      " 55  D_kick_punt_returns_yds  5464 non-null   float64\n",
      " 56  D_punting_pnt            5464 non-null   float64\n",
      " 57  D_punting_avg            5464 non-null   float64\n",
      " 58  D_scoring_fga            5464 non-null   float64\n",
      " 59  D_scoring_fgp            5464 non-null   float64\n",
      " 60  D_scoring_xpa            5464 non-null   float64\n",
      " 61  D_scoring_xpp            5464 non-null   float64\n",
      " 62  D_Final                  5464 non-null   float64\n",
      " 63  D_Final_Allowed          5464 non-null   float64\n",
      " 64  D_start_odds             5464 non-null   float64\n",
      " 65  D_halftime_odds          5464 non-null   float64\n",
      " 66  D_datediff               5464 non-null   float64\n",
      " 67  D_pythagorean            5464 non-null   float64\n",
      " 68  kick_punt_umap_dim_1     5264 non-null   float64\n",
      " 69  kick_punt_umap_dim_2     5264 non-null   float64\n",
      "dtypes: float64(65), int64(2), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "df after perf set removed: (5264, 70)\n",
      "performance set size: (200, 70)\n",
      "df after missing odds removed: (5264, 70)\n",
      "df perf after missing odds removed: (191, 70)\n",
      "<class 'umap.umap_.UMAP'>\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"./footballData/CombinedSlidingWindow4.csv\", index_col=False, low_memory=False)\n",
    "\n",
    "df.info()\n",
    "\n",
    "# The performance set's size is defined in the SlidingWindowNFL-1 file. When kick_punt_umap_dim_1 (or 2) is blank\n",
    "test_performance_df = df[df['kick_punt_umap_dim_1'].isna()]\n",
    "df = df[df['kick_punt_umap_dim_1'].isna() == False]\n",
    "print(f'df after perf set removed: {df.shape}')\n",
    "print(f'performance set size: {test_performance_df.shape}')\n",
    "\n",
    "# Remove missing odds data (Ignore data with no odds?)\n",
    "test_performance_df = test_performance_df[test_performance_df['D_start_odds'] != 0.0]\n",
    "\n",
    "print(f'df after missing odds removed: {df.shape}')\n",
    "print(f'df perf after missing odds removed: {test_performance_df.shape}')\n",
    "\n",
    "# Load the UMAP\n",
    "filename = \"kick_punt_umap.sav\"\n",
    "umap_model = None\n",
    "try:\n",
    "    with open(filename, 'rb') as file:\n",
    "        umap_model = pickle.load(file)\n",
    "        print(type(umap_model))\n",
    "except EOFError:\n",
    "    print(\"The file is empty or corrupt. Please check its content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26c9e0",
   "metadata": {},
   "source": [
    "### Remove items w/ missing odds data, apply UMAP to performance set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593aec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove missing odds data\n",
    "test_performance_df = test_performance_df[test_performance_df['D_start_odds'] != 0.0]\n",
    "print(test_performance_df.shape)\n",
    "\n",
    "# ---- Apply UMAP to performance set ----\n",
    "# Fit standardScaler on the training set\n",
    "umap_columns = [\"D_kick_punt_returns_lng\", \"D_kick_punt_returns_rt\", \"D_kick_punt_returns_yds\"]\n",
    "umap_train_df = df[umap_columns]\n",
    "umap_scaler = StandardScaler().fit(umap_train_df)\n",
    "\n",
    "# Scale the test set\n",
    "scaled_return_game_df = umap_scaler.transform(test_performance_df[umap_columns])\n",
    "\n",
    "if umap_model is None:\n",
    "    print(\"UMAP not correctly loaded FIX NOW\")\n",
    "\n",
    "umap_embedding = umap_model.transform(scaled_return_game_df)\n",
    "print(umap_embedding.shape)\n",
    "\n",
    "# Create the two new columns, drop the 4\n",
    "test_performance_df['kick_punt_umap_dim_1'] = umap_embedding[:,0]\n",
    "test_performance_df['kick_punt_umap_dim_2'] = umap_embedding[:,1]\n",
    "\n",
    "test_performance_df.drop(umap_columns, axis=1, inplace=True)\n",
    "df.drop(umap_columns, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9bfcf9-0964-4ed7-8fcb-3512b324b220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Visitor_Team</th>\n",
       "      <th>H_halftime_odds</th>\n",
       "      <th>V_halftime_odds</th>\n",
       "      <th>H_start_odds</th>\n",
       "      <th>V_start_odds</th>\n",
       "      <th>H_Won</th>\n",
       "      <th>D_First_Downs</th>\n",
       "      <th>D_Rush</th>\n",
       "      <th>D_Yds</th>\n",
       "      <th>D_TDs</th>\n",
       "      <th>D_Cmp</th>\n",
       "      <th>D_Att</th>\n",
       "      <th>D_Yd</th>\n",
       "      <th>D_TD</th>\n",
       "      <th>D_INT</th>\n",
       "      <th>D_Sacked</th>\n",
       "      <th>D_Sacked_Yards</th>\n",
       "      <th>D_Net_Pass_Yards</th>\n",
       "      <th>D_Total_Yards</th>\n",
       "      <th>D_Fumbles</th>\n",
       "      <th>D_Lost</th>\n",
       "      <th>D_Turnovers</th>\n",
       "      <th>D_Penalties</th>\n",
       "      <th>D_Third_Down_Conv</th>\n",
       "      <th>D_Fourth_Down_Conv</th>\n",
       "      <th>D_Time_of_Possession</th>\n",
       "      <th>D_passing_att</th>\n",
       "      <th>D_passing_cmp</th>\n",
       "      <th>D_passing_int</th>\n",
       "      <th>D_passing_lng</th>\n",
       "      <th>D_passing_sk</th>\n",
       "      <th>D_passing_td</th>\n",
       "      <th>D_receiving_lng</th>\n",
       "      <th>D_rushing_att</th>\n",
       "      <th>D_rushing_lng</th>\n",
       "      <th>D_rushing_td</th>\n",
       "      <th>D_rushing_yds</th>\n",
       "      <th>D_passing_rushing_td</th>\n",
       "      <th>D_def_interceptions_int</th>\n",
       "      <th>D_def_interceptions_td</th>\n",
       "      <th>D_def_interceptions_yds</th>\n",
       "      <th>D_fumbles_ff</th>\n",
       "      <th>D_fumbles_fr</th>\n",
       "      <th>D_fumbles_td</th>\n",
       "      <th>D_fumbles_yds</th>\n",
       "      <th>D_sk</th>\n",
       "      <th>D_tackles_ast</th>\n",
       "      <th>D_tackles_comb</th>\n",
       "      <th>D_tackles_solo</th>\n",
       "      <th>D_punting_pnt</th>\n",
       "      <th>D_punting_avg</th>\n",
       "      <th>D_scoring_fga</th>\n",
       "      <th>D_scoring_fgp</th>\n",
       "      <th>D_scoring_xpa</th>\n",
       "      <th>D_scoring_xpp</th>\n",
       "      <th>D_Final</th>\n",
       "      <th>D_Final_Allowed</th>\n",
       "      <th>D_start_odds</th>\n",
       "      <th>D_halftime_odds</th>\n",
       "      <th>D_datediff</th>\n",
       "      <th>D_pythagorean</th>\n",
       "      <th>kick_punt_umap_dim_1</th>\n",
       "      <th>kick_punt_umap_dim_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>7449</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>KAN</td>\n",
       "      <td>BUF</td>\n",
       "      <td>2.386667</td>\n",
       "      <td>1.577778</td>\n",
       "      <td>2.073398</td>\n",
       "      <td>1.724771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.049</td>\n",
       "      <td>14.342</td>\n",
       "      <td>-4.790</td>\n",
       "      <td>-10.070</td>\n",
       "      <td>-1.931</td>\n",
       "      <td>-67.962</td>\n",
       "      <td>5.714</td>\n",
       "      <td>52.173</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>3.239</td>\n",
       "      <td>1.041</td>\n",
       "      <td>-18.251</td>\n",
       "      <td>-53.359</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>1.029</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-3.945</td>\n",
       "      <td>-13.555</td>\n",
       "      <td>27.766</td>\n",
       "      <td>-4.679</td>\n",
       "      <td>3.271</td>\n",
       "      <td>1.649</td>\n",
       "      <td>-0.306</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>13.745</td>\n",
       "      <td>-10.854</td>\n",
       "      <td>-4.265</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>-35.108</td>\n",
       "      <td>-1.125</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-8.337</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.277</td>\n",
       "      <td>25.928</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-2.725</td>\n",
       "      <td>5.923</td>\n",
       "      <td>8.648</td>\n",
       "      <td>0.551</td>\n",
       "      <td>2.611</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.944908</td>\n",
       "      <td>9.706598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>7444</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>DET</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1.263333</td>\n",
       "      <td>3.894444</td>\n",
       "      <td>4.307745</td>\n",
       "      <td>1.203585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.376</td>\n",
       "      <td>-5.287</td>\n",
       "      <td>1.664</td>\n",
       "      <td>-19.688</td>\n",
       "      <td>6.013</td>\n",
       "      <td>-10.797</td>\n",
       "      <td>3.569</td>\n",
       "      <td>26.740</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>4.852</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>15.220</td>\n",
       "      <td>-15.201</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>16.338</td>\n",
       "      <td>-14.753</td>\n",
       "      <td>38.606</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>2.920</td>\n",
       "      <td>3.124</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>-4.086</td>\n",
       "      <td>-0.315</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>4.240</td>\n",
       "      <td>-1.072</td>\n",
       "      <td>-18.576</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-30.421</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.961</td>\n",
       "      <td>0.267</td>\n",
       "      <td>-2.540</td>\n",
       "      <td>-1.567</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>2.681</td>\n",
       "      <td>3.104</td>\n",
       "      <td>-2.631</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>4.765425</td>\n",
       "      <td>5.378789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>7445</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>KAN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1.345556</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>2.885004</td>\n",
       "      <td>1.396731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.149</td>\n",
       "      <td>-29.932</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>3.770</td>\n",
       "      <td>2.065</td>\n",
       "      <td>5.677</td>\n",
       "      <td>3.682</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-6.887</td>\n",
       "      <td>15.044</td>\n",
       "      <td>-17.795</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.246</td>\n",
       "      <td>1.906</td>\n",
       "      <td>-1.403</td>\n",
       "      <td>-7.241</td>\n",
       "      <td>0.512</td>\n",
       "      <td>7.909</td>\n",
       "      <td>4.222</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-2.455</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-1.230</td>\n",
       "      <td>-16.767</td>\n",
       "      <td>-3.475</td>\n",
       "      <td>-19.850</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-32.839</td>\n",
       "      <td>-1.727</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-13.352</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.207</td>\n",
       "      <td>14.747</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-8.664</td>\n",
       "      <td>-8.438</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-1.516</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-8.754</td>\n",
       "      <td>-2.969</td>\n",
       "      <td>1.488</td>\n",
       "      <td>-1.877</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.746289</td>\n",
       "      <td>10.155971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>7645</td>\n",
       "      <td>2023</td>\n",
       "      <td>2024-02-11</td>\n",
       "      <td>SFO</td>\n",
       "      <td>KAN</td>\n",
       "      <td>1.301111</td>\n",
       "      <td>3.472222</td>\n",
       "      <td>1.757009</td>\n",
       "      <td>2.028809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.930</td>\n",
       "      <td>23.153</td>\n",
       "      <td>3.614</td>\n",
       "      <td>-38.602</td>\n",
       "      <td>1.845</td>\n",
       "      <td>-27.846</td>\n",
       "      <td>2.388</td>\n",
       "      <td>45.530</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-3.815</td>\n",
       "      <td>6.219</td>\n",
       "      <td>22.362</td>\n",
       "      <td>34.943</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-6.133</td>\n",
       "      <td>18.912</td>\n",
       "      <td>-20.599</td>\n",
       "      <td>2.204</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.194</td>\n",
       "      <td>6.831</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.370</td>\n",
       "      <td>3.113</td>\n",
       "      <td>1.567</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.951</td>\n",
       "      <td>12.581</td>\n",
       "      <td>1.320</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.080</td>\n",
       "      <td>13.771</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-14.084</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-2.174</td>\n",
       "      <td>-5.335</td>\n",
       "      <td>-3.160</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.046</td>\n",
       "      <td>-1.315</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>1.278</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>3.839</td>\n",
       "      <td>3.252</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>-2.171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>6.982881</td>\n",
       "      <td>4.331357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>7808</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1.056667</td>\n",
       "      <td>9.383333</td>\n",
       "      <td>1.461897</td>\n",
       "      <td>2.642566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.140</td>\n",
       "      <td>14.184</td>\n",
       "      <td>7.482</td>\n",
       "      <td>-32.831</td>\n",
       "      <td>-7.632</td>\n",
       "      <td>-101.676</td>\n",
       "      <td>-0.471</td>\n",
       "      <td>56.893</td>\n",
       "      <td>-1.129</td>\n",
       "      <td>-1.901</td>\n",
       "      <td>-3.625</td>\n",
       "      <td>-37.717</td>\n",
       "      <td>-7.982</td>\n",
       "      <td>1.507</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-21.287</td>\n",
       "      <td>6.148</td>\n",
       "      <td>1.838</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-15.357</td>\n",
       "      <td>-12.401</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-3.408</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-3.691</td>\n",
       "      <td>10.496</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-1.471</td>\n",
       "      <td>29.735</td>\n",
       "      <td>-1.018</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.460</td>\n",
       "      <td>24.419</td>\n",
       "      <td>1.353</td>\n",
       "      <td>2.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-1.915</td>\n",
       "      <td>-3.603</td>\n",
       "      <td>-1.688</td>\n",
       "      <td>-1.445</td>\n",
       "      <td>-0.773</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-6.312</td>\n",
       "      <td>-1.181</td>\n",
       "      <td>-8.327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-2.863090</td>\n",
       "      <td>8.433458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Season        Date Home_Team Visitor_Team  H_halftime_odds  \\\n",
       "5264        7449    2023  2024-01-21       KAN          BUF         2.386667   \n",
       "5265        7444    2023  2024-01-28       DET          SFO         1.263333   \n",
       "5266        7445    2023  2024-01-28       KAN          BAL         1.345556   \n",
       "5267        7645    2023  2024-02-11       SFO          KAN         1.301111   \n",
       "5268        7808    2024  2024-10-10       SFO          SEA         1.056667   \n",
       "\n",
       "      V_halftime_odds  H_start_odds  V_start_odds  H_Won  D_First_Downs  \\\n",
       "5264         1.577778      2.073398      1.724771    1.0         -5.049   \n",
       "5265         3.894444      4.307745      1.203585    0.0         -0.376   \n",
       "5266         3.222222      2.885004      1.396731    1.0         -1.149   \n",
       "5267         3.472222      1.757009      2.028809    0.0          1.930   \n",
       "5268         9.383333      1.461897      2.642566    1.0         -6.140   \n",
       "\n",
       "      D_Rush  D_Yds   D_TDs  D_Cmp    D_Att   D_Yd    D_TD  D_INT  D_Sacked  \\\n",
       "5264  14.342 -4.790 -10.070 -1.931  -67.962  5.714  52.173 -0.224     3.239   \n",
       "5265  -5.287  1.664 -19.688  6.013  -10.797  3.569  26.740 -0.405     4.852   \n",
       "5266 -29.932 -1.342   3.770  2.065    5.677  3.682   1.174  0.019     0.237   \n",
       "5267  23.153  3.614 -38.602  1.845  -27.846  2.388  45.530  0.263    -3.815   \n",
       "5268  14.184  7.482 -32.831 -7.632 -101.676 -0.471  56.893 -1.129    -1.901   \n",
       "\n",
       "      D_Sacked_Yards  D_Net_Pass_Yards  D_Total_Yards  D_Fumbles  D_Lost  \\\n",
       "5264           1.041           -18.251        -53.359     -0.615   1.029   \n",
       "5265          -0.741            15.220        -15.201      0.130  -0.277   \n",
       "5266          -6.887            15.044        -17.795     -0.440   0.002   \n",
       "5267           6.219            22.362         34.943     -0.535  -0.615   \n",
       "5268          -3.625           -37.717         -7.982      1.507   0.691   \n",
       "\n",
       "      D_Turnovers  D_Penalties  D_Third_Down_Conv  D_Fourth_Down_Conv  \\\n",
       "5264       -0.423       -3.945            -13.555              27.766   \n",
       "5265       -0.445       16.338            -14.753              38.606   \n",
       "5266        0.246        1.906             -1.403              -7.241   \n",
       "5267       -0.271       -6.133             18.912             -20.599   \n",
       "5268       -0.143      -21.287              6.148               1.838   \n",
       "\n",
       "      D_Time_of_Possession  D_passing_att  D_passing_cmp  D_passing_int  \\\n",
       "5264                -4.679          3.271          1.649         -0.306   \n",
       "5265                -1.158          2.920          3.124         -0.397   \n",
       "5266                 0.512          7.909          4.222          0.376   \n",
       "5267                 2.204         -1.002         -0.423          0.194   \n",
       "5268                 0.993        -15.357        -12.401         -0.485   \n",
       "\n",
       "      D_passing_lng  D_passing_sk  D_passing_td  D_receiving_lng  \\\n",
       "5264          0.766         0.376        -0.178           13.745   \n",
       "5265         -4.086        -0.315        -0.269            4.240   \n",
       "5266         -2.455        -0.990        -1.230          -16.767   \n",
       "5267          6.831         0.779         0.370            3.113   \n",
       "5268         -3.408        -0.875         0.452           -3.691   \n",
       "\n",
       "      D_rushing_att  D_rushing_lng  D_rushing_td  D_rushing_yds  \\\n",
       "5264        -10.854         -4.265        -0.947        -35.108   \n",
       "5265         -1.072        -18.576         0.293        -30.421   \n",
       "5266         -3.475        -19.850        -0.497        -32.839   \n",
       "5267          1.567          2.206         0.951         12.581   \n",
       "5268         10.496         -0.232        -1.471         29.735   \n",
       "\n",
       "      D_passing_rushing_td  D_def_interceptions_int  D_def_interceptions_td  \\\n",
       "5264                -1.125                   -1.165                  -0.193   \n",
       "5265                 0.024                   -0.155                  -0.104   \n",
       "5266                -1.727                   -0.833                  -0.034   \n",
       "5267                 1.320                    1.064                   0.080   \n",
       "5268                -1.018                    0.526                   0.460   \n",
       "\n",
       "      D_def_interceptions_yds  D_fumbles_ff  D_fumbles_fr  D_fumbles_td  \\\n",
       "5264                   -8.337         0.421        -0.257         0.277   \n",
       "5265                    0.189         0.511        -0.168         0.000   \n",
       "5266                  -13.352        -0.654        -0.109         0.207   \n",
       "5267                   13.771        -0.396        -0.668        -0.155   \n",
       "5268                   24.419         1.353         2.059         0.000   \n",
       "\n",
       "      D_fumbles_yds   D_sk  D_tackles_ast  D_tackles_comb  D_tackles_solo  \\\n",
       "5264         25.928  0.859         -2.725           5.923           8.648   \n",
       "5265          1.961  0.267         -2.540          -1.567           0.973   \n",
       "5266         14.747  0.109         -8.664          -8.438           0.226   \n",
       "5267        -14.084 -0.516         -2.174          -5.335          -3.160   \n",
       "5268         -0.919  0.618         -1.915          -3.603          -1.688   \n",
       "\n",
       "      D_punting_pnt  D_punting_avg  D_scoring_fga  D_scoring_fgp  \\\n",
       "5264          0.551          2.611          1.207          0.139   \n",
       "5265          0.893          0.897         -0.082          0.198   \n",
       "5266         -0.408          1.400          0.973          0.093   \n",
       "5267          0.132         -1.046         -1.315         -0.326   \n",
       "5268         -1.445         -0.773          0.985          0.460   \n",
       "\n",
       "      D_scoring_xpa  D_scoring_xpp  D_Final  D_Final_Allowed  D_start_odds  \\\n",
       "5264         -1.272         -0.004   -5.790           -1.099         0.349   \n",
       "5265         -0.369         -0.064   -0.484            2.681         3.104   \n",
       "5266         -1.516         -0.004   -8.754           -2.969         1.488   \n",
       "5267          1.278         -0.052    3.839            3.252        -0.272   \n",
       "5268          0.000          0.000    0.062           -6.312        -1.181   \n",
       "\n",
       "      D_halftime_odds  D_datediff  D_pythagorean  kick_punt_umap_dim_1  \\\n",
       "5264            0.809         2.0         -0.073             -0.944908   \n",
       "5265           -2.631        -1.0         -0.178              4.765425   \n",
       "5266           -1.877        -1.0         -0.126              0.746289   \n",
       "5267           -2.171         0.0          0.104              6.982881   \n",
       "5268           -8.327         0.0          0.026             -2.863090   \n",
       "\n",
       "      kick_punt_umap_dim_2  \n",
       "5264              9.706598  \n",
       "5265              5.378789  \n",
       "5266             10.155971  \n",
       "5267              4.331357  \n",
       "5268              8.433458  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_df[:5]\n",
    "# print(test_performance_df['H_start_odds'][:5])\n",
    "# print(test_performance_df['V_start_odds'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc250",
   "metadata": {},
   "source": [
    "# Columns to use\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db79ec",
   "metadata": {},
   "source": [
    "## 1. Separate continuous, categorical, and label column names\n",
    "\n",
    "Pretty much everything is continuous. \n",
    "\n",
    "Note: the y_col is what you're trying to predict\n",
    "\n",
    "## Feature engineering\n",
    "New Columns\n",
    "- **h_win**: Home team won\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3960b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5264, 67)\n",
      "(5264, 48)\n",
      "(191, 5)\n",
      "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
      "5459    0.0      1.724771      2.073398              0.0              0.0\n",
      "5460    0.0      4.991514      1.159063              0.0              0.0\n",
      "5461    1.0      4.513858      1.188369              0.0              0.0\n",
      "5462    0.0      3.804017      1.250000              0.0              0.0\n",
      "5463    0.0      1.790476      1.986097              0.0              0.0\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "\n",
    "cont_cols = [col for col in nfl_utils.cont_cols if col not in nfl_utils.drop_cols]\n",
    "\n",
    "\n",
    "y_col = ['H_Won'] # Old\n",
    "y_col = ['H_Won', 'H_start_odds', 'V_start_odds']\n",
    "y_col_perf = ['H_Won', 'H_start_odds', 'V_start_odds', 'H_halftime_odds', 'V_halftime_odds']\n",
    "\n",
    "\n",
    "# create cont_df and y_df from the df\n",
    "print(df.shape)\n",
    "cont_df = df[cont_cols]\n",
    "y_df = df[y_col]\n",
    "\n",
    "# test performance set\n",
    "perf_conts_df = test_performance_df[cont_cols]\n",
    "perf_y_df = test_performance_df[y_col_perf]\n",
    "perf_date_df = test_performance_df[['Date','Home_Team', 'Visitor_Team']]\n",
    "\n",
    "# print(cont_df.dtypes)\n",
    "print(cont_df.shape)\n",
    "print(perf_y_df.shape)\n",
    "print(perf_y_df.tail())\n",
    "# print(perf_conts_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a936f59-3205-422f-b760-7296518b2739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
      "5264    1.0      2.073398      1.724771         2.386667         1.577778\n",
      "5265    0.0      4.307745      1.203585         1.263333         3.894444\n",
      "5266    1.0      2.885004      1.396731         1.345556         3.222222\n",
      "5267    0.0      1.757009      2.028809         1.301111         3.472222\n",
      "5268    1.0      1.461897      2.642566         1.056667         9.383333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_First_Downs</th>\n",
       "      <th>D_Rush</th>\n",
       "      <th>D_Yds</th>\n",
       "      <th>D_TDs</th>\n",
       "      <th>D_Cmp</th>\n",
       "      <th>D_Att</th>\n",
       "      <th>D_Yd</th>\n",
       "      <th>D_INT</th>\n",
       "      <th>D_Sacked</th>\n",
       "      <th>D_Sacked_Yards</th>\n",
       "      <th>D_Total_Yards</th>\n",
       "      <th>D_Fumbles</th>\n",
       "      <th>D_Lost</th>\n",
       "      <th>D_Turnovers</th>\n",
       "      <th>D_Penalties</th>\n",
       "      <th>D_Fourth_Down_Conv</th>\n",
       "      <th>D_Time_of_Possession</th>\n",
       "      <th>D_passing_att</th>\n",
       "      <th>D_passing_cmp</th>\n",
       "      <th>D_passing_int</th>\n",
       "      <th>D_passing_lng</th>\n",
       "      <th>D_passing_sk</th>\n",
       "      <th>D_passing_td</th>\n",
       "      <th>D_receiving_lng</th>\n",
       "      <th>D_rushing_att</th>\n",
       "      <th>D_rushing_lng</th>\n",
       "      <th>D_rushing_td</th>\n",
       "      <th>D_rushing_yds</th>\n",
       "      <th>D_def_interceptions_int</th>\n",
       "      <th>D_def_interceptions_td</th>\n",
       "      <th>D_def_interceptions_yds</th>\n",
       "      <th>D_fumbles_fr</th>\n",
       "      <th>D_fumbles_td</th>\n",
       "      <th>D_fumbles_yds</th>\n",
       "      <th>D_sk</th>\n",
       "      <th>D_tackles_ast</th>\n",
       "      <th>D_tackles_comb</th>\n",
       "      <th>D_tackles_solo</th>\n",
       "      <th>kick_punt_umap_dim_1</th>\n",
       "      <th>kick_punt_umap_dim_2</th>\n",
       "      <th>D_punting_pnt</th>\n",
       "      <th>D_punting_avg</th>\n",
       "      <th>D_scoring_fga</th>\n",
       "      <th>D_scoring_fgp</th>\n",
       "      <th>D_scoring_xpa</th>\n",
       "      <th>D_scoring_xpp</th>\n",
       "      <th>D_pythagorean</th>\n",
       "      <th>D_start_odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.265</td>\n",
       "      <td>5.140</td>\n",
       "      <td>-8.261</td>\n",
       "      <td>31.290</td>\n",
       "      <td>-8.121</td>\n",
       "      <td>43.430</td>\n",
       "      <td>4.074</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>134.107</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>22.515</td>\n",
       "      <td>35.846</td>\n",
       "      <td>-1.945</td>\n",
       "      <td>15.846</td>\n",
       "      <td>8.055</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>34.941</td>\n",
       "      <td>-2.048</td>\n",
       "      <td>1.702</td>\n",
       "      <td>32.967</td>\n",
       "      <td>-6.551</td>\n",
       "      <td>24.316</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-11.221</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.276</td>\n",
       "      <td>10.643</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.599</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.291422</td>\n",
       "      <td>9.552850</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-1.273</td>\n",
       "      <td>0.662</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>2.044</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.629</td>\n",
       "      <td>-29.721</td>\n",
       "      <td>-20.239</td>\n",
       "      <td>105.471</td>\n",
       "      <td>-4.695</td>\n",
       "      <td>135.596</td>\n",
       "      <td>-6.074</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-6.794</td>\n",
       "      <td>-1.007</td>\n",
       "      <td>-58.301</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-2.555</td>\n",
       "      <td>13.787</td>\n",
       "      <td>-5.022</td>\n",
       "      <td>-2.121</td>\n",
       "      <td>1.048</td>\n",
       "      <td>1.272</td>\n",
       "      <td>19.176</td>\n",
       "      <td>1.702</td>\n",
       "      <td>0.835</td>\n",
       "      <td>7.434</td>\n",
       "      <td>-14.743</td>\n",
       "      <td>-19.537</td>\n",
       "      <td>-2.132</td>\n",
       "      <td>-82.452</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.096</td>\n",
       "      <td>1.397</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-11.360</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.618100</td>\n",
       "      <td>7.267665</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>5.719</td>\n",
       "      <td>1.636</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-1.904</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>1.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.647</td>\n",
       "      <td>-7.419</td>\n",
       "      <td>-4.353</td>\n",
       "      <td>41.000</td>\n",
       "      <td>3.283</td>\n",
       "      <td>62.070</td>\n",
       "      <td>-4.474</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-3.724</td>\n",
       "      <td>-4.224</td>\n",
       "      <td>65.592</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-1.324</td>\n",
       "      <td>-13.379</td>\n",
       "      <td>13.787</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>2.772</td>\n",
       "      <td>-2.246</td>\n",
       "      <td>0.033</td>\n",
       "      <td>21.437</td>\n",
       "      <td>-3.029</td>\n",
       "      <td>10.765</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>-4.886</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-10.676</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-21.176</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.573103</td>\n",
       "      <td>1.891357</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-4.020</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-1.007</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.827</td>\n",
       "      <td>-3.625</td>\n",
       "      <td>2.011</td>\n",
       "      <td>-21.217</td>\n",
       "      <td>5.103</td>\n",
       "      <td>37.158</td>\n",
       "      <td>7.551</td>\n",
       "      <td>2.173</td>\n",
       "      <td>-2.059</td>\n",
       "      <td>-13.463</td>\n",
       "      <td>144.618</td>\n",
       "      <td>0.544</td>\n",
       "      <td>1.187</td>\n",
       "      <td>3.801</td>\n",
       "      <td>-11.202</td>\n",
       "      <td>49.173</td>\n",
       "      <td>5.379</td>\n",
       "      <td>14.000</td>\n",
       "      <td>10.915</td>\n",
       "      <td>3.441</td>\n",
       "      <td>21.096</td>\n",
       "      <td>-3.386</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>47.860</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-5.044</td>\n",
       "      <td>1.118</td>\n",
       "      <td>-11.184</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.165</td>\n",
       "      <td>8.996</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.044179</td>\n",
       "      <td>8.739308</td>\n",
       "      <td>-4.794</td>\n",
       "      <td>-4.150</td>\n",
       "      <td>2.202</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-5.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.110</td>\n",
       "      <td>-15.445</td>\n",
       "      <td>10.092</td>\n",
       "      <td>-12.125</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-82.890</td>\n",
       "      <td>1.221</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-3.026</td>\n",
       "      <td>0.585</td>\n",
       "      <td>13.544</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.544</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>11.952</td>\n",
       "      <td>6.434</td>\n",
       "      <td>1.794</td>\n",
       "      <td>-8.794</td>\n",
       "      <td>-8.033</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-3.371</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-1.228</td>\n",
       "      <td>-34.746</td>\n",
       "      <td>9.721</td>\n",
       "      <td>-6.382</td>\n",
       "      <td>0.754</td>\n",
       "      <td>40.412</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-18.860</td>\n",
       "      <td>-1.121</td>\n",
       "      <td>0.276</td>\n",
       "      <td>1.985</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.613956</td>\n",
       "      <td>2.804782</td>\n",
       "      <td>-1.349</td>\n",
       "      <td>-5.401</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   D_First_Downs  D_Rush   D_Yds    D_TDs  D_Cmp    D_Att   D_Yd  D_INT  \\\n",
       "0          2.265   5.140  -8.261   31.290 -8.121   43.430  4.074 -0.684   \n",
       "1         -3.629 -29.721 -20.239  105.471 -4.695  135.596 -6.074 -0.011   \n",
       "2          2.647  -7.419  -4.353   41.000  3.283   62.070 -4.474 -0.184   \n",
       "3          6.827  -3.625   2.011  -21.217  5.103   37.158  7.551  2.173   \n",
       "4          3.110 -15.445  10.092  -12.125 -0.239  -82.890  1.221  0.368   \n",
       "\n",
       "   D_Sacked  D_Sacked_Yards  D_Total_Yards  D_Fumbles  D_Lost  D_Turnovers  \\\n",
       "0    -0.044          -4.750        134.107     -0.342  -0.103       -1.526   \n",
       "1    -6.794          -1.007        -58.301      0.239   0.537        0.941   \n",
       "2    -3.724          -4.224         65.592     -1.029  -0.110       -1.324   \n",
       "3    -2.059         -13.463        144.618      0.544   1.187        3.801   \n",
       "4    -3.026           0.585         13.544      0.518  -0.544       -0.162   \n",
       "\n",
       "   D_Penalties  D_Fourth_Down_Conv  D_Time_of_Possession  D_passing_att  \\\n",
       "0       22.515              35.846                -1.945         15.846   \n",
       "1       -2.555              13.787                -5.022         -2.121   \n",
       "2      -13.379              13.787                -1.588          0.430   \n",
       "3      -11.202              49.173                 5.379         14.000   \n",
       "4       11.952               6.434                 1.794         -8.794   \n",
       "\n",
       "   D_passing_cmp  D_passing_int  D_passing_lng  D_passing_sk  D_passing_td  \\\n",
       "0          8.055         -1.257         34.941        -2.048         1.702   \n",
       "1          1.048          1.272         19.176         1.702         0.835   \n",
       "2          0.305         -0.460          2.772        -2.246         0.033   \n",
       "3         10.915          3.441         21.096        -3.386        -0.460   \n",
       "4         -8.033         -0.360         -3.371         0.007        -1.228   \n",
       "\n",
       "   D_receiving_lng  D_rushing_att  D_rushing_lng  D_rushing_td  D_rushing_yds  \\\n",
       "0           32.967         -6.551         24.316        -0.099        -11.221   \n",
       "1            7.434        -14.743        -19.537        -2.132        -82.452   \n",
       "2           21.437         -3.029         10.765        -0.415         -4.886   \n",
       "3           47.860         -0.140         -5.044         1.118        -11.184   \n",
       "4          -34.746          9.721         -6.382         0.754         40.412   \n",
       "\n",
       "   D_def_interceptions_int  D_def_interceptions_td  D_def_interceptions_yds  \\\n",
       "0                    0.180                   0.276                   10.643   \n",
       "1                   -0.820                   0.000                    2.096   \n",
       "2                   -0.952                  -0.165                  -10.676   \n",
       "3                    0.614                   0.165                    8.996   \n",
       "4                   -0.044                  -0.276                  -18.860   \n",
       "\n",
       "   D_fumbles_fr  D_fumbles_td  D_fumbles_yds   D_sk  D_tackles_ast  \\\n",
       "0        -0.835         0.000         -4.599  0.526            0.0   \n",
       "1         1.397        -0.165        -11.360 -1.272            0.0   \n",
       "2        -0.140        -0.460        -21.176 -0.165            0.0   \n",
       "3         0.937         0.000          0.662  0.732            0.0   \n",
       "4        -1.121         0.276          1.985 -0.298            0.0   \n",
       "\n",
       "   D_tackles_comb  D_tackles_solo  kick_punt_umap_dim_1  kick_punt_umap_dim_2  \\\n",
       "0             0.0             0.0              5.291422              9.552850   \n",
       "1             0.0             0.0              7.618100              7.267665   \n",
       "2             0.0             0.0              2.573103              1.891357   \n",
       "3             0.0             0.0              4.044179              8.739308   \n",
       "4             0.0             0.0              3.613956              2.804782   \n",
       "\n",
       "   D_punting_pnt  D_punting_avg  D_scoring_fga  D_scoring_fgp  D_scoring_xpa  \\\n",
       "0          0.599         -1.273          0.662         -0.094          2.044   \n",
       "1         -0.864          5.719          1.636         -0.153         -1.904   \n",
       "2         -0.989         -4.020          0.901          0.242         -1.007   \n",
       "3         -4.794         -4.150          2.202          0.255         -0.390   \n",
       "4         -1.349         -5.401         -0.890          0.103         -0.022   \n",
       "\n",
       "   D_scoring_xpp  D_pythagorean  D_start_odds  \n",
       "0          0.441          0.114         1.181  \n",
       "1          0.099         -0.063         1.330  \n",
       "2         -0.526          0.179         0.741  \n",
       "3         -0.360          0.248        -5.646  \n",
       "4          0.000          0.007         1.181  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(perf_y_df[:5])\n",
    "cont_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05613417",
   "metadata": {},
   "source": [
    "#### 1a. Normalize cont_df\n",
    "StandardScaler is instead used by the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e76a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "cont_scaled = standard_scaler.fit_transform(cont_df.values)\n",
    "cont_df = pd.DataFrame(cont_scaled)\n",
    "# print(cont_df.head())\n",
    "\n",
    "# test performance set\n",
    "perf_conts_df_scaled = standard_scaler.fit_transform(perf_conts_df.values)\n",
    "perf_conts_df = pd.DataFrame(perf_conts_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1912ae",
   "metadata": {},
   "source": [
    "### 3. Create an array of continuous values\n",
    "Numpy array 'conts' containing stack of each continuous column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([cont_df[col].values for col in list(cont_df.columns)], 1)\n",
    "conts[:5]\n",
    "\n",
    "y_col = np.stack([y_df[col].values for col in y_col], 1)\n",
    "\n",
    "# test performance set\n",
    "perf_conts = np.stack([perf_conts_df[col].values for col in list(perf_conts_df.columns)], 1)\n",
    "perf_y_col = np.stack([perf_y_df[col].values for col in list(perf_y_df.columns)], 1)\n",
    "perf_date_col = np.stack([perf_date_df[col].values for col in list(perf_date_df.columns)], 1)\n",
    "\n",
    "\n",
    "conts_train = conts\n",
    "y_train = y_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2547a",
   "metadata": {},
   "source": [
    "### 4. Convert conts to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5264, 48)\n",
      "(5264, 3)\n"
     ]
    }
   ],
   "source": [
    "print(conts.shape)\n",
    "print(y_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handled by model.fit()\n",
    "# conts = torch.tensor(conts, dtype=torch.float32)\n",
    "# y_col = torch.tensor(y_col, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb278a38-cb66-41d3-9652-85996190807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Want: \n",
    "    An array > 1 elements for PCC formula\n",
    "    A smaller array for kelly_criterion\n",
    "    \n",
    "\n",
    "\n",
    "x: 1d array of predictions between -1 and 1 where negative number means visitor predicted to win\n",
    "y: ['H_Won', 'H_start_odds', 'V_start_odds']\n",
    "pearson_multiplier: constant to multiply the pearson correlation coefficient's result by\n",
    "max_bet_pct: max percentage allowed per bet.\n",
    "return_res_array: Skip the torch.cumprod part\n",
    "\"\"\"\n",
    "def nfl_custom_criterion(x, y, pearson_multiplier=0.5, max_bet_pct=0.1, return_res_array=False):\n",
    "    # ------------------------------------------------\n",
    "    # Preliminary calculations\n",
    "    # ------------------------------------------------\n",
    "    # acct_value = 100 # Preset account value\n",
    "    batch_size = len(x)\n",
    "    h_start_odds = y[:,1]\n",
    "    v_start_odds = y[:,2]\n",
    "    h_won = y[:,0]\n",
    "    y_decimal_odds = torch.where(x > 0, h_start_odds, v_start_odds) # Decimal odds for model's predicted outcome\n",
    "    y_prob = 1 / y_decimal_odds                  # Implied Probability (regardless of correct prediction)\n",
    "    x_H_Won = torch.round(torch.sigmoid(20 * x)) # H_won for predicted bets (Converts model's -1 to 1 range to 0 to 1)\n",
    "                                                 # Sigmoid so that it's differentiable. The 20 is arbitrarily large number\n",
    "    y_incorrect_prediction = torch.abs((x_H_Won - h_won))        # 1 if wrong bet, otherwise 0. Used to reset kelly when wrong\n",
    "    y_incorrect_prediction_mult_two = 2 * y_incorrect_prediction   # 2 if wrong bet, 0 if correct\n",
    "\n",
    "    #x = torch.abs(x)         # OLD VERSION\n",
    "    x_prob = torch.where(x > 0, (x + 1) / 2, (1 - x) / 2)\n",
    "    x = x_prob                # x is now the implied probability(?) of your prediction.\n",
    "                              # It's a number between 0 and 1 (formerly -1 and 1) representing the model's predicted probability of a win.\n",
    "                              # This now only shows the probability. Not whether it was correct & not for which side (home vs visitor)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # 1. Calculate the Pearson Correlation Coefficient\n",
    "    #    Currently includes cases where predicted wrong\n",
    "    #    ^ This is filtered out after step 2\n",
    "    # ------------------------------------------------\n",
    "    n = x.size(0)\n",
    "    sum_x = torch.sum(x)\n",
    "    sum_x_squared = torch.sum(x**2)\n",
    "    sum_y = torch.sum(y_prob)\n",
    "    sum_y_squared = torch.sum(y_prob**2)\n",
    "    sum_pow_x = torch.sum(x**2)\n",
    "    sum_pow_y = torch.sum(y_prob**2)\n",
    "    x_mul_y = torch.mul(x, y_prob)\n",
    "    sum_x_mul_y = torch.sum(x_mul_y)\n",
    "\n",
    "    \n",
    "    # PCC Formula (eps to avoid NaN)\n",
    "    eps = 1e-8\n",
    "    pcc_numerator = n * sum_x_mul_y - sum_x * sum_y\n",
    "    pcc_denominator_one = torch.sqrt(n * sum_pow_x - sum_x_squared + eps)\n",
    "    pcc_denominator_two = torch.sqrt(n * sum_pow_y - sum_y_squared + eps)\n",
    "    pcc = pcc_numerator / (pcc_denominator_one * pcc_denominator_two + eps)\n",
    "    pcc = pearson_multiplier * torch.abs(pcc)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # 2. Calculate the kelly criterion\n",
    "    #    Entirely wrong predictions are negated and kept in \"incorrect_bets\" (pcc not applied to wrong predictions)\n",
    "    #    Correct predictions are kept in \"correct_bets\". Pcc is applied to this & stored in pcc_adjusted_correct_bets\n",
    "    #    Possible issue: This always bets max_bet_pct\n",
    "    #    The result is cumulatively calculated. i.e. The sum of the previous values are used to calculate the next one\n",
    "    # ------------------------------------------------\n",
    "    # kelly_criterion = x - ((1 - x) / y_decimal_odds)  # OLD VERSION\n",
    "    kelly_criterion = x - ((1 - x) / (y_decimal_odds - 1))\n",
    "    bet_multiplier = torch.clamp(kelly_criterion, min=0)   # Kelly results that are negative are ignored\n",
    "    bet_multiplier = bet_multiplier*max_bet_pct            # Scale down the bets to the maximum allowed percentage per bet\n",
    "\n",
    "\n",
    "    # 4/5/25 adjustment of kelly\n",
    "    #    Want to use cumprod. Cumsum does nothing and is the same as torch.sum in this scenario?\n",
    "    #    Basically start with max_bet_pct and return as if you made the bets sequentially\n",
    "    correct_bet_multiplier = bet_multiplier - (bet_multiplier * y_incorrect_prediction)          # Correct bets after kelly. Bet multiplier or 0\n",
    "    correct_bet_multiplier = correct_bet_multiplier * (1 - pcc)                                  # \"correct_bet_multiplier\" penalized by pcc\n",
    "    assert torch.all(correct_bet_multiplier <= max_bet_pct), \"Correct bet mult. can't exceed max bet pct\"\n",
    "\n",
    "    correct_bet_multiplier = correct_bet_multiplier * y_decimal_odds                             # Bet multiplier taking market odds into account\n",
    "    incorrect_bet_multiplier = bet_multiplier - (bet_multiplier * y_incorrect_prediction_mult_two) # Negative numbers are incorrect bets\n",
    "    incorrect_bet_multiplier = torch.clamp(incorrect_bet_multiplier, max=0)                      # Restrict to 0 or negative\n",
    "    combined_bet_multiplier = correct_bet_multiplier + incorrect_bet_multiplier                  # Combine correct & incorrect bet multipliers\n",
    "    combined_bet_multiplier = combined_bet_multiplier + 1                                        # Converts to format friendly to cumprod\n",
    "                                                                                                 # Ex: loss=-0.3, profit=0.3 --> loss=0.7, profit=1.3\n",
    "\n",
    "    assert torch.all((x >= 0) & (x <= 1)), \"Probabilities must be between 0 and 1\"\n",
    "    assert torch.all(y_decimal_odds > 1), \"Decimal odds must be greater than 1\"\n",
    "    assert torch.all(kelly_criterion <= 1), \"Kelly Criterion cannot be greater than 1\"\n",
    "    assert torch.all(incorrect_bet_multiplier >= -max_bet_pct), \"Incorrect bet mult. can't exceed max bet pct\"\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Combine & Return\n",
    "    #     Negate everything for Adam & optuna\n",
    "    # ------------------------------------------------\n",
    "    if return_res_array:\n",
    "        return combined_bet_multiplier\n",
    "        \n",
    "    # Prepend max_bet_pct to the tensor before torch.cumprod\n",
    "    res = torch.sum(combined_bet_multiplier) / batch_size\n",
    "    # print(res)\n",
    "    return -res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9875b494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TabularModelUpdated(nn.Module, BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, optimizer_class=torch.optim.Adam,\n",
    "                 lr=0.001, confidence_threshold=0.1, batch_size=1000):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "\n",
    "        # Training params\n",
    "        # self.criterion = criterion\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.Mish(),  # Mish instead of ReLU\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.Mish(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([nn.Linear(self.layer_shape[-1], out_sz)])\n",
    "        \n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist).to(self.device)\n",
    "        \n",
    "        # Initialize the optimizer & scheduler\n",
    "        self.optimizer = optimizer_class(self.parameters(), lr=self.lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min',\n",
    "                                                                    factor=0.1, patience=10,\n",
    "                                                                    threshold=0.0001,threshold_mode='rel',\n",
    "                                                                    cooldown=0, min_lr=0, eps=1e-08)\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        # x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return torch.clamp(x, -1, 1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X).to(self.device)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y).to(self.device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        # optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        # Verify optimizer exists\n",
    "        if not hasattr(self, 'optimizer'):\n",
    "            raise ValueError(\"Optimizer not initialized. Set self.optimizer in __init__.\")\n",
    "\n",
    "        dataset = TensorDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        # Training loop\n",
    "        running_loss = []    # This is only for training over final dataset\n",
    "        self.train()\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred = self.forward(X_batch)[:,0]\n",
    "            #loss = self.criterion(y_pred, y_batch)\n",
    "            loss = nfl_custom_criterion(y_pred, y_batch)\n",
    "            running_loss.append(loss)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        # return self  # TODO: This being replaced w/ loss might break things\n",
    "        return torch.mean(torch.stack(running_loss))\n",
    "\n",
    "    def step_lr(self, val_loss):\n",
    "        \"\"\"\n",
    "        Since CV is run outside of this class, we need to update the local self.optimizer variable\n",
    "        after each CV fold.\n",
    "        \"\"\"\n",
    "        self.scheduler.step(val_loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self(X).squeeze()\n",
    "        return y_pred\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "    \n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "    \n",
    "        dataset = TensorDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                y_pred = self.forward(X_batch)[:, 0]  # [batch_size]\n",
    "                batch_loss = nfl_custom_criterion(y_pred, y_batch)  # scalar\n",
    "                total_loss += batch_loss.item() * len(X_batch)\n",
    "                count += len(X_batch)\n",
    "    \n",
    "        return total_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b31ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, override_params=None):\n",
    "    \"\"\"\n",
    "    When doing optuna training: trial is defined, override_params left as None\n",
    "    when recreating model using best parameters (override_params): trial is None, override_params are defined\n",
    "    \"\"\"\n",
    "    is_training = trial != None\n",
    "    # --- Suggest hyperparameters ---\n",
    "    # criterion = trial.suggest_categorical('criterion', nfl_utils.map_losses(None).keys())\n",
    "    if is_training:\n",
    "        batch_size = trial.suggest_categorical('batch_size', [100, 400, 1000, 3000])\n",
    "        first_layer_size = trial.suggest_categorical('first_layer_size', [64, 56, 48, 32, 16, 12])\n",
    "        min_layers = math.floor(math.sqrt(first_layer_size))\n",
    "        num_layers = trial.suggest_int('num_layers', 2, min_layers)\n",
    "        confidence_threshold = trial.suggest_float('confidence_threshold', 0, 0.05)\n",
    "        dropout = trial.suggest_float('dropout', 0.28, 0.38)\n",
    "        lr = trial.suggest_float('lr', 1e-3, 1e-2, log=True)\n",
    "    else:\n",
    "        batch_size = override_params[\"batch_size\"]\n",
    "        first_layer_size = override_params[\"first_layer_size\"]\n",
    "        num_layers = override_params[\"num_layers\"]\n",
    "        confidence_threshold = override_params[\"confidence_threshold\"]\n",
    "        dropout = override_params[\"dropout\"]\n",
    "        lr = override_params[\"lr\"]\n",
    "    \n",
    "    layer_shape = [first_layer_size]\n",
    "    for i in range(1, num_layers):\n",
    "        layer_shape.append(first_layer_size//(2*i))\n",
    "\n",
    "    # Set random state to have consistent results (42 is arbitrary)\n",
    "    set_all_seeds()\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Split once\n",
    "    X_train_fold = []\n",
    "    X_val = []\n",
    "    y_train_fold = []\n",
    "    y_val = []\n",
    "    models = []\n",
    "    for train_index, val_index in kf.split(conts_train):\n",
    "        # print(f\"train {train_index.shape} val {val_index.shape}\")\n",
    "        X_train_fold.append(torch.FloatTensor(conts_train[train_index]).to(device))\n",
    "        X_val.append(torch.FloatTensor(conts_train[val_index]).to(device))\n",
    "\n",
    "        y_train_fold.append(torch.FloatTensor(y_train[train_index]).to(device))\n",
    "        y_val.append(torch.FloatTensor(y_train[val_index]).to(device))\n",
    "\n",
    "        model = TabularModelUpdated(\n",
    "            n_cont=conts.shape[1],\n",
    "            out_sz=1,\n",
    "            layer_shape=layer_shape,\n",
    "            p=dropout,     # Dropout\n",
    "            # criterion=nfl_utils.map_losses(criterion),\n",
    "            optimizer_class=torch.optim.Adam,\n",
    "            lr=lr,   # Learning rate \n",
    "            confidence_threshold=confidence_threshold,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        models.append(model)\n",
    "\n",
    "    # If not training, ignore CV\n",
    "    if is_training is False:\n",
    "        # put everything in one fold to ignore CV\n",
    "        n_splits = 1 \n",
    "        X_train_fold.append(torch.FloatTensor(conts_train).to(device))\n",
    "        y_train_fold.append(torch.FloatTensor(y_train).to(device))\n",
    "        # X_val & y_val is not used since we train on whole dataset\n",
    "    \n",
    "    # Run once on each split, track average loss, stop if > max patience\n",
    "    max_patience = 10\n",
    "    current_patience = max_patience\n",
    "    tracked_loss = 0.0\n",
    "    n_epochs = 0\n",
    "    while current_patience > 0 or n_epochs < 10:\n",
    "        n_epochs = n_epochs + 1\n",
    "        running_loss = []\n",
    "        for i in range(0,n_splits):\n",
    "            # ----- Train -----\n",
    "            model_score = models[i].fit(X_train_fold[i], y_train_fold[i])\n",
    "\n",
    "            # ----- Eval -----\n",
    "            # print(f\"los: {models[i].score(X_val[i], y_val[i])} type: {type(models[i].score(X_val[i], y_val[i]))}\")\n",
    "            if is_training:\n",
    "                model_score = models[i].score(X_val[i], y_val[i])\n",
    "            else:\n",
    "                model_score = model_score.detach().numpy()\n",
    "            running_loss.append(model_score)\n",
    "            models[i].step_lr(model_score)\n",
    "\n",
    "        # print(f\"{running_loss} at {n_epochs}\")\n",
    "        running_loss = np.mean(running_loss)\n",
    "        # print(f\"rloss: {running_loss}\")\n",
    "        \n",
    "        # ----- Current epoch loss < previous -----\n",
    "        # print(f\"{tracked_loss} {running_loss} {tracked_loss > running_loss}\")\n",
    "        if tracked_loss > running_loss:\n",
    "            current_patience = max_patience\n",
    "            tracked_loss = running_loss\n",
    "        else:\n",
    "            current_patience = current_patience - 1\n",
    "\n",
    "    # Return the tracked_loss if in optuna training (trial != None)\n",
    "    if is_training:\n",
    "        trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "        trial.report(tracked_loss, n_epochs)\n",
    "        return tracked_loss\n",
    "\n",
    "    # When not training, only the first model is relevant since CV is ignored\n",
    "    return models[0]\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value}\")\n",
    "    print(f\"Best trial so far: {study.best_trial.number}, value: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd663af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 19:46:27,713] A new study created in memory with name: no-name-3608cf28-c804-4133-865b-8421ab2e9e1f\n",
      "[W 2025-05-01 19:46:29,498] Trial 0 failed with parameters: {'batch_size': 3000, 'first_layer_size': 12, 'num_layers': 3, 'confidence_threshold': 0.01981474771636556, 'dropout': 0.3498476638880475, 'lr': 0.0033646825924544383} because of the following error: AssertionError(\"Correct bet mult. can't exceed max bet pct\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/forbesjon2/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_19326/163893759.py\", line 79, in objective\n",
      "    model_score = models[i].fit(X_train_fold[i], y_train_fold[i])\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_19326/1833517405.py\", line 85, in fit\n",
      "    loss = nfl_custom_criterion(y_pred, y_batch)\n",
      "  File \"/var/folders/k0/7b4qgkdx2vb9ml4ktdckf0hc0000gn/T/ipykernel_19326/1199472572.py\", line 80, in nfl_custom_criterion\n",
      "    assert torch.all(correct_bet_multiplier <= max_bet_pct), \"Correct bet mult. can't exceed max bet pct\"\n",
      "AssertionError: Correct bet mult. can't exceed max bet pct\n",
      "[W 2025-05-01 19:46:29,500] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Correct bet mult. can't exceed max bet pct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Uncomment to run\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# study.optimize(objective, n_trials=3)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchenv/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[14], line 79\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, override_params)\u001b[0m\n\u001b[1;32m     76\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,n_splits):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# ----- Train -----\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     model_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# ----- Eval -----\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# print(f\"los: {models[i].score(X_val[i], y_val[i])} type: {type(models[i].score(X_val[i], y_val[i]))}\")\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_training:\n",
      "Cell \u001b[0;32mIn[13], line 85\u001b[0m, in \u001b[0;36mTabularModelUpdated.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_batch)[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#loss = self.criterion(y_pred, y_batch)\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnfl_custom_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m running_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     87\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[12], line 80\u001b[0m, in \u001b[0;36mnfl_custom_criterion\u001b[0;34m(x, y, pearson_multiplier, max_bet_pct, return_res_array)\u001b[0m\n\u001b[1;32m     78\u001b[0m correct_bet_multiplier \u001b[38;5;241m=\u001b[39m bet_multiplier \u001b[38;5;241m-\u001b[39m (bet_multiplier \u001b[38;5;241m*\u001b[39m y_incorrect_prediction)          \u001b[38;5;66;03m# Correct bets after kelly. Bet multiplier or 0\u001b[39;00m\n\u001b[1;32m     79\u001b[0m correct_bet_multiplier \u001b[38;5;241m=\u001b[39m correct_bet_multiplier \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pcc)                                  \u001b[38;5;66;03m# \"correct_bet_multiplier\" penalized by pcc\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(correct_bet_multiplier \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_bet_pct), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrect bet mult. can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exceed max bet pct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m correct_bet_multiplier \u001b[38;5;241m=\u001b[39m correct_bet_multiplier \u001b[38;5;241m*\u001b[39m y_decimal_odds                             \u001b[38;5;66;03m# Bet multiplier taking market odds into account\u001b[39;00m\n\u001b[1;32m     83\u001b[0m incorrect_bet_multiplier \u001b[38;5;241m=\u001b[39m bet_multiplier \u001b[38;5;241m-\u001b[39m (bet_multiplier \u001b[38;5;241m*\u001b[39m y_incorrect_prediction_mult_two) \u001b[38;5;66;03m# Negative numbers are incorrect bets\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Correct bet mult. can't exceed max bet pct"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1,\n",
    "        max_resource=1000\n",
    "    )\n",
    ")\n",
    "# Uncomment to run\n",
    "if True:\n",
    "    study.optimize(objective, n_trials=200, callbacks=[print_callback])\n",
    "    # study.optimize(objective, n_trials=3)\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"Value: \", trial.value)\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ea5b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_params = study.best_trial.params\n",
    "# Trial 121 finished with value: -1756081089942937.5 and parameters:\n",
    "best_params = {'batch_size': 100, 'first_layer_size': 16, 'num_layers': 2, 'confidence_threshold': 0.03489120689273306, 'dropout': 0.29423607324535794, 'lr': 0.009613362543526419, 'n_epochs': 53}\n",
    "\n",
    "model = objective(None, best_params)\n",
    "probas = model.predict(perf_conts)\n",
    "perf_y_col_tensor = torch.FloatTensor(perf_y_col).to(device)\n",
    "\n",
    "performance_tensor = nfl_custom_criterion(probas, perf_y_col_tensor, 0.5, 0.1, True)\n",
    "\n",
    "\n",
    "y_axis = torch.cumprod(performance_tensor, dim=0).numpy()\n",
    "x_axis = np.arange(len(y_axis))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_axis, y_axis)\n",
    "# plt.title(f'Backtest Results\\nWin Rate: {win_rate:.2%} | ROI: {roi:.2%} | Max DD: {max_drawdown:.2%}')\n",
    "plt.xlabel('Number of Games')\n",
    "plt.ylabel('Account Value')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# print(performance_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5844eb-ecd7-44ff-8e36-e60139554f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_tensor = nfl_custom_criterion(probas, perf_y_col_tensor, 0.5, 0.1, True)\n",
    "\n",
    "print(performance_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c7a4f-eaad-4145-bcd6-765ed7d1c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_tensor = nfl_custom_criterion(probas, perf_y_col_tensor, 0.5, 0.1, True).numpy()\n",
    "print(performance_tensor)\n",
    "print(perf_date_col)\n",
    "nfl_utils.backtest_model_custom_loss(performance_tensor, perf_date_col, initial_capital=100, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92020224-b9cf-4c61-9dbc-3d0a536d2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_utils.backtest_model(model, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.1, \n",
    "                   confidence_threshold=0.0, show_plot=True, max_won_odds=2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109e37c",
   "metadata": {},
   "source": [
    "Value:  0.37491718013436764\n",
    "\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 39\n",
    "    dropout: 0.47875406200808335\n",
    "    lr: 0.009997751942238913\n",
    "    \n",
    "\n",
    "\n",
    "Value:  0.3759073484440955\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 68\n",
    "    dropout: 0.4497689844977892\n",
    "    lr: 0.007977206154472633\n",
    "    \n",
    "    \n",
    "    \n",
    "12/6\n",
    "\n",
    "Trial 206 finished with value: 0.547218605316966 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.05966702820817666, 'n_epochs': 379, 'dropout': 0.36961850006275193, 'lr': 0.008649806179332952}. Best is trial 206 with value: 0.547218605316966.\n",
    "\n",
    "[I 2024-12-06 12:49:28,047] Trial 579 finished with value: 0.5335308702482566 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.059979796814548306, 'n_epochs': 481, 'dropout': 0.2511747953677191, 'lr': 0.007942836869449217}. Best is trial 579 with value: 0.5335308702482566.\n",
    "\n",
    "\n",
    "[I 2024-12-06 14:53:00,850] Trial 385 finished with value: 0.5547767877242975 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.003263372268063613, 'n_epochs': 300, 'dropout': 0.3153661030384182, 'lr': 0.00593138298730814}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:32:38,969] Trial 583 finished with value: 0.550872165273167 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.010458110701511005, 'n_epochs': 336, 'dropout': 0.3188974735143638, 'lr': 0.006976522077116529}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:55:26,133] Trial 669 finished with value: 0.5645423555160363 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.0243907527056759, 'n_epochs': 370, 'dropout': 0.32998724447261185, 'lr': 0.0075018456671685696}. Best is trial 669 with value: 0.5645423555160363.\n",
    "\n",
    "[I 2024-12-06 20:33:46,555] Trial 1737 finished with value: 0.5716002919237433 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.015368961704784596, 'n_epochs': 328, 'dropout': 0.348927921024466, 'lr': 0.009575624984802092}. Best is trial 1737 with value: 0.5716002919237433.\n",
    "\n",
    "\n",
    "[I 2024-12-06 21:17:06,545] Trial 1889 finished with value: 0.5739803740995499 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.014029751567812504, 'n_epochs': 357, 'dropout': 0.34275064196127053, 'lr': 0.008692336113071646}. Best is trial 1889 with value: 0.5739803740995499.\n",
    "\n",
    "[I 2024-12-10 09:39:54,796] Trial 1612 finished with value: 0.5748324966932515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.003855147984840053, 'dropout': 0.3182765851196762, 'lr': 0.008210651343970551, 'n_epochs': 219}. Best is trial 1612 with value: 0.5748324966932515.\n",
    "\n",
    "\n",
    "\n",
    "Trial 1749 finished with value: 0.5772962775717783 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328981",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_utils.backtest_model(pipeline, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.05, confidence_threshold=best_params['confidence_threshold'], show_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outside of confidence threshold\n",
    "mask = (probas < 0.5 - confidence_threshold) | (probas > 0.5 + confidence_threshold)\n",
    "predictions = np.where(mask, probas, np.nan)\n",
    "\n",
    "# Use numpy mask for nan values\n",
    "valid_mask = ~np.isnan(predictions)\n",
    "valid_predictions = predictions[valid_mask]\n",
    "valid_mask = valid_mask.flatten()\n",
    "perf_y_col_mask = perf_y_col[valid_mask]\n",
    "\n",
    "\n",
    "true_values = perf_y_col_mask[:,0].astype(np.int32)\n",
    "pred_values = valid_predictions.flatten()\n",
    "pred_values_int = np.rint(valid_predictions).flatten().astype(np.int32)\n",
    "\n",
    "model_win_prob = (1.0*(true_values == pred_values_int).sum()) / (true_values.shape[0])\n",
    "print(model_win_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d6ca8",
   "metadata": {},
   "source": [
    "# Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8524f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.008, 0.01, 0.03],           # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3, 6, 9],                      # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [100, 200],                  # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.8, 1.0],                     # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.8, 1.0],              # Same as above\n",
    "    'min_child_weight': [1, 3],                  # Removed 5 as it might be too restrictive\n",
    "}\n",
    "aparam_grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],        # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3],                         # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [300, 350, 400],             # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.5, 0.6, 0.7],                # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],         # Same as above\n",
    "    'min_child_weight': [3, 4],                  # Removed 5 as it might be too restrictive\n",
    "}\n",
    "\n",
    "# model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create a custom scorer using the F1 score\n",
    "# f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "# Tune hyperparameters using GridSearchCV with the custom F1 scorer\n",
    "# grid_search = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=5, verbose=1)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "grid_search.fit(conts_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2ec9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# train final model w/ early stopping\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10,\n",
    "    # **grid_search.best_params_,\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 31.4%\n",
    "    # {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 30.9%\n",
    "    # {'colsample_bytree': 1.0, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.6}\n",
    ")\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    # **grid_search.best_params_,\n",
    "    # 67.3 w/ kelly adjustments 0.2, 0.01\n",
    "    # {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 350, 'subsample': 0.6}\n",
    "    # 67.2, dd 28.68 kelly 0.25, 0.014\n",
    "    # **{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 350, 'subsample': 0.5}\n",
    "    \n",
    "   # **{'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 0.5}\n",
    "    **{'colsample_bytree': 1.0, 'learning_rate': 0.03, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "\n",
    ")\n",
    "model.fit(\n",
    "    conts_train,\n",
    "    y_train,\n",
    "    eval_set=[(conts_train, y_train)], # , (holdout_conts, holdout_y)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef6e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_conts.shape\n",
    "perf_y_col.shape\n",
    "perf_y_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177675db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for test data\n",
    "# model = grid_search.best_estimator_\n",
    "y_pred = model.predict(perf_conts)\n",
    "\n",
    "nfl_utils.backtest_model(model, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.1, \n",
    "                   confidence_threshold=0.0, show_plot=True, max_won_odds=2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make confusion matrix\n",
    "cm = confusion_matrix(perf_y_col[:,0], y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7025ece",
   "metadata": {},
   "source": [
    "## Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a1a349",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
