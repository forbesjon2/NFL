{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70409bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from NFLUtils import NFLUtils\n",
    "import optuna\n",
    "%matplotlib inline\n",
    "nfl_utils = NFLUtils()\n",
    "\n",
    "# ANN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import logging\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# XGBoost \n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn as sns # confusion matrix\n",
    "\n",
    "# Set device to GPU if available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556dd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff2364",
   "metadata": {},
   "source": [
    "### Load CSV\n",
    "cp Combined.csv ~/drive/Notes/ML/Pytorch/footballData/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfebbf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5510 entries, 0 to 5509\n",
      "Columns: 209 entries, Unnamed: 0 to D_datediff\n",
      "dtypes: float64(133), int64(67), object(9)\n",
      "memory usage: 8.8+ MB\n",
      "df after perf set removed: (5310, 209)\n",
      "df perf set size (200, 209)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./footballData/CombinedSlidingWindow4.csv\", index_col=False, low_memory=False)\n",
    "\n",
    "# Shuffle dataFrame (don't do this?)\n",
    "# df = shuffle(df, random_state=101)\n",
    "# df.head()\n",
    "df.info()\n",
    "\n",
    "test_performance_size = 200\n",
    "test_performance_df = df[df.shape[0]-test_performance_size:]\n",
    "df = df[:df.shape[0]-test_performance_size]\n",
    "print(f'df after perf set removed: {df.shape}')\n",
    "print(f'df perf set size {test_performance_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26c9e0",
   "metadata": {},
   "source": [
    "### Remove items from performance set where you have no odds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593aec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance_df = test_performance_df.loc[test_performance_df['D_start_odds']!= 0]\n",
    "test_performance_size = test_performance_df.shape[0]\n",
    "# test_performance_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfc250",
   "metadata": {},
   "source": [
    "# Columns to use\n",
    "(TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1174d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>H_Q1</th>\n",
       "      <th>H_Q2</th>\n",
       "      <th>H_Q3</th>\n",
       "      <th>H_Q4</th>\n",
       "      <th>H_OT</th>\n",
       "      <th>H_Final</th>\n",
       "      <th>...</th>\n",
       "      <th>D_punting_lng</th>\n",
       "      <th>D_punting_pnt</th>\n",
       "      <th>D_punting_yds</th>\n",
       "      <th>D_scoring_fga</th>\n",
       "      <th>D_scoring_fgm</th>\n",
       "      <th>D_scoring_xpa</th>\n",
       "      <th>D_scoring_xpm</th>\n",
       "      <th>D_start_odds</th>\n",
       "      <th>D_halftime_odds</th>\n",
       "      <th>D_datediff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>-67.480</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>CIN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.936</td>\n",
       "      <td>0.392</td>\n",
       "      <td>19.296</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.520</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.256</td>\n",
       "      <td>-5.080</td>\n",
       "      <td>-237.168</td>\n",
       "      <td>2.176</td>\n",
       "      <td>1.376</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>229</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-08</td>\n",
       "      <td>ARI</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6.576</td>\n",
       "      <td>-0.752</td>\n",
       "      <td>-25.640</td>\n",
       "      <td>1.424</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-1.528</td>\n",
       "      <td>-1.528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-10-09</td>\n",
       "      <td>LAC</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>-81.712</td>\n",
       "      <td>-0.904</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Season        Date Home_Team  H_Q1  H_Q2  H_Q3  H_Q4  H_OT  \\\n",
       "0         228    1995  1995-10-08       WAS    10     7     7    10     0   \n",
       "1         232    1995  1995-10-08       CIN     3     3     3     7     0   \n",
       "2         234    1995  1995-10-08       PIT     0     7     6     3     0   \n",
       "3         229    1995  1995-10-08       ARI     3     7    11     0     0   \n",
       "4         223    1995  1995-10-09       LAC     3    10     0    10     0   \n",
       "\n",
       "   H_Final  ... D_punting_lng  D_punting_pnt  D_punting_yds  D_scoring_fga  \\\n",
       "0       34  ...        -0.952         -1.120        -67.480          0.784   \n",
       "1       16  ...         3.936          0.392         19.296          1.224   \n",
       "2       16  ...       -11.256         -5.080       -237.168          2.176   \n",
       "3       21  ...         6.576         -0.752        -25.640          1.424   \n",
       "4       23  ...         2.944         -1.304        -81.712         -0.904   \n",
       "\n",
       "   D_scoring_fgm  D_scoring_xpa  D_scoring_xpm  D_start_odds  D_halftime_odds  \\\n",
       "0          0.784         -0.488         -0.488           0.0              0.0   \n",
       "1          0.744          1.520          1.520           0.0              0.0   \n",
       "2          1.376         -0.080         -0.080           0.0              0.0   \n",
       "3          1.024         -1.528         -1.528           0.0              0.0   \n",
       "4         -0.480         -0.408         -0.408           0.0              0.0   \n",
       "\n",
       "   D_datediff  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 209 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db79ec",
   "metadata": {},
   "source": [
    "## 1. Separate continuous, categorical, and label column names\n",
    "\n",
    "Pretty much everything is continuous. \n",
    "\n",
    "Note: the y_col is what you're trying to predict\n",
    "\n",
    "## Feature engineering\n",
    "New Columns\n",
    "- **h_win**: Home team won\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3960b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5310, 209)\n",
      "(5310, 59)\n",
      "(124, 5)\n",
      "      H_Won  H_start_odds  V_start_odds  H_halftime_odds  V_halftime_odds\n",
      "5429    1.0      1.364000      3.239000         1.010000        34.000000\n",
      "5430    1.0      5.405556      1.164444         3.908333         1.255000\n",
      "5431    1.0      4.210000      1.242000         2.808333         1.416667\n",
      "5432    1.0      1.403333      3.047778         1.590000         2.320000\n",
      "5433    1.0      1.625000      2.359000         1.546667         2.425000\n",
      "      D_datediff  D_First_Downs  D_Rush  D_Yds  D_TDs  D_Cmp  D_Att  D_Yd  \\\n",
      "5429         0.0              2     -35     -8     13      2     37     2   \n",
      "5430        -4.0             -4       0     -7      8      2     49    -2   \n",
      "5431         1.0              2     -36     -6     54      2     62    -6   \n",
      "5432         0.0              2     -14     -2    -14     -2     31    -3   \n",
      "5433         0.0              4     -24      0    -18     15    -32     6   \n",
      "\n",
      "      D_TD  D_INT  ...  D_punt_returns_ret  D_punt_returns_td  \\\n",
      "5429    51      2  ...           -0.359501           0.000000   \n",
      "5430   -94      1  ...           -0.605848           0.016796   \n",
      "5431   -82     -1  ...           -1.312822           0.000000   \n",
      "5432   -10     -1  ...           -0.420003           0.000000   \n",
      "5433    87      0  ...           -1.300214           0.000000   \n",
      "\n",
      "      D_punt_returns_yds  D_punting_lng  D_punting_pnt  D_punting_yds  \\\n",
      "5429            5.678093     -10.536684      -1.019144     -59.666117   \n",
      "5430            2.967758      -4.139303       0.185345       0.487907   \n",
      "5431          -17.946932       0.719435       0.041708       2.925234   \n",
      "5432            1.447332     -11.252014      -0.000051     -32.390245   \n",
      "5433          -18.632518       5.022005      -1.052166     -44.815866   \n",
      "\n",
      "      D_scoring_fga  D_scoring_fgm  D_scoring_xpa  D_scoring_xpm  \n",
      "5429      -0.735183      -0.687721       2.457313       2.437407  \n",
      "5430      -0.649544      -0.516492      -1.726352      -1.726352  \n",
      "5431      -1.985245      -1.442208       0.083734       0.083734  \n",
      "5432      -0.185660      -0.968864       0.145627       0.145627  \n",
      "5433      -0.842341      -0.743231       1.350899       1.346097  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "cont_cols = [\n",
    "    # Home vs away days since last game\n",
    "    'H_datediff', 'V_datediff',\n",
    "    \n",
    "    # First Downs\n",
    "    'H_First_Downs', 'V_First_Downs',\n",
    "    \n",
    "    # Basic Stats\n",
    "    'H_Rush', 'V_Rush',\n",
    "    'H_Yds', 'V_Yds',\n",
    "    'H_TDs', 'V_TDs',\n",
    "    'H_Cmp', 'V_Cmp',\n",
    "    'H_Att', 'V_Att',\n",
    "    'H_Yd', 'V_Yd',\n",
    "    'H_TD', 'V_TD',\n",
    "    'H_INT', 'V_INT',\n",
    "    'H_Sacked', 'V_Sacked',\n",
    "    'H_Yards', 'V_Yards',\n",
    "    'H_Net_Pass_Yards', 'V_Net_Pass_Yards',\n",
    "    'H_Total_Yards', 'V_Total_Yards',\n",
    "    'H_Fumbles', 'V_Fumbles',\n",
    "    'H_Lost', 'V_Lost',\n",
    "    'H_Turnovers', 'V_Turnovers',\n",
    "    'H_Penalties', 'V_Penalties',\n",
    "    #'H_Third_Down_Conv', 'V_Third_Down_Conv',\n",
    "    #'H_Fourth_Down_Conv', 'V_Fourth_Down_Conv',\n",
    "    #'H_Time_of_Possession', 'V_Time_of_Possession',\n",
    "    \n",
    "    # Passing Detailed\n",
    "    'H_passing_att', 'V_passing_att',\n",
    "    'H_passing_cmp', 'V_passing_cmp',\n",
    "    'H_passing_int', 'V_passing_int',\n",
    "    'H_passing_lng', 'V_passing_lng',\n",
    "    'H_passing_sk', 'V_passing_sk',\n",
    "    'H_passing_td', 'V_passing_td',\n",
    "    'H_passing_yds', 'V_passing_yds',\n",
    "    \n",
    "    # Receiving\n",
    "    'H_receiving_lng', 'V_receiving_lng',\n",
    "    'H_receiving_td', 'V_receiving_td',\n",
    "    'H_receiving_yds', 'V_receiving_yds',\n",
    "    \n",
    "    # Rushing Detailed\n",
    "    'H_rushing_att', 'V_rushing_att',\n",
    "    'H_rushing_lng', 'V_rushing_lng',\n",
    "    'H_rushing_td', 'V_rushing_td',\n",
    "    'H_rushing_yds', 'V_rushing_yds',\n",
    "    \n",
    "    # Defense Interceptions\n",
    "    'H_def_interceptions_int', 'V_def_interceptions_int',\n",
    "    'H_def_interceptions_lng', 'V_def_interceptions_lng',\n",
    "    # 'H_def_interceptions_pd', 'V_def_interceptions_pd',\n",
    "    'H_def_interceptions_td', 'V_def_interceptions_td',\n",
    "    'H_def_interceptions_yds', 'V_def_interceptions_yds',\n",
    "    \n",
    "    # Defense Fumbles\n",
    "    'H_fumbles_ff', 'V_fumbles_ff',\n",
    "    'H_fumbles_fr', 'V_fumbles_fr',\n",
    "    'H_fumbles_td', 'V_fumbles_td',\n",
    "    'H_fumbles_yds', 'V_fumbles_yds',\n",
    "    \n",
    "    # Defense Tackles\n",
    "    'H_sk', 'V_sk',\n",
    "    'H_tackles_ast', 'V_tackles_ast',\n",
    "    'H_tackles_comb', 'V_tackles_comb',\n",
    "    # 'H_tackles_qbhits', 'V_tackles_qbhits',\n",
    "    'H_tackles_solo', 'V_tackles_solo',\n",
    "    # 'H_tackles_tfl', 'V_tackles_tfl',\n",
    "    \n",
    "    # Kick Returns\n",
    "    'H_kick_returns_lng', 'V_kick_returns_lng',\n",
    "    'H_kick_returns_rt', 'V_kick_returns_rt',\n",
    "    'H_kick_returns_td', 'V_kick_returns_td',\n",
    "    'H_kick_returns_yds', 'V_kick_returns_yds',\n",
    "    \n",
    "    # Punt Returns\n",
    "    'H_punt_returns_lng', 'V_punt_returns_lng',\n",
    "    'H_punt_returns_ret', 'V_punt_returns_ret',\n",
    "    'H_punt_returns_td', 'V_punt_returns_td',\n",
    "    'H_punt_returns_yds', 'V_punt_returns_yds',\n",
    "    \n",
    "    # Punting/Scoring\n",
    "    'H_punting_lng', 'V_punting_lng',\n",
    "    'H_punting_pnt', 'V_punting_pnt',\n",
    "    'H_punting_yds', 'V_punting_yds',\n",
    "    'H_scoring_fga', 'V_scoring_fga',\n",
    "    'H_scoring_fgm', 'V_scoring_fgm',\n",
    "    'H_scoring_xpa', 'V_scoring_xpa',\n",
    "    'H_scoring_xpm', 'V_scoring_xpm',\n",
    "    \n",
    "    # Odds\n",
    "    # 'H_start_odds', 'V_start_odds',\n",
    "    # 'H_halftime_odds', 'V_halftime_odds'\n",
    "]\n",
    "\n",
    "cont_cols = [\n",
    "    'D_datediff', # Days since last game (Home - visitor)\n",
    "    \n",
    "    # first downs\n",
    "    'D_First_Downs',\n",
    "    \n",
    "    # Basic Stats\n",
    "    'D_Rush',\n",
    "    'D_Yds',\n",
    "    'D_TDs',\n",
    "    'D_Cmp',\n",
    "    'D_Att',\n",
    "    'D_Yd',\n",
    "    'D_TD',\n",
    "    'D_INT',\n",
    "    'D_Sacked',\n",
    "    'D_Yards',\n",
    "    'D_Net_Pass_Yards',\n",
    "    'D_Total_Yards',\n",
    "    'D_Fumbles',\n",
    "    'D_Lost',\n",
    "    'D_Turnovers',\n",
    "    'D_Penalties',\n",
    "    \n",
    "    # Passing Detailed\n",
    "    'D_passing_att',\n",
    "    'D_passing_cmp',\n",
    "    'D_passing_int',\n",
    "    'D_passing_lng',\n",
    "    'D_passing_sk',\n",
    "    'D_passing_td',\n",
    "    'D_passing_yds',\n",
    "    \n",
    "    # Receiving\n",
    "    'D_receiving_lng',\n",
    "    'D_receiving_td',\n",
    "    'D_receiving_yds',\n",
    "    \n",
    "    # Rushing Detailed\n",
    "    'D_rushing_att',\n",
    "    'D_rushing_lng',\n",
    "    'D_rushing_td',\n",
    "    'D_rushing_yds',\n",
    "    \n",
    "    # Defense interceptions\n",
    "    'D_def_interceptions_int',\n",
    "    'D_def_interceptions_lng',\n",
    "    # 'D_def_interceptions_pd',\n",
    "    'D_def_interceptions_td',\n",
    "    'D_def_interceptions_yds',\n",
    "    \n",
    "    # Defense fumbles\n",
    "    'D_fumbles_ff',\n",
    "    'D_fumbles_fr',\n",
    "    'D_fumbles_td',\n",
    "    'D_fumbles_yds',\n",
    "    \n",
    "    # Defense tackles\n",
    "    'D_sk',\n",
    "    'D_tackles_ast',\n",
    "    'D_tackles_comb',\n",
    "    # 'D_tackles_qbhits',\n",
    "    'D_tackles_solo',\n",
    "    # 'D_tackles_tfl',\n",
    "    \n",
    "    # Kick Returns\n",
    "    'D_kick_returns_lng',\n",
    "    'D_kick_returns_rt',\n",
    "    'D_kick_returns_td',\n",
    "    'D_kick_returns_yds',\n",
    "    \n",
    "    # Punt Returns\n",
    "    'D_punt_returns_lng',\n",
    "    'D_punt_returns_ret',\n",
    "    'D_punt_returns_td',\n",
    "    'D_punt_returns_yds',\n",
    "    \n",
    "    # Punting / Scoring\n",
    "    'D_punting_lng',\n",
    "    'D_punting_pnt',\n",
    "    'D_punting_yds',\n",
    "    'D_scoring_fga',\n",
    "    'D_scoring_fgm',\n",
    "    'D_scoring_xpa',\n",
    "    'D_scoring_xpm'\n",
    "]\n",
    "\n",
    "\n",
    "y_col = ['H_Won']\n",
    "y_col_perf = ['H_Won', 'H_start_odds', 'V_start_odds', 'H_halftime_odds', 'V_halftime_odds']\n",
    "\n",
    "\n",
    "# create cont_df and y_df from the df\n",
    "print(df.shape)\n",
    "cont_df = df[cont_cols]\n",
    "y_df = df[y_col]\n",
    "\n",
    "# test performance set\n",
    "perf_conts_df = test_performance_df[cont_cols]\n",
    "perf_y_df = test_performance_df[y_col_perf]\n",
    "perf_date_df = test_performance_df[['Date']]\n",
    "\n",
    "# print(cont_df.dtypes)\n",
    "print(cont_df.shape)\n",
    "print(perf_y_df.shape)\n",
    "print(perf_y_df.tail())\n",
    "print(perf_conts_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0a853",
   "metadata": {},
   "source": [
    "## Monotone constraints dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147aeb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1)\n",
      "(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "monotone_constraints = {\n",
    "    # Time between games - More rest is better\n",
    "    'D_datediff': 1,\n",
    "    \n",
    "    # Offensive positive indicators\n",
    "    'D_First_Downs': 1,\n",
    "    'D_Rush': 1,\n",
    "    'D_Yds': 1,\n",
    "    'D_TDs': 1,\n",
    "    'D_Cmp': 1,\n",
    "    'D_Yd': 1,\n",
    "    'D_TD': 1,\n",
    "    'D_Net_Pass_Yards': 1,\n",
    "    'D_Total_Yards': 1,\n",
    "    \n",
    "    # Negative indicators\n",
    "    'D_INT': -1,\n",
    "    'D_Sacked': -1,\n",
    "    'D_Fumbles': -1,\n",
    "    'D_Lost': -1,\n",
    "    'D_Turnovers': -1,\n",
    "    'D_Penalties': -1,\n",
    "    \n",
    "    # Passing detail - positive\n",
    "    'D_passing_cmp': 1,\n",
    "    'D_passing_td': 1,\n",
    "    'D_passing_yds': 1,\n",
    "    'D_passing_lng': 1,\n",
    "    \n",
    "    # Passing detail - negative\n",
    "    'D_passing_int': -1,\n",
    "    'D_passing_sk': -1,\n",
    "    \n",
    "    # Receiving/Rushing - all positive\n",
    "    'D_receiving_td': 1,\n",
    "    'D_receiving_yds': 1,\n",
    "    'D_receiving_lng': 1,\n",
    "    'D_rushing_td': 1,\n",
    "    'D_rushing_yds': 1,\n",
    "    'D_rushing_lng': 1,\n",
    "    \n",
    "    # Defense - generally positive when in your favor\n",
    "    'D_def_interceptions_int': 1,\n",
    "    'D_def_interceptions_td': 1,\n",
    "    'D_def_interceptions_yds': 1,\n",
    "    'D_fumbles_fr': 1,\n",
    "    'D_fumbles_td': 1,\n",
    "    'D_sk': 1,\n",
    "    # 'D_tackles_qbhits': 1,\n",
    "    # 'D_tackles_tfl': 1,\n",
    "    \n",
    "    # Special teams - positive indicators\n",
    "    'D_kick_returns_td': 1,\n",
    "    'D_kick_returns_yds': 1,\n",
    "    'D_punt_returns_td': 1,\n",
    "    'D_punt_returns_yds': 1,\n",
    "    \n",
    "    # Scoring - positive\n",
    "    'D_scoring_fgm': 1,\n",
    "    'D_scoring_xpm': 1\n",
    "}\n",
    "\n",
    "monotone_constraints_tuple = ()\n",
    "no_monotone_constraints_tuple = ()\n",
    "for col in cont_cols:\n",
    "    monotone_constraints_tuple = monotone_constraints_tuple + (monotone_constraints[col],) if col in monotone_constraints else monotone_constraints_tuple + (0,)\n",
    "    no_monotone_constraints_tuple = no_monotone_constraints_tuple + (0,)\n",
    "print(monotone_constraints_tuple)\n",
    "print(no_monotone_constraints_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05613417",
   "metadata": {},
   "source": [
    "#### 1a. Normalize cont_df\n",
    "StandardScaler is instead used by the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e76a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# cont_scaled = min_max_scaler.fit_transform(cont_df.values)\n",
    "# cont_df = pd.DataFrame(cont_scaled)\n",
    "# cont_df.head()\n",
    "\n",
    "# # test performance set\n",
    "# perf_conts_df_scaled = min_max_scaler.fit_transform(perf_conts_df.values)\n",
    "# perf_conts_df = pd.DataFrame(perf_conts_df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1912ae",
   "metadata": {},
   "source": [
    "### 3. Create an array of continuous values\n",
    "Numpy array 'conts' containing stack of each continuous column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([cont_df[col].values for col in list(cont_df.columns)], 1)\n",
    "conts[:5]\n",
    "\n",
    "y_col = np.stack([y_df[col].values for col in y_col], 1)\n",
    "\n",
    "# test performance set\n",
    "perf_conts = np.stack([perf_conts_df[col].values for col in list(perf_conts_df.columns)], 1)\n",
    "perf_y_col = np.stack([perf_y_df[col].values for col in list(perf_y_df.columns)], 1)\n",
    "perf_date_col = np.stack([perf_date_df[col].values for col in list(perf_date_df.columns)], 1)\n",
    "\n",
    "\n",
    "conts_train = conts\n",
    "y_train = y_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2547a",
   "metadata": {},
   "source": [
    "### 4. Convert conts to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7db899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5310, 59)\n",
      "(5310, 1)\n"
     ]
    }
   ],
   "source": [
    "print(conts.shape)\n",
    "print(y_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handled by model.fit()\n",
    "# conts = torch.tensor(conts, dtype=torch.float32)\n",
    "# y_col = torch.tensor(y_col, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331d34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, criterion=nn.BCELoss(),\n",
    "                optimizer_class=torch.optim.Adam, lr=0.001, n_epochs=10, confidence_threshold=0.1):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Training params\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.n_epochs = n_epochs\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # BatchNorm layer for continuous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([\n",
    "            nn.Linear(self.layer_shape[-1], out_sz),\n",
    "            # nn.Sigmoid()  # Ensures output between 0 and 1\n",
    "        ])\n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Training loop\n",
    "        self.train()\n",
    "        for _ in range(self.n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        # return (probas > 0.5).astype(int)\n",
    "        return probas\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X, torch.Tensor):\n",
    "                X = torch.FloatTensor(X)\n",
    "            return self(X).numpy()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"        \n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        # First apply confidence thresholding\n",
    "        mask = (probas < 0.5 - self.confidence_threshold) | (probas > 0.5 + self.confidence_threshold)\n",
    "        predictions = np.where(mask, (probas > 0.5).astype(np.int32), np.nan)\n",
    "\n",
    "        # Use numpy mask for nan values\n",
    "        valid_mask = ~np.isnan(predictions)\n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = y[valid_mask]\n",
    "        \n",
    "        # Apply f1 score\n",
    "        score = f1_score(valid_predictions.flatten(), valid_targets)\n",
    "        return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875b494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TabularModelUpdated(nn.Module, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_cont, out_sz, layer_shape, p=0.5, criterion=nn.MSELoss(),\n",
    "                optimizer_class=torch.optim.Adam, lr=0.001, confidence_threshold=0.1):\n",
    "        super().__init__()\n",
    "        # Model architecture params\n",
    "        self.layer_shape = layer_shape\n",
    "        self.n_cont = n_cont\n",
    "        self.out_sz = out_sz\n",
    "        self.p = p\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Training params\n",
    "        self.criterion = criterion\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # BatchNorm layer for continuous data\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Variable that holds the list of layers\n",
    "        layerlist = []\n",
    "        n_in = n_cont # no embed again\n",
    "        # Iterate through the passed in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i, width in enumerate(self.layer_shape):\n",
    "            # First layer gets special treatment\n",
    "            if i == 0:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p/2)  # Less dropout in earlier layers\n",
    "                ])\n",
    "            else:\n",
    "                layerlist.extend([\n",
    "                    nn.Linear(n_in, width),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(width),\n",
    "                    nn.Dropout(p)\n",
    "                ])\n",
    "            n_in = width\n",
    "        # layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "        \n",
    "        # Final layer\n",
    "        layerlist.extend([\n",
    "            nn.Linear(self.layer_shape[-1], out_sz),\n",
    "            # nn.Sigmoid()  # Ensures output between 0 and 1\n",
    "        ])\n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        # Initialize the optimizer\n",
    "        self.optimizer = optimizer_class(self.parameters(), lr=self.lr)\n",
    "\n",
    "        \n",
    "    def forward(self, x_cont):\n",
    "        x_cont = self.bn_cont(x_cont)  # Normalize the incoming continuous data\n",
    "        x = self.layers(x_cont)        # Set up model layers\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For sklearn pipeline\n",
    "        \"\"\"\n",
    "        # Convert X,y to torch.tensor if needed\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.FloatTensor(y)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        # optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
    "        # Training loop\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        y_pred = self.forward(X)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas > 0.5).astype(int)\n",
    "        # return probas\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(X, torch.Tensor):\n",
    "                X = torch.FloatTensor(X)\n",
    "            return self(X).numpy()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"        \n",
    "        12/5 - this isn't called at all if 'scoring' is defined\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        # First apply confidence thresholding\n",
    "        mask = (probas < 0.5 - self.confidence_threshold) | (probas > 0.5 + self.confidence_threshold)\n",
    "        predictions = np.where(mask, (probas > 0.5).astype(np.int32), np.nan)\n",
    "\n",
    "        # Use numpy mask for nan values\n",
    "        valid_mask = ~np.isnan(predictions)\n",
    "        valid_predictions = predictions[valid_mask]\n",
    "        valid_targets = y[valid_mask]\n",
    "        \n",
    "        # Penalize if < 80% predicted\n",
    "        if (1.0* len(valid_predictions) / len(X)) < 0.85:\n",
    "            # print(f\"mask {len(valid_predictions)}  pred {len(X)}\")\n",
    "            return 0.0\n",
    "\n",
    "        # Apply f1 score\n",
    "        score = f1_score(valid_predictions.flatten(), valid_targets)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b31ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- Suggest hyperparameters ---\n",
    "\n",
    "    criterion = trial.suggest_categorical('criterion', nfl_utils.map_losses(None).keys())\n",
    "    first_layer_size = trial.suggest_categorical('first_layer_size', [64, 56, 48, 32, 16, 12])\n",
    "    min_layers = math.floor(math.sqrt(first_layer_size))\n",
    "    num_layers = trial.suggest_int('num_layers', 2, min_layers)\n",
    "    confidence_threshold = trial.suggest_float('confidence_threshold', 0, 0.05)\n",
    "    layer_shape = [first_layer_size]\n",
    "    for i in range(1, num_layers):\n",
    "        layer_shape.append(first_layer_size//(2*i))\n",
    "    \n",
    "    # Set random state to have consistent results (42 is arbitrary)\n",
    "    set_all_seeds()\n",
    "    \n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    # Split once\n",
    "    X_train_fold = []\n",
    "    X_val = []\n",
    "    y_train_fold = []\n",
    "    y_val = []\n",
    "    models = []\n",
    "    for train_index, val_index in kf.split(conts_train):\n",
    "        # print(f\"train {train_index.shape} val {val_index.shape}\")\n",
    "        X_train_fold.append(torch.FloatTensor(conts_train[train_index]).to(device))\n",
    "        X_val.append(torch.FloatTensor(conts_train[val_index]).to(device))\n",
    "\n",
    "        y_train_fold.append(torch.FloatTensor(y_train[train_index]).to(device))\n",
    "        y_val.append(torch.FloatTensor(y_train[val_index]).to(device))\n",
    "\n",
    "        model = TabularModelUpdated(\n",
    "            n_cont=conts.shape[1],\n",
    "            out_sz=1,\n",
    "            layer_shape=layer_shape,\n",
    "            p=trial.suggest_float('dropout', 0.28, 0.38),     # Dropout\n",
    "            criterion=nfl_utils.map_losses(criterion),\n",
    "            optimizer_class=torch.optim.Adam,\n",
    "            lr=trial.suggest_float('lr', 1e-3, 1e-2, log=True),   # Learning rate \n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "            # ('regressor', LinearRegression()), # Apply a regression model\n",
    "            ('model', model)\n",
    "        ])\n",
    "        models.append(pipeline)\n",
    "\n",
    "    # Run once on each split, track average loss, stop if > max patience\n",
    "    max_patience = 10\n",
    "    current_patience = max_patience\n",
    "    tracked_loss = 0.0\n",
    "    n_epochs = 0\n",
    "    while current_patience > 0 or n_epochs < 100:\n",
    "        n_epochs = n_epochs + 1\n",
    "        running_loss = []\n",
    "        for i in range(0,n_splits):\n",
    "            # ----- Train -----\n",
    "            models[i].fit(X_train_fold[i], y_train_fold[i])\n",
    "\n",
    "            # ----- Eval -----\n",
    "            running_loss.append(models[i].score(X_val[i], y_val[i]))\n",
    "            # y_pred = models[i].predict(X_val[i])\n",
    "            # running_loss.append(f1_score(y_val[i], y_pred))\n",
    "        running_loss = np.mean(running_loss)\n",
    "\n",
    "        # ----- Current epoch loss > previous -----\n",
    "        # print(f\"{tracked_loss} {running_loss} {tracked_loss < running_loss}\")\n",
    "        if tracked_loss < running_loss:\n",
    "            current_patience = max_patience\n",
    "            tracked_loss = running_loss\n",
    "        else:\n",
    "            current_patience = current_patience - 1\n",
    "    trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "    trial.report(tracked_loss, n_epochs)\n",
    "    return tracked_loss\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value}\")\n",
    "    print(f\"Best trial so far: {study.best_trial.number}, value: {study.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd663af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',   # max because using f1\n",
    "    pruner=optuna.pruners.HyperbandPruner(\n",
    "        min_resource=1,\n",
    "        max_resource=1000\n",
    "    )\n",
    ")\n",
    "# Uncomment to run\n",
    "if True:\n",
    "    study.optimize(objective, n_trials=2000, callbacks=[print_callback])\n",
    "    # study.optimize(objective, n_trials=3)\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"Value: \", trial.value)\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ea5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = study.best_trial.params\n",
    "best_params = {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}\n",
    "layer_shape = [best_params['first_layer_size']]\n",
    "for i in range(1, best_params['num_layers']):\n",
    "    layer_shape.append(best_params['first_layer_size']//(2*i))\n",
    "\n",
    "# Set random state to have consistent results (42 is arbitrary)\n",
    "set_all_seeds()\n",
    "model = TabularModelUpdated(\n",
    "    n_cont=conts.shape[1],\n",
    "    out_sz=1,\n",
    "    layer_shape=layer_shape,\n",
    "    p=best_params['dropout'],     # Dropout\n",
    "    criterion=nfl_utils.map_losses(best_params['criterion']),\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    lr= best_params['lr'],   # Learning rate \n",
    "    confidence_threshold=best_params['confidence_threshold']\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Standardize the numerical features\n",
    "    # ('regressor', LinearRegression()), # Apply a regression model\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Run once on each split, track average loss, stop if > max patience\n",
    "for _ in range(0, (best_params['n_epochs'] - 10)):\n",
    "    running_loss = 0.0\n",
    "    # ----- Train -----\n",
    "    pipeline.fit(conts_train, y_train)\n",
    "\n",
    "    # ----- Eval -----\n",
    "    # loss = pipeline.score(perf_conts, perf_y_col)\n",
    "    #print(f\"loss: {loss}\")\n",
    "\n",
    "# pipeline.fit(conts_train, y_train)\n",
    "probas = pipeline.predict(perf_conts)\n",
    "confidence_threshold = best_params['confidence_threshold']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109e37c",
   "metadata": {},
   "source": [
    "Value:  0.37491718013436764\n",
    "\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 39\n",
    "    dropout: 0.47875406200808335\n",
    "    lr: 0.009997751942238913\n",
    "    \n",
    "\n",
    "\n",
    "Value:  0.3759073484440955\n",
    "Params: \n",
    "    first_layer_size: 8\n",
    "    num_layers: 2\n",
    "    n_epochs: 68\n",
    "    dropout: 0.4497689844977892\n",
    "    lr: 0.007977206154472633\n",
    "    \n",
    "    \n",
    "    \n",
    "12/6\n",
    "\n",
    "Trial 206 finished with value: 0.547218605316966 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 32, 'num_layers': 5, 'confidence_threshold': 0.05966702820817666, 'n_epochs': 379, 'dropout': 0.36961850006275193, 'lr': 0.008649806179332952}. Best is trial 206 with value: 0.547218605316966.\n",
    "\n",
    "[I 2024-12-06 12:49:28,047] Trial 579 finished with value: 0.5335308702482566 and parameters: {'criterion': 'SmoothL1Loss', 'first_layer_size': 16, 'num_layers': 3, 'confidence_threshold': 0.059979796814548306, 'n_epochs': 481, 'dropout': 0.2511747953677191, 'lr': 0.007942836869449217}. Best is trial 579 with value: 0.5335308702482566.\n",
    "\n",
    "\n",
    "[I 2024-12-06 14:53:00,850] Trial 385 finished with value: 0.5547767877242975 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 6, 'confidence_threshold': 0.003263372268063613, 'n_epochs': 300, 'dropout': 0.3153661030384182, 'lr': 0.00593138298730814}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:32:38,969] Trial 583 finished with value: 0.550872165273167 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.010458110701511005, 'n_epochs': 336, 'dropout': 0.3188974735143638, 'lr': 0.006976522077116529}. Best is trial 385 with value: 0.5547767877242975.\n",
    "\n",
    "[I 2024-12-06 15:55:26,133] Trial 669 finished with value: 0.5645423555160363 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.0243907527056759, 'n_epochs': 370, 'dropout': 0.32998724447261185, 'lr': 0.0075018456671685696}. Best is trial 669 with value: 0.5645423555160363.\n",
    "\n",
    "[I 2024-12-06 20:33:46,555] Trial 1737 finished with value: 0.5716002919237433 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.015368961704784596, 'n_epochs': 328, 'dropout': 0.348927921024466, 'lr': 0.009575624984802092}. Best is trial 1737 with value: 0.5716002919237433.\n",
    "\n",
    "\n",
    "[I 2024-12-06 21:17:06,545] Trial 1889 finished with value: 0.5739803740995499 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 56, 'num_layers': 7, 'confidence_threshold': 0.014029751567812504, 'n_epochs': 357, 'dropout': 0.34275064196127053, 'lr': 0.008692336113071646}. Best is trial 1889 with value: 0.5739803740995499.\n",
    "\n",
    "[I 2024-12-10 09:39:54,796] Trial 1612 finished with value: 0.5748324966932515 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 0.003855147984840053, 'dropout': 0.3182765851196762, 'lr': 0.008210651343970551, 'n_epochs': 219}. Best is trial 1612 with value: 0.5748324966932515.\n",
    "\n",
    "\n",
    "\n",
    "Trial 1749 finished with value: 0.5772962775717783 and parameters: {'criterion': 'MSELoss', 'first_layer_size': 64, 'num_layers': 7, 'confidence_threshold': 1.8653941637231173e-05, 'dropout': 0.3181431308672629, 'lr': 0.009969598746996452, 'n_epochs': 231}.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328981",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nfl_utils.backtest_model(pipeline, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.05, confidence_threshold=best_params['confidence_threshold'], show_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outside of confidence threshold\n",
    "mask = (probas < 0.5 - confidence_threshold) | (probas > 0.5 + confidence_threshold)\n",
    "predictions = np.where(mask, probas, np.nan)\n",
    "\n",
    "# Use numpy mask for nan values\n",
    "valid_mask = ~np.isnan(predictions)\n",
    "valid_predictions = predictions[valid_mask]\n",
    "valid_mask = valid_mask.flatten()\n",
    "perf_y_col_mask = perf_y_col[valid_mask]\n",
    "\n",
    "\n",
    "true_values = perf_y_col_mask[:,0].astype(np.int32)\n",
    "pred_values = valid_predictions.flatten()\n",
    "pred_values_int = np.rint(valid_predictions).flatten().astype(np.int32)\n",
    "\n",
    "model_win_prob = (1.0*(true_values == pred_values_int).sum()) / (true_values.shape[0])\n",
    "print(model_win_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d6ca8",
   "metadata": {},
   "source": [
    "# Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c222c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8524f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "param_grid = {\n",
    "    'learning_rate': [ 0.008, 0.01, 0.03],           # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3, 6, 9],                      # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [100, 200],                  # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.8, 1.0],                     # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.8, 1.0],              # Same as above\n",
    "    'min_child_weight': [1, 3],                  # Removed 5 as it might be too restrictive\n",
    "    # 'monotone_constraints': [monotone_constraints_tuple, no_monotone_constraints_tuple]\n",
    "    'monotone_constraints': [no_monotone_constraints_tuple]\n",
    "}\n",
    "param_grid = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],        # Removed 0.5, 1 as they're often too aggressive\n",
    "    'max_depth': [3],                         # Simplified to 3 values, covering shallow to deep\n",
    "    'n_estimators': [300, 350, 400],             # Removed extremes, these are most common sweet spots\n",
    "    'subsample': [0.5, 0.6, 0.7],                # Removed 0.6 as it might be too aggressive for this dataset size\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],         # Same as above\n",
    "    'min_child_weight': [3, 4],                  # Removed 5 as it might be too restrictive\n",
    "    'monotone_constraints': [monotone_constraints_tuple, no_monotone_constraints_tuple]\n",
    "}\n",
    "\n",
    "# model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create a custom scorer using the F1 score\n",
    "# f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "# Tune hyperparameters using GridSearchCV with the custom F1 scorer\n",
    "# grid_search = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=5, verbose=1)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "grid_search.fit(conts_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "# No monotone constraints\n",
    "# 60.15%, {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "# 65% {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "\n",
    "# Monotone constraints\n",
    "# {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 200, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee2ec9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.49959\n",
      "[1]\tvalidation_0-rmse:0.49919\n",
      "[2]\tvalidation_0-rmse:0.49881\n",
      "[3]\tvalidation_0-rmse:0.49842\n",
      "[4]\tvalidation_0-rmse:0.49800\n",
      "[5]\tvalidation_0-rmse:0.49761\n",
      "[6]\tvalidation_0-rmse:0.49724\n",
      "[7]\tvalidation_0-rmse:0.49688\n",
      "[8]\tvalidation_0-rmse:0.49650\n",
      "[9]\tvalidation_0-rmse:0.49614\n",
      "[10]\tvalidation_0-rmse:0.49576\n",
      "[11]\tvalidation_0-rmse:0.49538\n",
      "[12]\tvalidation_0-rmse:0.49501\n",
      "[13]\tvalidation_0-rmse:0.49465\n",
      "[14]\tvalidation_0-rmse:0.49432\n",
      "[15]\tvalidation_0-rmse:0.49398\n",
      "[16]\tvalidation_0-rmse:0.49365\n",
      "[17]\tvalidation_0-rmse:0.49330\n",
      "[18]\tvalidation_0-rmse:0.49301\n",
      "[19]\tvalidation_0-rmse:0.49270\n",
      "[20]\tvalidation_0-rmse:0.49238\n",
      "[21]\tvalidation_0-rmse:0.49206\n",
      "[22]\tvalidation_0-rmse:0.49174\n",
      "[23]\tvalidation_0-rmse:0.49144\n",
      "[24]\tvalidation_0-rmse:0.49114\n",
      "[25]\tvalidation_0-rmse:0.49086\n",
      "[26]\tvalidation_0-rmse:0.49059\n",
      "[27]\tvalidation_0-rmse:0.49031\n",
      "[28]\tvalidation_0-rmse:0.49004\n",
      "[29]\tvalidation_0-rmse:0.48977\n",
      "[30]\tvalidation_0-rmse:0.48951\n",
      "[31]\tvalidation_0-rmse:0.48922\n",
      "[32]\tvalidation_0-rmse:0.48894\n",
      "[33]\tvalidation_0-rmse:0.48868\n",
      "[34]\tvalidation_0-rmse:0.48841\n",
      "[35]\tvalidation_0-rmse:0.48816\n",
      "[36]\tvalidation_0-rmse:0.48792\n",
      "[37]\tvalidation_0-rmse:0.48766\n",
      "[38]\tvalidation_0-rmse:0.48741\n",
      "[39]\tvalidation_0-rmse:0.48715\n",
      "[40]\tvalidation_0-rmse:0.48690\n",
      "[41]\tvalidation_0-rmse:0.48665\n",
      "[42]\tvalidation_0-rmse:0.48642\n",
      "[43]\tvalidation_0-rmse:0.48621\n",
      "[44]\tvalidation_0-rmse:0.48599\n",
      "[45]\tvalidation_0-rmse:0.48575\n",
      "[46]\tvalidation_0-rmse:0.48555\n",
      "[47]\tvalidation_0-rmse:0.48533\n",
      "[48]\tvalidation_0-rmse:0.48513\n",
      "[49]\tvalidation_0-rmse:0.48491\n",
      "[50]\tvalidation_0-rmse:0.48471\n",
      "[51]\tvalidation_0-rmse:0.48448\n",
      "[52]\tvalidation_0-rmse:0.48430\n",
      "[53]\tvalidation_0-rmse:0.48411\n",
      "[54]\tvalidation_0-rmse:0.48391\n",
      "[55]\tvalidation_0-rmse:0.48374\n",
      "[56]\tvalidation_0-rmse:0.48354\n",
      "[57]\tvalidation_0-rmse:0.48333\n",
      "[58]\tvalidation_0-rmse:0.48314\n",
      "[59]\tvalidation_0-rmse:0.48299\n",
      "[60]\tvalidation_0-rmse:0.48280\n",
      "[61]\tvalidation_0-rmse:0.48260\n",
      "[62]\tvalidation_0-rmse:0.48241\n",
      "[63]\tvalidation_0-rmse:0.48222\n",
      "[64]\tvalidation_0-rmse:0.48204\n",
      "[65]\tvalidation_0-rmse:0.48187\n",
      "[66]\tvalidation_0-rmse:0.48169\n",
      "[67]\tvalidation_0-rmse:0.48152\n",
      "[68]\tvalidation_0-rmse:0.48134\n",
      "[69]\tvalidation_0-rmse:0.48118\n",
      "[70]\tvalidation_0-rmse:0.48101\n",
      "[71]\tvalidation_0-rmse:0.48082\n",
      "[72]\tvalidation_0-rmse:0.48065\n",
      "[73]\tvalidation_0-rmse:0.48049\n",
      "[74]\tvalidation_0-rmse:0.48034\n",
      "[75]\tvalidation_0-rmse:0.48019\n",
      "[76]\tvalidation_0-rmse:0.48002\n",
      "[77]\tvalidation_0-rmse:0.47987\n",
      "[78]\tvalidation_0-rmse:0.47975\n",
      "[79]\tvalidation_0-rmse:0.47962\n",
      "[80]\tvalidation_0-rmse:0.47947\n",
      "[81]\tvalidation_0-rmse:0.47932\n",
      "[82]\tvalidation_0-rmse:0.47914\n",
      "[83]\tvalidation_0-rmse:0.47900\n",
      "[84]\tvalidation_0-rmse:0.47885\n",
      "[85]\tvalidation_0-rmse:0.47871\n",
      "[86]\tvalidation_0-rmse:0.47856\n",
      "[87]\tvalidation_0-rmse:0.47842\n",
      "[88]\tvalidation_0-rmse:0.47824\n",
      "[89]\tvalidation_0-rmse:0.47810\n",
      "[90]\tvalidation_0-rmse:0.47795\n",
      "[91]\tvalidation_0-rmse:0.47781\n",
      "[92]\tvalidation_0-rmse:0.47767\n",
      "[93]\tvalidation_0-rmse:0.47755\n",
      "[94]\tvalidation_0-rmse:0.47742\n",
      "[95]\tvalidation_0-rmse:0.47729\n",
      "[96]\tvalidation_0-rmse:0.47715\n",
      "[97]\tvalidation_0-rmse:0.47701\n",
      "[98]\tvalidation_0-rmse:0.47686\n",
      "[99]\tvalidation_0-rmse:0.47674\n",
      "[100]\tvalidation_0-rmse:0.47663\n",
      "[101]\tvalidation_0-rmse:0.47651\n",
      "[102]\tvalidation_0-rmse:0.47638\n",
      "[103]\tvalidation_0-rmse:0.47627\n",
      "[104]\tvalidation_0-rmse:0.47616\n",
      "[105]\tvalidation_0-rmse:0.47604\n",
      "[106]\tvalidation_0-rmse:0.47591\n",
      "[107]\tvalidation_0-rmse:0.47579\n",
      "[108]\tvalidation_0-rmse:0.47568\n",
      "[109]\tvalidation_0-rmse:0.47559\n",
      "[110]\tvalidation_0-rmse:0.47548\n",
      "[111]\tvalidation_0-rmse:0.47536\n",
      "[112]\tvalidation_0-rmse:0.47524\n",
      "[113]\tvalidation_0-rmse:0.47512\n",
      "[114]\tvalidation_0-rmse:0.47501\n",
      "[115]\tvalidation_0-rmse:0.47488\n",
      "[116]\tvalidation_0-rmse:0.47476\n",
      "[117]\tvalidation_0-rmse:0.47466\n",
      "[118]\tvalidation_0-rmse:0.47454\n",
      "[119]\tvalidation_0-rmse:0.47441\n",
      "[120]\tvalidation_0-rmse:0.47431\n",
      "[121]\tvalidation_0-rmse:0.47417\n",
      "[122]\tvalidation_0-rmse:0.47407\n",
      "[123]\tvalidation_0-rmse:0.47395\n",
      "[124]\tvalidation_0-rmse:0.47384\n",
      "[125]\tvalidation_0-rmse:0.47374\n",
      "[126]\tvalidation_0-rmse:0.47361\n",
      "[127]\tvalidation_0-rmse:0.47351\n",
      "[128]\tvalidation_0-rmse:0.47340\n",
      "[129]\tvalidation_0-rmse:0.47330\n",
      "[130]\tvalidation_0-rmse:0.47320\n",
      "[131]\tvalidation_0-rmse:0.47310\n",
      "[132]\tvalidation_0-rmse:0.47300\n",
      "[133]\tvalidation_0-rmse:0.47288\n",
      "[134]\tvalidation_0-rmse:0.47279\n",
      "[135]\tvalidation_0-rmse:0.47272\n",
      "[136]\tvalidation_0-rmse:0.47262\n",
      "[137]\tvalidation_0-rmse:0.47254\n",
      "[138]\tvalidation_0-rmse:0.47245\n",
      "[139]\tvalidation_0-rmse:0.47235\n",
      "[140]\tvalidation_0-rmse:0.47228\n",
      "[141]\tvalidation_0-rmse:0.47219\n",
      "[142]\tvalidation_0-rmse:0.47209\n",
      "[143]\tvalidation_0-rmse:0.47200\n",
      "[144]\tvalidation_0-rmse:0.47191\n",
      "[145]\tvalidation_0-rmse:0.47181\n",
      "[146]\tvalidation_0-rmse:0.47171\n",
      "[147]\tvalidation_0-rmse:0.47161\n",
      "[148]\tvalidation_0-rmse:0.47152\n",
      "[149]\tvalidation_0-rmse:0.47143\n",
      "[150]\tvalidation_0-rmse:0.47135\n",
      "[151]\tvalidation_0-rmse:0.47127\n",
      "[152]\tvalidation_0-rmse:0.47120\n",
      "[153]\tvalidation_0-rmse:0.47112\n",
      "[154]\tvalidation_0-rmse:0.47103\n",
      "[155]\tvalidation_0-rmse:0.47094\n",
      "[156]\tvalidation_0-rmse:0.47087\n",
      "[157]\tvalidation_0-rmse:0.47079\n",
      "[158]\tvalidation_0-rmse:0.47069\n",
      "[159]\tvalidation_0-rmse:0.47061\n",
      "[160]\tvalidation_0-rmse:0.47053\n",
      "[161]\tvalidation_0-rmse:0.47045\n",
      "[162]\tvalidation_0-rmse:0.47037\n",
      "[163]\tvalidation_0-rmse:0.47029\n",
      "[164]\tvalidation_0-rmse:0.47022\n",
      "[165]\tvalidation_0-rmse:0.47014\n",
      "[166]\tvalidation_0-rmse:0.47006\n",
      "[167]\tvalidation_0-rmse:0.46997\n",
      "[168]\tvalidation_0-rmse:0.46988\n",
      "[169]\tvalidation_0-rmse:0.46980\n",
      "[170]\tvalidation_0-rmse:0.46971\n",
      "[171]\tvalidation_0-rmse:0.46964\n",
      "[172]\tvalidation_0-rmse:0.46957\n",
      "[173]\tvalidation_0-rmse:0.46950\n",
      "[174]\tvalidation_0-rmse:0.46942\n",
      "[175]\tvalidation_0-rmse:0.46936\n",
      "[176]\tvalidation_0-rmse:0.46929\n",
      "[177]\tvalidation_0-rmse:0.46921\n",
      "[178]\tvalidation_0-rmse:0.46914\n",
      "[179]\tvalidation_0-rmse:0.46907\n",
      "[180]\tvalidation_0-rmse:0.46899\n",
      "[181]\tvalidation_0-rmse:0.46893\n",
      "[182]\tvalidation_0-rmse:0.46885\n",
      "[183]\tvalidation_0-rmse:0.46877\n",
      "[184]\tvalidation_0-rmse:0.46871\n",
      "[185]\tvalidation_0-rmse:0.46862\n",
      "[186]\tvalidation_0-rmse:0.46855\n",
      "[187]\tvalidation_0-rmse:0.46847\n",
      "[188]\tvalidation_0-rmse:0.46839\n",
      "[189]\tvalidation_0-rmse:0.46832\n",
      "[190]\tvalidation_0-rmse:0.46824\n",
      "[191]\tvalidation_0-rmse:0.46817\n",
      "[192]\tvalidation_0-rmse:0.46813\n",
      "[193]\tvalidation_0-rmse:0.46804\n",
      "[194]\tvalidation_0-rmse:0.46799\n",
      "[195]\tvalidation_0-rmse:0.46790\n",
      "[196]\tvalidation_0-rmse:0.46783\n",
      "[197]\tvalidation_0-rmse:0.46775\n",
      "[198]\tvalidation_0-rmse:0.46769\n",
      "[199]\tvalidation_0-rmse:0.46765\n",
      "[200]\tvalidation_0-rmse:0.46757\n",
      "[201]\tvalidation_0-rmse:0.46749\n",
      "[202]\tvalidation_0-rmse:0.46742\n",
      "[203]\tvalidation_0-rmse:0.46738\n",
      "[204]\tvalidation_0-rmse:0.46730\n",
      "[205]\tvalidation_0-rmse:0.46723\n",
      "[206]\tvalidation_0-rmse:0.46717\n",
      "[207]\tvalidation_0-rmse:0.46710\n",
      "[208]\tvalidation_0-rmse:0.46702\n",
      "[209]\tvalidation_0-rmse:0.46695\n",
      "[210]\tvalidation_0-rmse:0.46688\n",
      "[211]\tvalidation_0-rmse:0.46681\n",
      "[212]\tvalidation_0-rmse:0.46673\n",
      "[213]\tvalidation_0-rmse:0.46668\n",
      "[214]\tvalidation_0-rmse:0.46660\n",
      "[215]\tvalidation_0-rmse:0.46654\n",
      "[216]\tvalidation_0-rmse:0.46647\n",
      "[217]\tvalidation_0-rmse:0.46640\n",
      "[218]\tvalidation_0-rmse:0.46633\n",
      "[219]\tvalidation_0-rmse:0.46625\n",
      "[220]\tvalidation_0-rmse:0.46618\n",
      "[221]\tvalidation_0-rmse:0.46612\n",
      "[222]\tvalidation_0-rmse:0.46604\n",
      "[223]\tvalidation_0-rmse:0.46597\n",
      "[224]\tvalidation_0-rmse:0.46590\n",
      "[225]\tvalidation_0-rmse:0.46583\n",
      "[226]\tvalidation_0-rmse:0.46576\n",
      "[227]\tvalidation_0-rmse:0.46568\n",
      "[228]\tvalidation_0-rmse:0.46564\n",
      "[229]\tvalidation_0-rmse:0.46557\n",
      "[230]\tvalidation_0-rmse:0.46550\n",
      "[231]\tvalidation_0-rmse:0.46545\n",
      "[232]\tvalidation_0-rmse:0.46537\n",
      "[233]\tvalidation_0-rmse:0.46530\n",
      "[234]\tvalidation_0-rmse:0.46524\n",
      "[235]\tvalidation_0-rmse:0.46517\n",
      "[236]\tvalidation_0-rmse:0.46511\n",
      "[237]\tvalidation_0-rmse:0.46505\n",
      "[238]\tvalidation_0-rmse:0.46500\n",
      "[239]\tvalidation_0-rmse:0.46493\n",
      "[240]\tvalidation_0-rmse:0.46486\n",
      "[241]\tvalidation_0-rmse:0.46481\n",
      "[242]\tvalidation_0-rmse:0.46473\n",
      "[243]\tvalidation_0-rmse:0.46470\n",
      "[244]\tvalidation_0-rmse:0.46464\n",
      "[245]\tvalidation_0-rmse:0.46458\n",
      "[246]\tvalidation_0-rmse:0.46452\n",
      "[247]\tvalidation_0-rmse:0.46448\n",
      "[248]\tvalidation_0-rmse:0.46442\n",
      "[249]\tvalidation_0-rmse:0.46435\n",
      "[250]\tvalidation_0-rmse:0.46429\n",
      "[251]\tvalidation_0-rmse:0.46425\n",
      "[252]\tvalidation_0-rmse:0.46418\n",
      "[253]\tvalidation_0-rmse:0.46409\n",
      "[254]\tvalidation_0-rmse:0.46404\n",
      "[255]\tvalidation_0-rmse:0.46398\n",
      "[256]\tvalidation_0-rmse:0.46393\n",
      "[257]\tvalidation_0-rmse:0.46388\n",
      "[258]\tvalidation_0-rmse:0.46384\n",
      "[259]\tvalidation_0-rmse:0.46379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[260]\tvalidation_0-rmse:0.46371\n",
      "[261]\tvalidation_0-rmse:0.46364\n",
      "[262]\tvalidation_0-rmse:0.46357\n",
      "[263]\tvalidation_0-rmse:0.46354\n",
      "[264]\tvalidation_0-rmse:0.46350\n",
      "[265]\tvalidation_0-rmse:0.46345\n",
      "[266]\tvalidation_0-rmse:0.46338\n",
      "[267]\tvalidation_0-rmse:0.46333\n",
      "[268]\tvalidation_0-rmse:0.46329\n",
      "[269]\tvalidation_0-rmse:0.46322\n",
      "[270]\tvalidation_0-rmse:0.46317\n",
      "[271]\tvalidation_0-rmse:0.46309\n",
      "[272]\tvalidation_0-rmse:0.46303\n",
      "[273]\tvalidation_0-rmse:0.46296\n",
      "[274]\tvalidation_0-rmse:0.46292\n",
      "[275]\tvalidation_0-rmse:0.46289\n",
      "[276]\tvalidation_0-rmse:0.46284\n",
      "[277]\tvalidation_0-rmse:0.46280\n",
      "[278]\tvalidation_0-rmse:0.46274\n",
      "[279]\tvalidation_0-rmse:0.46269\n",
      "[280]\tvalidation_0-rmse:0.46264\n",
      "[281]\tvalidation_0-rmse:0.46257\n",
      "[282]\tvalidation_0-rmse:0.46251\n",
      "[283]\tvalidation_0-rmse:0.46243\n",
      "[284]\tvalidation_0-rmse:0.46236\n",
      "[285]\tvalidation_0-rmse:0.46231\n",
      "[286]\tvalidation_0-rmse:0.46226\n",
      "[287]\tvalidation_0-rmse:0.46222\n",
      "[288]\tvalidation_0-rmse:0.46219\n",
      "[289]\tvalidation_0-rmse:0.46214\n",
      "[290]\tvalidation_0-rmse:0.46209\n",
      "[291]\tvalidation_0-rmse:0.46202\n",
      "[292]\tvalidation_0-rmse:0.46197\n",
      "[293]\tvalidation_0-rmse:0.46193\n",
      "[294]\tvalidation_0-rmse:0.46185\n",
      "[295]\tvalidation_0-rmse:0.46182\n",
      "[296]\tvalidation_0-rmse:0.46175\n",
      "[297]\tvalidation_0-rmse:0.46168\n",
      "[298]\tvalidation_0-rmse:0.46162\n",
      "[299]\tvalidation_0-rmse:0.46157\n",
      "[300]\tvalidation_0-rmse:0.46151\n",
      "[301]\tvalidation_0-rmse:0.46145\n",
      "[302]\tvalidation_0-rmse:0.46141\n",
      "[303]\tvalidation_0-rmse:0.46135\n",
      "[304]\tvalidation_0-rmse:0.46129\n",
      "[305]\tvalidation_0-rmse:0.46124\n",
      "[306]\tvalidation_0-rmse:0.46118\n",
      "[307]\tvalidation_0-rmse:0.46113\n",
      "[308]\tvalidation_0-rmse:0.46107\n",
      "[309]\tvalidation_0-rmse:0.46102\n",
      "[310]\tvalidation_0-rmse:0.46096\n",
      "[311]\tvalidation_0-rmse:0.46089\n",
      "[312]\tvalidation_0-rmse:0.46083\n",
      "[313]\tvalidation_0-rmse:0.46077\n",
      "[314]\tvalidation_0-rmse:0.46071\n",
      "[315]\tvalidation_0-rmse:0.46065\n",
      "[316]\tvalidation_0-rmse:0.46060\n",
      "[317]\tvalidation_0-rmse:0.46054\n",
      "[318]\tvalidation_0-rmse:0.46049\n",
      "[319]\tvalidation_0-rmse:0.46047\n",
      "[320]\tvalidation_0-rmse:0.46041\n",
      "[321]\tvalidation_0-rmse:0.46038\n",
      "[322]\tvalidation_0-rmse:0.46034\n",
      "[323]\tvalidation_0-rmse:0.46028\n",
      "[324]\tvalidation_0-rmse:0.46024\n",
      "[325]\tvalidation_0-rmse:0.46018\n",
      "[326]\tvalidation_0-rmse:0.46013\n",
      "[327]\tvalidation_0-rmse:0.46009\n",
      "[328]\tvalidation_0-rmse:0.46002\n",
      "[329]\tvalidation_0-rmse:0.45997\n",
      "[330]\tvalidation_0-rmse:0.45994\n",
      "[331]\tvalidation_0-rmse:0.45989\n",
      "[332]\tvalidation_0-rmse:0.45983\n",
      "[333]\tvalidation_0-rmse:0.45975\n",
      "[334]\tvalidation_0-rmse:0.45968\n",
      "[335]\tvalidation_0-rmse:0.45962\n",
      "[336]\tvalidation_0-rmse:0.45958\n",
      "[337]\tvalidation_0-rmse:0.45953\n",
      "[338]\tvalidation_0-rmse:0.45947\n",
      "[339]\tvalidation_0-rmse:0.45942\n",
      "[340]\tvalidation_0-rmse:0.45936\n",
      "[341]\tvalidation_0-rmse:0.45931\n",
      "[342]\tvalidation_0-rmse:0.45924\n",
      "[343]\tvalidation_0-rmse:0.45919\n",
      "[344]\tvalidation_0-rmse:0.45915\n",
      "[345]\tvalidation_0-rmse:0.45909\n",
      "[346]\tvalidation_0-rmse:0.45907\n",
      "[347]\tvalidation_0-rmse:0.45901\n",
      "[348]\tvalidation_0-rmse:0.45898\n",
      "[349]\tvalidation_0-rmse:0.45892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.01, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=3,\n",
       "             missing=nan,\n",
       "             monotone_constraints=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...),\n",
       "             n_estimators=350, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train final model w/ early stopping\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10,\n",
    "    # **grid_search.best_params_\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # **{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 90, 'subsample': 1.0},\n",
    "    \n",
    "    # **{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 0, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1), 'n_estimators': 200, 'subsample': 1.0}\n",
    "\n",
    "    # **grid_search.best_params_,\n",
    "    # **{'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 31.4%\n",
    "    # {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 200, 'subsample': 0.8}\n",
    "    # 66.5%, dd 30.9%\n",
    "    # {'colsample_bytree': 1.0, 'learning_rate': 0.005, 'max_depth': 5, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 300, 'subsample': 0.6}\n",
    ")\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    # **grid_search.best_params_,\n",
    "    # 67.3 w/ kelly adjustments 0.2, 0.01\n",
    "    # {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 4, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 350, 'subsample': 0.6}\n",
    "    # 67.2, dd 28.68 kelly 0.25, 0.014\n",
    "    **{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), 'n_estimators': 350, 'subsample': 0.5}\n",
    ")\n",
    "model.fit(\n",
    "    conts_train,\n",
    "    y_train,\n",
    "    eval_set=[(conts_train, y_train)], # , (holdout_conts, holdout_y)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef6e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perf_conts.shape\n",
    "perf_y_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "177675db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 2.9785714285714286\n",
      "skipping 2.490714285714286\n",
      "skipping 2.2085714285714286\n",
      "skipping 2.5471428571428576\n",
      "skipping 2.885\n",
      "skipping 2.186153846153846\n",
      "[4, 6, 7, 8, 9, 12, 13, 14]\n",
      "2024-01-13 kelly 1.00 w_odds:1.57 acct_val: 1000.00 usable cash: 900.00 won: True\n",
      "2024-01-13 kelly 1.00 w_odds:1.67 acct_val: 1056.93 usable cash: 794.31 won: False\n",
      "2024-01-13 kelly 1.00 w_odds:1.68 acct_val: 951.24 usable cash: 699.18 won: False\n",
      "2024-01-13 kelly 1.00 w_odds:1.29 acct_val: 856.11 usable cash: 613.57 won: True\n",
      "2024-01-13 kelly 1.00 w_odds:1.11 acct_val: 881.06 usable cash: 525.47 won: False\n",
      "2024-01-13 kelly 1.00 w_odds:1.66 acct_val: 792.96 usable cash: 446.17 won: True\n",
      "2024-01-13 kelly 1.00 w_odds:1.52 acct_val: 844.95 usable cash: 361.68 won: True\n",
      "2024-01-13 kelly 1.00 w_odds:1.58 acct_val: 888.53 usable cash: 272.82 won: True\n",
      "skipping 3.8642857142857134\n",
      "[16]\n",
      "2024-01-14 kelly 1.00 w_odds:1.44 acct_val: 939.93 usable cash: 845.94 won: True\n",
      "[18]\n",
      "2024-01-15 kelly 1.00 w_odds:1.61 acct_val: 980.89 usable cash: 882.80 won: True\n",
      "skipping 2.3146153846153847\n",
      "[19]\n",
      "2024-01-20 kelly 1.00 w_odds:1.19 acct_val: 1040.44 usable cash: 936.40 won: True\n",
      "[21, 22]\n",
      "2024-01-21 kelly 1.00 w_odds:1.21 acct_val: 1060.43 usable cash: 954.39 won: True\n",
      "2024-01-21 kelly 1.00 w_odds:1.20 acct_val: 1082.70 usable cash: 846.12 won: True\n",
      "skipping 2.25\n",
      "[23]\n",
      "2024-01-28 kelly 1.00 w_odds:1.35 acct_val: 1104.20 usable cash: 993.78 won: True\n",
      "skipping 2.695\n",
      "skipping 2.0821428571428573\n",
      "[25]\n",
      "2024-10-10 kelly 1.00 w_odds:1.29 acct_val: 1142.45 usable cash: 1028.21 won: True\n",
      "[28]\n",
      "2024-10-13 kelly 1.00 w_odds:1.51 acct_val: 1175.10 usable cash: 1057.59 won: True\n",
      "skipping 2.038\n",
      "[29, 30, 32, 33, 34, 35, 36]\n",
      "2024-10-14 kelly 1.00 w_odds:1.55 acct_val: 1234.56 usable cash: 1111.10 won: False\n",
      "2024-10-14 kelly 1.00 w_odds:1.33 acct_val: 1111.10 usable cash: 999.99 won: True\n",
      "2024-10-14 kelly 1.00 w_odds:1.54 acct_val: 1148.10 usable cash: 885.18 won: True\n",
      "2024-10-14 kelly 1.00 w_odds:1.40 acct_val: 1210.44 usable cash: 764.14 won: True\n",
      "2024-10-14 kelly 1.00 w_odds:1.31 acct_val: 1258.38 usable cash: 638.30 won: True\n",
      "2024-10-14 kelly 1.00 w_odds:1.46 acct_val: 1297.01 usable cash: 508.60 won: True\n",
      "2024-10-14 kelly 1.00 w_odds:1.37 acct_val: 1356.15 usable cash: 372.98 won: False\n",
      "[37]\n",
      "2024-10-17 kelly 1.00 w_odds:1.85 acct_val: 1220.54 usable cash: 1098.48 won: True\n",
      "[38]\n",
      "2024-10-20 kelly 1.00 w_odds:1.68 acct_val: 1324.04 usable cash: 1191.63 won: False\n",
      "skipping 2.391\n",
      "skipping 2.054\n",
      "skipping 2.325\n",
      "skipping 2.244\n",
      "skipping 2.005\n",
      "[39, 42, 43, 44, 45, 46, 48, 49]\n",
      "2024-10-21 kelly 1.00 w_odds:1.42 acct_val: 1191.63 usable cash: 1072.47 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.60 acct_val: 1241.09 usable cash: 948.36 won: False\n",
      "2024-10-21 kelly 1.00 w_odds:1.28 acct_val: 1116.98 usable cash: 836.66 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.19 acct_val: 1148.81 usable cash: 721.78 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.67 acct_val: 1170.41 usable cash: 604.74 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.30 acct_val: 1248.59 usable cash: 479.88 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.20 acct_val: 1286.19 usable cash: 351.26 won: True\n",
      "2024-10-21 kelly 1.00 w_odds:1.57 acct_val: 1311.53 usable cash: 220.11 won: True\n",
      "skipping 2.2777777777777777\n",
      "[52]\n",
      "2024-10-27 kelly 1.00 w_odds:1.45 acct_val: 1386.55 usable cash: 1247.89 won: True\n",
      "skipping 2.276\n",
      "skipping 3.698\n",
      "skipping 3.74\n",
      "skipping 2.82\n",
      "[54, 55, 58, 61, 62, 63, 64, 65, 66, 67]\n",
      "2024-10-28 kelly 1.00 w_odds:1.12 acct_val: 1448.94 usable cash: 1304.05 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.13 acct_val: 1466.76 usable cash: 1157.37 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.54 acct_val: 1485.68 usable cash: 1008.80 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.80 acct_val: 1566.21 usable cash: 852.18 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.42 acct_val: 1692.29 usable cash: 682.95 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.41 acct_val: 1763.70 usable cash: 506.58 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.79 acct_val: 1836.37 usable cash: 322.95 won: False\n",
      "2024-10-28 kelly 1.00 w_odds:1.28 acct_val: 1652.73 usable cash: 157.67 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.61 acct_val: 1699.17 usable cash: 0.00 won: True\n",
      "2024-10-28 kelly 1.00 w_odds:1.22 acct_val: 1795.51 usable cash: 0.00 won: True\n",
      "[68]\n",
      "2024-10-31 kelly 1.00 w_odds:1.38 acct_val: 1795.51 usable cash: 1615.96 won: True\n",
      "[69]\n",
      "2024-11-03 kelly 1.00 w_odds:1.67 acct_val: 1863.20 usable cash: 1676.88 won: False\n",
      "skipping 3.745\n",
      "[70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82]\n",
      "2024-11-04 kelly 1.00 w_odds:1.77 acct_val: 1676.88 usable cash: 1509.19 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.70 acct_val: 1806.17 usable cash: 1328.58 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.58 acct_val: 1932.42 usable cash: 1135.33 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.40 acct_val: 2045.27 usable cash: 930.81 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.47 acct_val: 2127.49 usable cash: 718.06 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.28 acct_val: 2228.34 usable cash: 495.22 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.57 acct_val: 2291.62 usable cash: 266.06 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.77 acct_val: 2422.93 usable cash: 23.77 won: False\n",
      "2024-11-04 kelly 1.00 w_odds:1.23 acct_val: 2180.64 usable cash: 0.00 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.37 acct_val: 2186.08 usable cash: 0.00 won: True\n",
      "2024-11-04 kelly 1.00 w_odds:1.79 acct_val: 2186.08 usable cash: 0.00 won: False\n",
      "2024-11-04 kelly 1.00 w_odds:1.26 acct_val: 2186.08 usable cash: 0.00 won: True\n",
      "[83]\n",
      "2024-11-07 kelly 1.00 w_odds:1.24 acct_val: 2186.08 usable cash: 1967.47 won: True\n",
      "skipping 2.658\n",
      "skipping 3.3879999999999995\n",
      "[84]\n",
      "2024-11-10 kelly 1.00 w_odds:1.36 acct_val: 2237.45 usable cash: 2013.71 won: True\n",
      "skipping 3.405\n",
      "skipping 2.032\n",
      "skipping 2.141\n",
      "[87, 88, 89, 91, 93, 94, 95]\n",
      "2024-11-14 kelly 1.00 w_odds:1.34 acct_val: 2318.75 usable cash: 2086.87 won: False\n",
      "2024-11-14 kelly 1.00 w_odds:1.24 acct_val: 2086.87 usable cash: 1878.19 won: True\n",
      "2024-11-14 kelly 1.00 w_odds:1.44 acct_val: 2136.75 usable cash: 1664.51 won: True\n",
      "2024-11-14 kelly 1.00 w_odds:1.30 acct_val: 2230.98 usable cash: 1441.41 won: False\n",
      "2024-11-14 kelly 1.00 w_odds:1.29 acct_val: 2007.88 usable cash: 1240.62 won: True\n",
      "2024-11-14 kelly 1.00 w_odds:1.45 acct_val: 2065.51 usable cash: 1034.07 won: True\n",
      "2024-11-14 kelly 1.00 w_odds:1.28 acct_val: 2157.63 usable cash: 818.31 won: True\n",
      "[97]\n",
      "2024-11-17 kelly 1.00 w_odds:1.44 acct_val: 2217.83 usable cash: 1996.04 won: True\n",
      "skipping 3.1789999999999994\n",
      "skipping 2.753\n",
      "skipping 2.522\n",
      "[98, 99, 100, 101, 102, 103, 105, 106, 109]\n",
      "2024-11-18 kelly 1.00 w_odds:1.37 acct_val: 2315.85 usable cash: 2084.27 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.36 acct_val: 2401.77 usable cash: 1844.09 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.99 acct_val: 2489.44 usable cash: 1595.15 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.65 acct_val: 2736.64 usable cash: 1321.48 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.10 acct_val: 2915.62 usable cash: 1029.92 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.85 acct_val: 2944.48 usable cash: 735.47 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.24 acct_val: 3195.64 usable cash: 415.91 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.48 acct_val: 3272.98 usable cash: 88.61 won: True\n",
      "2024-11-18 kelly 1.00 w_odds:1.76 acct_val: 3431.39 usable cash: 0.00 won: True\n",
      "skipping 2.772\n",
      "[110]\n",
      "2024-11-24 kelly 1.00 w_odds:1.28 acct_val: 3498.38 usable cash: 3148.54 won: False\n",
      "skipping 2.015\n",
      "skipping 5.405555555555555\n",
      "skipping 4.21\n",
      "[112, 113, 114, 115, 116, 118, 119, 122]\n",
      "2024-11-25 kelly 1.00 w_odds:1.26 acct_val: 3148.54 usable cash: 2833.69 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.61 acct_val: 3231.35 usable cash: 2510.55 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.62 acct_val: 3428.46 usable cash: 2167.71 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.15 acct_val: 3639.66 usable cash: 1803.74 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.27 acct_val: 3694.25 usable cash: 1434.32 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.35 acct_val: 3795.84 usable cash: 1054.73 won: False\n",
      "2024-11-25 kelly 1.00 w_odds:1.36 acct_val: 3416.26 usable cash: 713.11 won: True\n",
      "2024-11-25 kelly 1.00 w_odds:1.40 acct_val: 3540.61 usable cash: 359.05 won: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'final_value': 3186.5492133057323,\n",
       " 'roi': 2.1865492133057325,\n",
       " 'win_rate': 0.813953488372093,\n",
       " 'max_drawdown': 0.24975485714285714,\n",
       " 'total_bets': 86}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for test data\n",
    "# model = grid_search.best_estimator_\n",
    "y_pred = model.predict(perf_conts)\n",
    "\n",
    "nfl_utils.backtest_model(model, perf_conts, perf_y_col, perf_date_col, initial_capital=1000, position_size=0.1, \n",
    "                   confidence_threshold=0.0, show_plot=True, max_won_odds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make confusion matrix\n",
    "cm = confusion_matrix(perf_y_col[:,0], y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7025ece",
   "metadata": {},
   "source": [
    "## Save XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94a74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6577d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a1a349",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
